{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 작업형1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mtcars 데이터셋의 qsec 칼럼을 최소-최대 척도(Min-Max Scale)로 변환한 후 0.5보다 큰 값을 가지는 레코드 수를 츌력하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mtcars = pd.read_csv('./data/mtcars.csv')\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "mtcars['scaled_qsec'] = scaler.fit_transform(mtcars[['qsec']])\n",
    "\n",
    "print(len(mtcars[mtcars['scaled_qsec'] > 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Cars93 데이터셋의 Wheelbase 컬럼에 대해서 평균 값에서 표준편차의 1.5배, 2배, 2.5배를 더하거나 뺀 값들의 구간 내의 데이터들의 평균을 각각 구한 후 원래의 데이터 평균에서 뺐을 때 차이들의 합을 출력하여라, (단, 소수점 다섯째 자리에서 반올림하여 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 확인\n",
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wheelbase 할당\n",
    "Wheelbase = Cars93['Wheelbase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.98924731182795"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wheelbase의 평균\n",
    "Wheelbase_avg = Wheelbase.mean()\n",
    "Wheelbase_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.389026269401888"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wheelbase의 표준편차\n",
    "Wheelbase_sd = Wheelbase.std()\n",
    "Wheelbase_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case1. 평균 값에서 표준편차를 1.5배를 더하거나 빼는 경우\n",
    "# 구간의 하한(Low_1)과 상한(Upp_1) 계산\n",
    "Low_1 = Wheelbase_avg - 1.5 * Wheelbase_sd\n",
    "Upp_1 = Wheelbase_avg + 1.5 * Wheelbase_sd\n",
    "\n",
    "# 구간 내 데이터들의 평균\n",
    "Avg_1 = Wheelbase[(Wheelbase > Low_1) & (Wheelbase < Upp_1)].mean()\n",
    "\n",
    "# 원래의 데이터 평균에서 뺌\n",
    "Case1 = Wheelbase_avg - Avg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case2. 평균 값에서 표준편차를 2배를 더하거나 빼는 경우\n",
    "# 구간의 하한(Low_2)과 상한(Upp_2) 계산\n",
    "Low_2 = Wheelbase_avg - 2 * Wheelbase_sd\n",
    "Upp_2 = Wheelbase_avg + 2 * Wheelbase_sd\n",
    "\n",
    "# 구간 내 데이터들의 평균\n",
    "Avg_2 = Wheelbase[(Wheelbase > Low_2) & (Wheelbase < Upp_2)].mean()\n",
    "\n",
    "# 원래의 데이터 평균에서 뺌\n",
    "Case2 = Wheelbase_avg - Avg_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case3. 평균 값에서 표준편차를 2.5배를 더하거나 빼는 경우\n",
    "# 구간의 하한(Low_3)과 상한(Upp_3) 계산\n",
    "Low_3 = Wheelbase_avg - 2.5 * Wheelbase_sd\n",
    "Upp_3 = Wheelbase_avg + 2.5 * Wheelbase_sd\n",
    "\n",
    "# 구간 내 데이터들의 평균\n",
    "Avg_3 = Wheelbase[(Wheelbase > Low_3) & (Wheelbase < Upp_3)].mean()\n",
    "\n",
    "# 원래의 데이터 평균에서 뺌\n",
    "Case3 = Wheelbase_avg - Avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(Case1 + Case2 + Case3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4845\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. Cars93 데이터셋의 Length 컬럼에 대해서 순위를 부여한 후, 1위부터 30위까지 값들의 표준편차를 구하고 소수점 셋째 자리까지 반올림하여 나타내어라. (단, 동점은 동일한 순위를 부여하되 평균내어 등수를 산정하며 최솟값을 1위로 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length의 순위\n",
    "rank = Cars93['Length'].rank(method = 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1위~30위까지만 추출\n",
    "sub = Cars93['Length'][rank <= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub의 표준편차\n",
    "sub_sd = sub.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 reseult에 할당\n",
    "result = round(sub_sd, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.884\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. Cars93 데이터셋의 Max_price 컬럼과 Min_price 컬럼에 대해서 각각 정렬한 후 정렬된 순서에 따라 레코드별로 Max_price와 Min_price의 차이를 산출하고 차이값에 대해 표준편차를 구하여라. (단, Max_price의 정렬은 내림차순, Min_price의 정렬은 오름차순으로 하며, 출력시 표준편차는 소수점 넷째 자리에서 반올림하여 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내림차순으로 정렬해 MaxPrice_sort에 할당\n",
    "MaxPrice_sort = Cars93['Max_Price'].sort_values(ascending = False, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내림차순으로 정렬해 MinPrice_sort에 할당\n",
    "MinPrice_sort = Cars93['Min_Price'].sort_values(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이 계산\n",
    "diff = MaxPrice_sort - MinPrice_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이에 대한 표준편차\n",
    "diff_sd = diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(diff_sd, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.584\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04. Cars93 데이터셋의 Weight 컬럼을 Min-Max 정규화로 변환한 후, 0.5보다 작은 값들의 분산과 0.5보다 큰 값들의 분산의 차이를 구하여라. (단, 차이는 큰 값에서 작은 값을 빼서 구하며, 소수점 넷째 자리에서 반올림하여 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight 컬럼 Min-Max 정규화로 변환\n",
    "Weight = Cars93['Weight']\n",
    "Weight_std = (Weight - min(Weight)) / (max(Weight) - min(Weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5보다 작은 Weight들의 분산\n",
    "var_under = Weight_std[Weight_std < 0.5].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5보다 큰 Weight들의 분산\n",
    "var_over = Weight_std[Weight_std > 0.5].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이 계산\n",
    "diff = abs(var_over - var_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(diff, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05. Cars93 데이터셋을 이용하여 Manufacturer, Origin 컬럼의 유일값 조합의 수와 Manufacturer 컬럼의 앞 두글자만 추출한 결과와 Origin 컬럼과의 유일값 조합 수의 차이를 구하여라. (단, 원래 유일값 조합 수에서 추출 이후 수를 뺄 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 유일값 조합의 수\n",
    "uniq_raw = Cars93[['Manufacturer', 'Origin']].drop_duplicates()\n",
    "num_uniq_raw = uniq_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manufacturer 컬럼 앞 두 글자 추출\n",
    "Cars93['sub_str'] = Cars93['Manufacturer'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유일값 조합의 수\n",
    "uniq_new = Cars93[['sub_str', 'Origin']].drop_duplicates()\n",
    "num_uniq_new = uniq_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = num_uniq_raw - num_uniq_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06. Cars93 데이터셋을 이용하여 컬럼 Type, Man_trans_avail에 대한 그룹별 RPM 레코드 수와 RPM 합계, 중앙값을 모두 구한 후, 그룹별 중앙값에서 그룹별 합계에서 레코드 수를 나눈 값들을 빼서 나온 결과의 총 원소 합을 구하여라. (단, 출력시 소수점은 첫째 자리에서 반올림하여 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'Model', 'Type', 'Min_Price', 'Price', 'Max_Price',\n",
       "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
       "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
       "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
       "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
       "       'Unnamed: 26', 'Make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars93.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 RPM 레코드 수\n",
    "count_RPM_gp = Cars93.groupby(['Type', 'Man_trans_avail'])['RPM'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 RPM 합계\n",
    "sum_RPM_gp = Cars93.groupby(['Type', 'Man_trans_avail'])['RPM'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 RPM 중앙값\n",
    "median_RPM_gp = Cars93.groupby(['Type', 'Man_trans_avail'])['RPM'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 중앙값 - (그룹별 합계 / 레코드 수)을 계산한 후 모든 원소 합\n",
    "calcul = sum(median_RPM_gp - sum_RPM_gp/count_RPM_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(calcul, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442.0\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07. Cars93 데이터셋을 이용하여 RPM 컬럼의 결측치를 평균으로 대체하고 RPM와 Wheelbase 컬럼을 각각 z-점수 표준화한 후 표준화된 Wheelbase에 상수 -36을 곱한 값과 표준화된 RPM 컬럼의 차이값을 구하고 표준편차를 산출하여라. (단, 소수점 셋째 자리까지 반올림하여 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manufacturer           0\n",
       "Model                  0\n",
       "Type                   0\n",
       "Min_Price              0\n",
       "Price                  9\n",
       "Max_Price              0\n",
       "MPG_city               0\n",
       "MPG_highway            0\n",
       "AirBags               34\n",
       "DriveTrain             0\n",
       "Cylinders              0\n",
       "EngineSize             0\n",
       "Horsepower             0\n",
       "RPM                    4\n",
       "Rev_per_mile           0\n",
       "Man_trans_avail        0\n",
       "Fuel_tank_capacity     0\n",
       "Passengers             0\n",
       "Length                 0\n",
       "Wheelbase              0\n",
       "Width                  0\n",
       "Turn_circle           13\n",
       "Rear_seat_room         2\n",
       "Luggage_room          11\n",
       "Weight                 0\n",
       "Origin                 0\n",
       "Unnamed: 26            0\n",
       "Make                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "Cars93.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPM 컬럼 결측치 평균 대체\n",
    "avg = Cars93['RPM'].mean()\n",
    "Cars93['RPM'] = Cars93['RPM'].fillna(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPM 컬럼 z-점수 표준화\n",
    "RPM_std = (Cars93['RPM'] - Cars93['RPM'].mean()) / Cars93['RPM'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wheelbase 컬럼 z-점수 표준화\n",
    "Wheelbase_std = (Cars93['Wheelbase'] - Cars93['Wheelbase'].mean()) / Cars93['Wheelbase'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화된 Wheelbase에 상수 -36을 곱한 값과 표준화된 RPM 변수의 차이값\n",
    "diff = Wheelbase_std * (-36) - RPM_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이값의 표준편차\n",
    "diff_sd = diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(diff_sd, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.561\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08. Cars93 데이터셋을 이용하여 먼저, Price 컬럼의 결측치를 평균으로 대체하고 Max_Price 변수와 Min_Price의 평균보다 작은 레코드만을 추출해 산출된 Origin 그룹별 Price의 합계를 구하고 다음으로 Price 컬럼의 결측치를 중앙값으로 대체하고 Price 컬럼이 Min_Price 컬럼의 제 3사분위수보다 작은 레코드만을 추출해 산출된 Origin별 Price의 합계를 Origin 그룹별로 합한 후 큰 값을 출력하여라. (단, 소수점 이하는 모두 절삭하여 정수로 표현할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 대체를 같은 컬럼에 두 번해야하는 문제이므로 이에 데이터프레임을 따로 복사함\n",
    "df_case1 = Cars93.copy()\n",
    "df_case2 = Cars93.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case1\n",
    "\n",
    "# Price 컬럼의 결측치를 평균으로 대체\n",
    "avg = df_case1['Price'].mean()\n",
    "df_case1['Price'] = df_case1['Price'].fillna(avg)\n",
    "\n",
    "# Price가 Max_Price와 Min_Price의 평균보다 작은 데이터프레임을 추출\n",
    "# Max_Price와 Min_Price 컬럼별 평균\n",
    "avg_MaxMin = df_case1[['Max_Price', 'Min_Price']].mean(axis = 1)\n",
    "\n",
    "# Price가 위의 평균보다 작은 데이터프레임\n",
    "sub_df_case1 = df_case1[df_case1['Price'] < avg_MaxMin]\n",
    "\n",
    "# Origin 그룹별 Price의 합계\n",
    "sum_case1 = sub_df_case1.groupby('Origin')['Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case2\n",
    "\n",
    "# Price 컬럼의 결측치를 중앙값으로 대체\n",
    "med = df_case2['Price'].median()\n",
    "df_case2['Price'] = df_case2['Price'].fillna(med)\n",
    "\n",
    "# Price가 Min_Price의 제 3사분위수보다 작은 데이터프레임 추출\n",
    "# Min_Price의 제 3사분위수\n",
    "q3 = df_case2['Min_Price'].quantile(0.75)\n",
    "\n",
    "# Price가 위의 제 3사분위수보다 작은 데이터프레임\n",
    "sub_df_case2 = df_case2[df_case2['Price'] < q3]\n",
    "\n",
    "# Origin 그룹별 Price의 합계\n",
    "sum_case2 = sub_df_case2.groupby('Origin')['Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n"
     ]
    }
   ],
   "source": [
    "# 두 결과를 합한 후 가장 큰 원소\n",
    "max_value = max(sum_case1 + sum_case2)\n",
    "\n",
    "# 결과를 result에 할당\n",
    "import numpy as np \n",
    "result = int(np.floor(max_value))\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09. Cars93 데이터셋에서 'Price' 컬럼은 'Min_Price'와 'Max_Price'의 평균으로 알려져있다. 이와 같은 사실을 통해 'Price'컬럼의 결측치의 원래의 값을 계산한 후, 'Price'가 14.7보다 작거나 25.3보다 크면서 'Large' 타입인 레코드 수를 계산하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Price' 컬럼의 결측치의 원래의 값을 계산\n",
    "# 컬럼들 시리즈로 별도 저장\n",
    "Price = Cars93['Price'].copy()\n",
    "Max_Price = Cars93['Max_Price'].copy()\n",
    "Min_Price = Cars93['Min_Price'].copy()\n",
    "Type = Cars93['Type'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Price' 컬럼이 결측인 조건\n",
    "cond_na = Price.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Price'가 결측치인 경우만 'Min_Price'와 'Max_Price'의 평균을 할당\n",
    "Price[cond_na] = (Max_Price[cond_na] + Min_Price[cond_na]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Price'가 14.7보다 작거나 25.3보다 크면서 'Large' 타입인 레코드 수\n",
    "# 조건1\n",
    "cond1 = Price < 14.7\n",
    "\n",
    "# 조건2\n",
    "cond2 = (Price > 25.3) & (Type == 'Large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당하는 조건\n",
    "cond = cond1 | cond2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = Cars93[cond].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Cars93 데이터셋에서 'Make' 컬럼을 이용하여 제조사가 'Chevrolet', 'Pontiac', 'Hyundai'이면서 'AirBags'이 'Driver'에만 있는 경우의 레코드 수를 계산하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼들 시리즈로 별도 저장\n",
    "Make = Cars93['Make'].copy()\n",
    "AirBags = Cars93['AirBags'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선행 문자(공백) 제거\n",
    "Make = Make.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건\n",
    "# 문자열이 'Chevrolet' 또는 'Pontiac' 또는 'Hyundai'로 시작하면 True를 반환함\n",
    "cond_1 = Make.str.startswith(('Chevrolet', 'Pontiac', 'Hyundai'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'AirBags'이 'Driver'에만 있는 경우\n",
    "cond_2 = AirBags == 'Driver only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = sum(cond_1 & cond_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Rabbit 데이터셋을 불러와 Dose 컬럼의 제 3사분위수와 제 2사분위수를 구하고 두 값의 차이의 절댓값을 구한 후 소수점을 버린 값을 출력하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Rabbit = pd.read_csv('./data/Rabbit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제 3사분위수, 제 2사분위수 별도 저장\n",
    "q3 = Rabbit['Dose'].quantile(0.75)\n",
    "q2 = Rabbit['Dose'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 값의 차이의 절댓값\n",
    "diff = abs(q3 - q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = diff.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Boston 데이터셋을 불러와 medv 컬럼에 대해서 동일한 폭으로 binning한 후 가장 많은 빈도를 가지고 구간을 산출하고 해당 구간 내 dis 컬럼의 중앙값을 구하여라.(폭은 10을 기준으로 하고 소수점은 둘째 자리까지 나타내시오.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Boston = pd.read_csv('./data/Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medv 컬럼에 대해서 동일한 폭으로 binning\n",
    "medv_cut = pd.cut(Boston['medv'], bins = [0, 10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많은 빈도를 가지는 구간을 산출\n",
    "mode = medv_cut.value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당구간 내 dis 컬럼의 중앙값\n",
    "# 조건\n",
    "cond = (medv_cut == mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값\n",
    "median = Boston['dis'][cond].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(median, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.95\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Melanoma 데이터셋을 불러와 1~122번째 레코드와 123번째 이후 레코드로 데이터셋을 분리하고 각 데이터셋별로 thickness 컬럼을 z-score 정규화로 변환한 후 -1과 1 사이 값들의 중앙값을 각각 산출한 후 합계를 구하여라. (단, z-score 정규화 변환 계산에 사용되는 평균과 표준편차는 분리된 것과 관계없이 1~123번째 레코드로 이루어진 데이터셋을 기준으로 하고 출력 시 소수점 넷째 자리까지 반올림하여 나타낼 것, 레코드 번호는 가장 위에 위치한 레코드를 1번으로 가정함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Melanoma = pd.read_csv('./data/Melanoma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~123번째 레코드와 123번째 이후 레코드로 데이터셋을 분리\n",
    "df1 = Melanoma.iloc[:123]\n",
    "df2 = Melanoma.iloc[123:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thickness 컬럼을 z-score 정규화로 변환\n",
    "avg = df1['thickness'].mean()\n",
    "sd = df1['thickness'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score 변환\n",
    "df1_zscore = (df1['thickness'] - avg) / sd\n",
    "df2_zscore = (df2['thickness'] - avg) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1과 1 사이 값들의 중앙값을 각각 산출\n",
    "sub_df1_zscore = df1_zscore[(df1_zscore > -1) & (df1_zscore < 1)]\n",
    "sub_df2_zscore = df2_zscore[(df2_zscore > -1) & (df2_zscore < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값\n",
    "med1 = sub_df1_zscore.median()\n",
    "med2 = sub_df2_zscore.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(med1 + med2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0027\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 03 통계분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic.csc는 타이타닉호의 침몰 사건에서 생존한 승객 및 사망한 승객의 정보를 포함한 자료이다. 생존 여부(Survived)를 예측하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic_train = pd.read_csv('./data/titanic_train.csv')\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 확인\n",
    "titanic_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차표 만들기\n",
    "contingency_table = pd.crosstab(titanic_train['Sex'], titanic_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동질성 검정\n",
    "from scipy.stats import chi2_contingency\n",
    "chi, p, df, expected = chi2_contingency(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.717\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(round(chi,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨인코더\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "titanic_train['Sex'] = le.fit_transform(titanic_train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수와 종속변수 지정\n",
    "X = titanic_train[['Sex', 'SibSp', 'Parch', 'Fare']]\n",
    "y = titanic_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# 상수항 추가\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM객체 생성 후 적합\n",
    "model = sm.GLM(y, X, family = sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Survived</td>     <th>  No. Observations:  </th>  <td>   891</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -429.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 16 Jun 2024</td> <th>  Deviance:          </th> <td>  859.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:37:33</td>     <th>  Pearson chi2:      </th>  <td>  879.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3077</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9466</td> <td>    0.169</td> <td>    5.590</td> <td> 0.000</td> <td>    0.615</td> <td>    1.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex</th>   <td>   -2.6422</td> <td>    0.186</td> <td>  -14.197</td> <td> 0.000</td> <td>   -3.007</td> <td>   -2.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th> <td>   -0.3539</td> <td>    0.098</td> <td>   -3.604</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th> <td>   -0.2007</td> <td>    0.112</td> <td>   -1.792</td> <td> 0.073</td> <td>   -0.420</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>  <td>    0.0147</td> <td>    0.003</td> <td>    5.553</td> <td> 0.000</td> <td>    0.010</td> <td>    0.020</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &     Survived     & \\textbf{  No. Observations:  } &      891    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      886    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -429.52   \\\\\n",
       "\\textbf{Date:}            & Sun, 16 Jun 2024 & \\textbf{  Deviance:          } &    859.04   \\\\\n",
       "\\textbf{Time:}            &     19:37:33     & \\textbf{  Pearson chi2:      } &     879.    \\\\\n",
       "\\textbf{No. Iterations:}  &        5         & \\textbf{  Pseudo R-squ. (CS):} &   0.3077    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.9466  &        0.169     &     5.590  &         0.000        &        0.615    &        1.279     \\\\\n",
       "\\textbf{Sex}   &      -2.6422  &        0.186     &   -14.197  &         0.000        &       -3.007    &       -2.277     \\\\\n",
       "\\textbf{SibSp} &      -0.3539  &        0.098     &    -3.604  &         0.000        &       -0.546    &       -0.161     \\\\\n",
       "\\textbf{Parch} &      -0.2007  &        0.112     &    -1.792  &         0.073        &       -0.420    &        0.019     \\\\\n",
       "\\textbf{Fare}  &       0.0147  &        0.003     &     5.553  &         0.000        &        0.010    &        0.020     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  891\n",
       "Model:                            GLM   Df Residuals:                      886\n",
       "Model Family:                Binomial   Df Model:                            4\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -429.52\n",
       "Date:                Sun, 16 Jun 2024   Deviance:                       859.04\n",
       "Time:                        19:37:33   Pearson chi2:                     879.\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):             0.3077\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9466      0.169      5.590      0.000       0.615       1.279\n",
       "Sex           -2.6422      0.186    -14.197      0.000      -3.007      -2.277\n",
       "SibSp         -0.3539      0.098     -3.604      0.000      -0.546      -0.161\n",
       "Parch         -0.2007      0.112     -1.792      0.073      -0.420       0.019\n",
       "Fare           0.0147      0.003      5.553      0.000       0.010       0.020\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.201\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(round(-0.2007, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 오즈비\n",
    "odds_ratio = round(np.exp(-0.3539), 3)\n",
    "print(odds_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1장. 가설 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1절 상관분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 사이킷런 패키지로부터 내장 데이터 diabetes를 데이터프레임 형태로 호출하고, 'age'와 'bmi' 두 개의 컬럼에 대하여 두 데이터가 상관관계가 있는지 피어슨 상관계수를 이용해 분석해보자. (정규성 만족 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출한 후 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 34.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.18508466614655553, pvalue=9.076791865417418e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scipy.stats.pearsonr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr(x = data['age'], y = data['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.088161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex       bmi\n",
       "sex  1.000000  0.088161\n",
       "bmi  0.088161  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단순한 상관계수의 산출은 데이터프레임객체.corr()로도 가능\n",
    "data[['sex', 'bmi']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2절. 정규성 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 임의의 균일 표본을 생성한 후, 생성된 표본의 정규성 여부 확인을 위한 샤피로-윌크 검정을 수행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 호출\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 균일표본 생성\n",
    "# (참고) np.random.random(size) : 균일 분포로부터 size개의 len을 가지는 난수 생성\n",
    "np.random.seed(2024) # 결과의 일관성을 위해 시드값 설정\n",
    "x = np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.8969662710477171, pvalue=0.20285343366469372)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샤피로-윌크 검정 수행\n",
    "from scipy.stats import shapiro\n",
    "shapiro(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3절. 모평균과 모분산 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 몸무게 데이터를 임의로 생성해보고 모집단의 평균이 70이라고 할 수 있는지 단일표본 t-검정을 수행해보자.(정규성 만족 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 호출\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몸무게 데이터 임의 생성\n",
    "kg = np.array([75.5, 83.9, 75.7, 56.2, 73.4, 67.7, 79.0, 50.7, 58.4, 74.1, 65.1, 77.8, 48.1, 46.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.56428571428572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표본 평균\n",
    "np.mean(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.0289933120202257, pvalue=0.3222484823978743, df=13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단일 표본 t-검정 실행\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "ttest_1samp(kg, 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 남녀 몸무게 데이터를 임의로 생성하고, 두 데이터가 서로 짝지어져 있다고 가정하고, 두 데이터에 대한 모평균이 서로 다르다고 할 수 있는 지 대응표본 t-검정을 수행해보자.(정규성 만족 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남녀 몸무게 데이터를 임의로 생성\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "female = np.array([50.7, 58.4, 74.1, 65.1, 77.8, 48.1, 46.3])\n",
    "male = np.array([75.5, 83.9, 75.7, 56.2, 73.4, 67.7, 79.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.985714285714291"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 데이터의 차이의 평균\n",
    "diff = female - male\n",
    "np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.078446933064972, pvalue=0.08291274205610201, df=6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대응표본 t-검정 실행\n",
    "from scipy.stats import ttest_rel\n",
    "ttest_rel(female, male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 남녀 몸무게 데이터를 활용해 두 데이터가 독립이라고 가정하고, 두 데이터에 대한 모평균이 서로 다르다고 할 수 있는 지 독립표본 t-검정을 수행해보자.(정규성, 등분산성 만족 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.2186641577772956, pvalue=0.046550122110569664, df=12.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 독립표본 t-검정 실행\n",
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(female, male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5절 비모수 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스피어만 상관계수 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 스피어만 상관계수로 상관관계를 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출한 후 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.09807947297621517, pvalue=0.03929011358104615)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scipy.stats.spearmanr\n",
    "from scipy.stats import spearmanr\n",
    "spearmanr(a = data['sex'], b = data['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.098079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex       bmi\n",
       "sex  1.000000  0.098079\n",
       "bmi  0.098079  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관계수\n",
    "data[['sex', 'bmi']].corr(method = 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "켄달의 타우 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 두 개의 등수 데이터를 임의로 생성하고 두 순위 간 상관관계가 있는지 검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=-0.29814239699997197, pvalue=0.4205962375999266)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요 패키지 호출\n",
    "import numpy as np\n",
    "\n",
    "# 두 개의 등수 데이터 임의로 생성\n",
    "x = np.array([5, 4, 3, 6, 1, 2])\n",
    "y = np.array([1, 5, 2, 2, 2, 6])\n",
    "\n",
    "# 켄달의 타우 검정 실시\n",
    "from scipy.stats import kendalltau\n",
    "kendalltau(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2장. 통계 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1절. 선형 회귀모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. diabetes 데이터에서 'bmi' 컬럼을 독립변수로 설정하고, 'target' 변수를 종속변수로 설정하여 선형 회귀분석을 실시해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출한 후 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'target' 컬럼 호출\n",
    "target = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinregressResult(slope=949.4352603840383, intercept=152.13348416289617, rvalue=0.5864501344746885, pvalue=3.4660064451673995e-42, stderr=62.51512200285265, intercept_stderr=2.973541118790735)\n"
     ]
    }
   ],
   "source": [
    "# 단순 선형회귀 모델 생성\n",
    "from scipy.stats import linregress\n",
    "\n",
    "model = linregress(x = data['bmi'], y = target)\n",
    "print(model) # 전체 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949.4352603840383\n"
     ]
    }
   ],
   "source": [
    "# 독립변수에 대한 추정된 회귀계수(beta1)\n",
    "print(model.slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.13348416289617\n"
     ]
    }
   ],
   "source": [
    "# 상수항에 대한 추정된 회귀계수(beta0)\n",
    "print(model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target = 152.13 + 949.44 * bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4660064451673995e-42\n"
     ]
    }
   ],
   "source": [
    "# beta1에 대한 통계적 유의성(p-value)\n",
    "print(model.pvalue) # p-value가 매우 작기 때문에 통계적으로 유의함(대립가설 : 회귀계수는 0이 아니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5864501344746885\n"
     ]
    }
   ],
   "source": [
    "# 결정계수(모형의 설명력)\n",
    "print(model.rvalue) # 현 데이터의 약 58.75%를 설명할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. tips 데이터를 불러와 총액(total_bill)과 사람 수(size)를 독립변수로 하고, 팁(tip)을 종속변수로 하는 다중 선형 회귀분석을 수행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요 데이터 호출\n",
    "import pandas as pd\n",
    "tips = pd.read_csv('./data/tips.csv')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수(total_bill, size)와 종속변수 지정\n",
    "X = tips[['total_bill', 'size']] # 독립변수\n",
    "y = tips['tip'] # 종속변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 상수항 추가\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 선형 회귀분석 수행\n",
    "# OLS 객체 생성 후 적합\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    tip   R-squared:                       0.468\n",
      "Model:                            OLS   Adj. R-squared:                  0.463\n",
      "Method:                 Least Squares   F-statistic:                     105.9\n",
      "Date:                Thu, 06 Jun 2024   Prob (F-statistic):           9.67e-34\n",
      "Time:                        23:26:46   Log-Likelihood:                -347.99\n",
      "No. Observations:                 244   AIC:                             702.0\n",
      "Df Residuals:                     241   BIC:                             712.5\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6689      0.194      3.455      0.001       0.288       1.050\n",
      "total_bill     0.0927      0.009     10.172      0.000       0.075       0.111\n",
      "size           0.1926      0.085      2.258      0.025       0.025       0.361\n",
      "==============================================================================\n",
      "Omnibus:                       24.753   Durbin-Watson:                   2.100\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.169\n",
      "Skew:                           0.545   Prob(JB):                     9.43e-11\n",
      "Kurtosis:                       4.831   Cond. No.                         67.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) # 회귀분석 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const          1.00\n",
      "total_bill    24.59\n",
      "size           4.00\n",
      "Name: 4, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None    3.719157\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5번째 관측치에 대한 tip의 기댓값을 추정\n",
    "print(X.iloc[4])\n",
    "model.predict(X.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.regression._prediction.PredictionResults object at 0x0000025D759C1700>\n"
     ]
    }
   ],
   "source": [
    "# 새로운 독립변수의 배열을 입력 값으로 지정\n",
    "new_data = pd.DataFrame({'const' : [1], 'total_bill' : [24.59], 'size' : [4]})\n",
    "\n",
    "# 예측 기댓값 결과 얻기\n",
    "result = model.get_prediction(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2절. 로지스틱 회귀모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. survived 데이터를 불러와 객실등급(pclass)을 독립변수로 하고, 생존여부(survived)를 종속변수로 하는 로지스틱 회귀분석을 수행해보자. (객실등급은 A등급인 경우 1, B등급인 경우는 0으로 인코딩 되어있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex   age\n",
       "0         0       0    1  22.0\n",
       "1         1       1    0  38.0\n",
       "2         1       0    0  26.0\n",
       "3         1       1    0  35.0\n",
       "4         0       0    1  35.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 데이터 호출\n",
    "import pandas as pd\n",
    "survived = pd.read_csv('./data/survived.csv')\n",
    "survived.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 독립변수와 종속변수 지정\n",
    "X = survived['pclass'] # 독립변수\n",
    "y = survived['survived'] # 종속변수\n",
    "\n",
    "# 상수항 추가\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                  541\n",
      "Model:                            GLM   Df Residuals:                      539\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -315.13\n",
      "Date:                Thu, 06 Jun 2024   Deviance:                       630.26\n",
      "Time:                        23:51:07   Pearson chi2:                     541.\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):             0.1527\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.1558      0.124     -9.293      0.000      -1.400      -0.912\n",
      "pclass         1.8009      0.198      9.086      0.000       1.412       2.189\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀분석\n",
    "# GLM객체 생성 후 적합\n",
    "model = sm.GLM(y, X, family = sm.families.Binomial()).fit()\n",
    "print(model.summary()) # 분석결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2394312844887346 0.6559054109099537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A등급의 추정 생존확률\n",
    "Prob_A = np.exp(-1.1558 + 0*1.8009) / (1 + np.exp(-1.1558 + 0*1.8009))\n",
    "\n",
    "# B등급의 추정 생존확률\n",
    "Prob_B = np.exp(-1.1558 + 1*1.8009) / (1 + np.exp(-1.1558 + 1*1.8009))\n",
    "\n",
    "print(Prob_A, Prob_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630.2646521014274\n",
      "719.8918959915944\n",
      "89.62724389016705 1\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#### 모형 적합도 검정\n",
    "# 적합모형의 이탈도\n",
    "dev = model.deviance\n",
    "print(dev)\n",
    "\n",
    "# 영모형의 이탈도\n",
    "dev0 = model.null_deviance\n",
    "print(dev0)\n",
    "\n",
    "# 카이제곱통계량과 자유도\n",
    "stat = dev0 - dev\n",
    "df = 2 - 1 # 적합모형의 회귀계수의 수 - 영모형의 회귀계수의 수\n",
    "print(stat, df)\n",
    "\n",
    "from scipy.stats import chi2\n",
    "pval = 1 - chi2.cdf(stat, df) # 유의확률\n",
    "print(pval) # 모형이 잘 적합하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업형3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3절 선형 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 선형 회귀모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. diabetes 데이터에서 'bmi', 'bp', 's1', 's2', 's3' 컬럼을 독립변수로 설정하고, 'target' 변수를 종속변수로 설정하여 선형 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출한 후 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnm = ['bmi', 'bp', 's1', 's2', 's3'] #컬럼명 리스트\n",
    "X = data[colnm]\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 객체 생성\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형회귀 적합\n",
    "model.fit(X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 608.94692667  301.1268683   990.86452444 -938.97359917 -597.46181621]\n"
     ]
    }
   ],
   "source": [
    "# 독립변수들에 대한 추정 회귀 계수들\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.13348416289614\n"
     ]
    }
   ],
   "source": [
    "# 절편항에 대한 추정 회귀 계수\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4772123190202695"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결정계수\n",
    "model.score(X = X, y = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "릿지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출한 후 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnm = ['bmi', 'bp', 's1', 's2', 's3'] #컬럼명 리스트\n",
    "X = data[colnm]\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 객체 생성\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형회귀 적합\n",
    "model.fit(X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 595.99425538  339.08790294  397.33725338 -338.99514707 -406.34548455]\n"
     ]
    }
   ],
   "source": [
    "# 독립변수들에 대한 추정 회귀 계수들\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.1334841628961\n"
     ]
    }
   ],
   "source": [
    "# 절편항에 대한 추정 회귀 계수\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Rabbit_Five.csv는 신약 개발을 위해 실험에 사용된 데이터이다. 데이터를 이용하여 실험군(MDL)과 대조군(Control) 간 혈압 변화(BPchange)가 차이가 있는 지를 대응표본 t-검정(paired t-test)를 통해 답하고자 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BP_change</th>\n",
       "      <th>Dose</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>lbl_Animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BP_change    Dose Treatment lbl_Animal\n",
       "0        0.5    6.25   Control         R1\n",
       "1        4.5   12.50   Control         R1\n",
       "2       10.0   25.00   Control         R1\n",
       "3       26.0   50.00   Control         R1\n",
       "4       37.0  100.00   Control         R1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Rabbit_Five = pd.read_csv('./data/Rabbit_Five.csv')\n",
    "Rabbit_Five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼 각각 할당\n",
    "BP_change = Rabbit_Five['BP_change']\n",
    "Treatment = Rabbit_Five['Treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment가 Control인 경우(대조군)과 MDL인 경우(실험군)의 BP_change 값 각각 할당\n",
    "BPC_Treat = BP_change[Treatment == 'MDL'].reset_index(drop = True)\n",
    "BPC_Control = BP_change[Treatment == 'Control'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.68\n"
     ]
    }
   ],
   "source": [
    "# 점추정량 = mean(PC_Treat, PC_Control)\n",
    "diff_avg = (BPC_Treat - BPC_Control).mean()\n",
    "diff_avg = round(diff_avg, 2)\n",
    "print(diff_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대응표본 t검정 수행\n",
    "from scipy.stats import ttest_rel\n",
    "a = ttest_rel(BPC_Treat, BPC_Control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.67\n"
     ]
    }
   ],
   "source": [
    "# 검정통계량\n",
    "stat = a.statistic\n",
    "stat = round(stat, 2)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "# p-값/기각여부\n",
    "pval = a.pvalue\n",
    "pval = round(pval, 3)\n",
    "print(pval)\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. mtcars2.csv를 통해 변속기 종류(am)에 따라 마력(hp)에 대한 분산이 차이가 있는 지를 분산비 검정(F test to compare two variances)를 통해 답하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  18.7    8    NaN  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mtcars2 = pd.read_csv('./data/mtcars2.csv', encoding = 'cp949')\n",
    "mtcars2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼 각각 할당\n",
    "am = mtcars2['am']\n",
    "hp = mtcars2['hp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동변속기(am=1)인 자동차의 마력(hp), 자동변속기(am=0)인 자동차의 마력(hp) 각각 할당\n",
    "hp_manual = hp[am==1].reset_index(drop = True)\n",
    "hp_auto = hp[am==0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.43\n"
     ]
    }
   ],
   "source": [
    "# 수동변속 표본분산/자동변속 표본분산\n",
    "var_ratio = hp_manual.var() / hp_auto.var()\n",
    "print(round(var_ratio, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.431605932653339\n"
     ]
    }
   ],
   "source": [
    "# F검정\n",
    "stat = var_ratio\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자유도\n",
    "df1, df2 = len(hp_manual) - 1, len(hp_auto) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "# F분포로 확률 계산\n",
    "pval = 1 - f.cdf(stat, dfn = df1, dfd = df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.43\n",
      "2.43\n",
      "0.043\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(round(var_ratio, 2))\n",
    "print(round(stat, 2))\n",
    "print(round(pval, 3))\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. 고객_등급리스트.csv를 통해 고객군(Segment)과 지역(Region)간 관련이 있는지를 독립성 검정(Test of independence)을 통해 답하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>6*</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>South</td>\n",
       "      <td>Consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>3*</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>6*</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>Consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>2*</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>Consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10480</td>\n",
       "      <td>Andrew Allen</td>\n",
       "      <td>5*</td>\n",
       "      <td>Concord</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>South</td>\n",
       "      <td>Consumer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID     ID             Name Age             City           State  \\\n",
       "0          NaN  12520      Claire Gute  6*        Henderson        Kentucky   \n",
       "1          NaN  13045  Darrin Van Huff  3*      Los Angeles      California   \n",
       "2          NaN  20335   Sean O'Donnell  6*  Fort Lauderdale         Florida   \n",
       "3          NaN  11710  Brosina Hoffman  2*      Los Angeles      California   \n",
       "4          NaN  10480     Andrew Allen  5*          Concord  North Carolina   \n",
       "\n",
       "  Region    Segment  \n",
       "0  South   Consumer  \n",
       "1   West  Corporate  \n",
       "2  South   Consumer  \n",
       "3   West   Consumer  \n",
       "4  South   Consumer  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customer = pd.read_csv('./data/고객_등급리스트.csv')\n",
    "customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차표 생성\n",
    "tb = pd.crosstab(customer['Segment'], customer['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카이제곱 검정\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, pval, df, expected = chi2_contingency(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.74\n"
     ]
    }
   ],
   "source": [
    "# E23 : expected의 (1,2) 인덱스 번호 추출\n",
    "e23 = expected[1, 2] \n",
    "e23 = round(e23, 2)\n",
    "print(e23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 검정통계량\n",
    "chi2 = chi2.astype('int')\n",
    "print(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.148\n",
      "채택\n"
     ]
    }
   ],
   "source": [
    "# p-값/기각 여부\n",
    "pval = round(pval, 3)\n",
    "print(pval)\n",
    "print('채택')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04. Cars93.csv를 통해 가격(Price)이 정규 분포를 따르는 지를 샤피로-윌크(Shapiro Wilk Test)를 통해 답하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼 할당\n",
    "Price = Cars93['Price'].copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.05\n"
     ]
    }
   ],
   "source": [
    "# 표본평균\n",
    "avg = Price.mean()\n",
    "avg = round(avg, 2)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# 샤피로 윌크 검정 수행\n",
    "from scipy.stats import shapiro\n",
    "stat, pval = shapiro(Price)\n",
    "\n",
    "# 검정통계량\n",
    "stat = round(stat, 2)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "# p-값/기각 여부\n",
    "pval = round(pval, 4)\n",
    "pval = int(pval)\n",
    "print(pval)\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05. Cars93.csv를 통해 마일당엔진회전수(Rev_per_mile)과 마력(Horsepower)과의 상관관계를 알아보고 상관계수의 유의성을 피어슨 상관계수 검정(Pearson`s Correlation Coefficient Test)를 통해 답하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관분석에 필요한 컬럼명 저장\n",
    "RPM = Cars93['Rev_per_mile']\n",
    "Horsepower = Cars93['Horsepower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관계수 검정\n",
    "from scipy.stats import pearsonr\n",
    "rho, pval = pearsonr(Horsepower, RPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.502\n"
     ]
    }
   ],
   "source": [
    "# 표본상관계수\n",
    "rho = round(rho, 3)\n",
    "print(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.54\n"
     ]
    }
   ],
   "source": [
    "# 검정통계량\n",
    "stat = rho / np.sqrt((1-rho**2)/(len(Horsepower)-2))\n",
    "stat = round(stat, 2)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "# p-값/기각 여부\n",
    "pval = int(pval)\n",
    "print(pval)\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06. USArrests.csv는 미국 50개 주의 범죄와 체포와 관련된 데이터이다. 차원 축소를 주성분 분석을 통해 수행하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Murder</th>\n",
       "      <th>Assault</th>\n",
       "      <th>UrbanPop</th>\n",
       "      <th>Rape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.2</td>\n",
       "      <td>236</td>\n",
       "      <td>58</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>263</td>\n",
       "      <td>48</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>294</td>\n",
       "      <td>80</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.8</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>276</td>\n",
       "      <td>91</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Murder  Assault  UrbanPop  Rape\n",
       "0    13.2      236        58  21.2\n",
       "1    10.0      263        48  44.5\n",
       "2     8.1      294        80  31.0\n",
       "3     8.8      190        50  19.5\n",
       "4     9.0      276        91  40.6"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "USArrests = pd.read_csv('./data/USArrests.csv')\n",
    "USArrests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.48021637e+01, -1.14480074e+01, -2.49493284e+00,\n",
       "         2.40790093e+00],\n",
       "       [ 9.28274502e+01, -1.79829427e+01,  2.01265749e+01,\n",
       "        -4.09404703e+00],\n",
       "       [ 1.24068216e+02,  8.83040304e+00, -1.68744836e+00,\n",
       "        -4.35368520e+00],\n",
       "       [ 1.83400354e+01, -1.67039114e+01,  2.10189364e-01,\n",
       "        -5.20993604e-01],\n",
       "       [ 1.07422953e+02,  2.25200698e+01,  6.74587299e+00,\n",
       "        -2.81182590e+00],\n",
       "       [ 3.49759860e+01,  1.37195840e+01,  1.22793628e+01,\n",
       "        -1.72146370e+00],\n",
       "       [-6.08872819e+01,  1.29325302e+01, -8.42065719e+00,\n",
       "        -6.99902287e-01],\n",
       "       [ 6.67310254e+01,  1.35379780e+00, -1.12809573e+01,\n",
       "        -3.72798119e+00],\n",
       "       [ 1.65244370e+02,  6.27469007e+00, -2.99793315e+00,\n",
       "         1.24768071e+00],\n",
       "       [ 4.05351766e+01, -7.29023959e+00,  3.60952946e+00,\n",
       "         7.34367284e+00],\n",
       "       [-1.23536106e+02,  2.42912079e+01,  3.72444284e+00,\n",
       "         3.47284940e+00],\n",
       "       [-5.17970023e+01, -9.46919099e+00, -1.52006356e+00,\n",
       "        -3.34782833e+00],\n",
       "       [ 7.89920973e+01,  1.28970605e+01, -5.88326477e+00,\n",
       "         3.67640738e-01],\n",
       "       [-5.75509607e+01,  2.84626471e+00,  3.73816049e+00,\n",
       "         1.64943016e+00],\n",
       "       [-1.15586790e+02, -3.34213050e+00, -6.54029354e-01,\n",
       "        -8.69495984e-01],\n",
       "       [-5.57896941e+01,  3.15723392e+00,  3.84364163e-01,\n",
       "         6.52791690e-01],\n",
       "       [-6.23831806e+01, -1.06732715e+01,  2.23708903e+00,\n",
       "         3.87621641e+00],\n",
       "       [ 7.82776313e+01, -4.29491750e+00, -3.82786965e+00,\n",
       "         4.48355900e+00],\n",
       "       [-8.92610443e+01, -1.14878272e+01, -4.69240562e+00,\n",
       "        -2.11619948e+00],\n",
       "       [ 1.29330136e+02, -5.00703148e+00, -2.34717282e+00,\n",
       "        -1.92832425e+00],\n",
       "       [-2.12662826e+01,  1.94501790e+01, -7.50714835e+00,\n",
       "        -1.03481895e+00],\n",
       "       [ 8.54515267e+01,  5.90455670e+00,  6.46434210e+00,\n",
       "         4.99047890e-01],\n",
       "       [-9.89548155e+01,  5.20960058e+00,  6.57375986e-03,\n",
       "        -7.31895664e-01],\n",
       "       [ 8.68563577e+01, -2.74284196e+01, -5.00343624e+00,\n",
       "         3.87975769e+00],\n",
       "       [ 7.98628867e+00,  5.27564140e+00,  5.50057972e+00,\n",
       "         6.79405505e-01],\n",
       "       [-6.24836353e+01, -9.51050205e+00,  1.83835536e+00,\n",
       "         2.45942647e-01],\n",
       "       [-6.90965444e+01, -2.11195917e-01,  4.68020859e-01,\n",
       "        -6.56566427e-01],\n",
       "       [ 8.36135784e+01,  1.51021839e+01,  1.58886948e+01,\n",
       "         3.34196244e-01],\n",
       "       [-1.14777355e+02, -4.73455836e+00, -2.28238693e+00,\n",
       "        -9.35910563e-01],\n",
       "       [-1.08157251e+01,  2.31373389e+01, -6.31015739e+00,\n",
       "         1.61242729e+00],\n",
       "       [ 1.14868163e+02, -3.36453098e-01,  2.26126996e+00,\n",
       "        -1.38124776e+00],\n",
       "       [ 8.42942305e+01,  1.59239655e+01, -4.72125960e+00,\n",
       "         8.92019350e-01],\n",
       "       [ 1.64325514e+02, -3.10966153e+01, -1.16961635e+01,\n",
       "        -2.11119273e+00],\n",
       "       [-1.27495597e+02, -1.61350394e+01, -1.31182982e+00,\n",
       "        -2.30096392e+00],\n",
       "       [-5.00868217e+01,  1.22793244e+01,  1.65733077e+00,\n",
       "         2.02911567e+00],\n",
       "       [-1.96937229e+01,  3.37013102e+00, -4.53143295e-01,\n",
       "        -1.80345739e-01],\n",
       "       [-1.11502396e+01,  3.86606815e+00,  8.12998050e+00,\n",
       "        -2.91401089e+00],\n",
       "       [-6.46891419e+01,  8.91154655e+00, -3.20646858e+00,\n",
       "         1.87493531e+00],\n",
       "       [ 3.06397257e+00,  1.83739704e+01, -1.74700197e+01,\n",
       "        -2.30825968e+00],\n",
       "       [ 1.07281069e+02, -2.35361159e+01, -2.03279501e+00,\n",
       "         1.25174626e+00],\n",
       "       [-8.61067201e+01, -1.65978586e+01,  1.31437998e+00,\n",
       "        -1.25228739e+00],\n",
       "       [ 1.75062643e+01, -6.50657560e+00,  6.10012753e+00,\n",
       "         3.92285575e+00],\n",
       "       [ 3.12911217e+01,  1.29849566e+01, -3.93409218e-01,\n",
       "         4.24200405e+00],\n",
       "       [-4.99133974e+01,  1.76484577e+01,  1.78816852e+00,\n",
       "        -1.86770524e+00],\n",
       "       [-1.24714469e+02, -2.73135591e+01,  4.80277765e+00,\n",
       "        -2.00498568e+00],\n",
       "       [-1.48174482e+01, -1.75261502e+00,  1.04538813e+00,\n",
       "         1.17384083e+00],\n",
       "       [-2.50758390e+01,  9.96796691e+00,  4.78112764e+00,\n",
       "        -2.69108186e+00],\n",
       "       [-9.15446470e+01, -2.29528778e+01, -4.01983435e-01,\n",
       "         7.36878098e-01],\n",
       "       [-1.18176328e+02,  5.50757920e+00, -2.71132077e+00,\n",
       "         2.04972398e-01],\n",
       "       [-1.04345394e+01, -5.92445292e+00, -3.79444682e+00,\n",
       "        -5.17867428e-01]])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca 수행\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 4) # 주성분 객체 생성\n",
    "pca.fit_transform(USArrests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 주성분의 폭력범죄 기여 가중치\n",
    "# pca.components_.T에서 행은 기존 컬럼(Merder, Assault, UrbanPop, Rape)\n",
    "# 열은 1~4 주성분\n",
    "weight = pca.components_.T[1, 0]\n",
    "weight = round(weight, 3)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-127.496\n"
     ]
    }
   ],
   "source": [
    "# 34번째 도시의 1주성분의 주성분 점수\n",
    "score = pca.fit_transform(USArrests)[33, 0]\n",
    "score = round(score, 3)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 주성분별 설명되는 분산 비율을 시리즈 객체로 저장\n",
    "var_ratio = pd.Series(pca.explained_variance_ratio_)\n",
    "result = round(var_ratio[0], 2)\n",
    "print(result)\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07. Cars93.csv를 통해 마일당엔진회전수(Rev_per_mile), 중량(Weight), 길이(Length), 엔진크기(EngineSize)를 입력하면 중간가격(Price)을 예측하는 다중 선형 회귀 분석을 하고자 한다. (단, 별도의 규제화는 진행하지 않으며, 결측치가 있을 경우 해당 컬럼들의 결측치는 모두 제거함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀분석 수행\n",
    "# 회귀분석에 필요한 컬럼 별도 지정\n",
    "col = ['Price', 'Rev_per_mile', 'Weight', 'Length', 'EngineSize']\n",
    "samp = Cars93[col].dropna() # 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# y, X에 각각 할당\n",
    "y = samp['Price']\n",
    "X = samp[['Rev_per_mile', 'Weight', 'Length', 'EngineSize']]\n",
    "X = sm.add_constant(X) # 절편항 적합을 위해 상수벡터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 적합\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit() # fit메소드를 통해 모형 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 16 Jun 2024</td> <th>  Prob (F-statistic):</th> <td>3.69e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:51:15</td>     <th>  Log-Likelihood:    </th> <td> -288.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    84</td>      <th>  AIC:               </th> <td>   586.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    79</td>      <th>  BIC:               </th> <td>   598.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   -2.6152</td> <td>   17.252</td> <td>   -0.152</td> <td> 0.880</td> <td>  -36.954</td> <td>   31.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rev_per_mile</th> <td>    0.0016</td> <td>    0.002</td> <td>    0.844</td> <td> 0.401</td> <td>   -0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weight</th>       <td>    0.0023</td> <td>    0.002</td> <td>    1.427</td> <td> 0.158</td> <td>   -0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Length</th>       <td>   -0.0210</td> <td>    0.104</td> <td>   -0.203</td> <td> 0.840</td> <td>   -0.227</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EngineSize</th>   <td>    5.7126</td> <td>    1.479</td> <td>    3.861</td> <td> 0.000</td> <td>    2.768</td> <td>    8.657</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>54.602</td> <th>  Durbin-Watson:     </th> <td>   1.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 252.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.010</td> <th>  Prob(JB):          </th> <td>1.41e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.485</td> <th>  Cond. No.          </th> <td>7.98e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.98e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Price       & \\textbf{  R-squared:         } &     0.396   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.366   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     12.96   \\\\\n",
       "\\textbf{Date:}             & Sun, 16 Jun 2024 & \\textbf{  Prob (F-statistic):} &  3.69e-08   \\\\\n",
       "\\textbf{Time:}             &     12:51:15     & \\textbf{  Log-Likelihood:    } &   -288.33   \\\\\n",
       "\\textbf{No. Observations:} &          84      & \\textbf{  AIC:               } &     586.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          79      & \\textbf{  BIC:               } &     598.8   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}          &      -2.6152  &       17.252     &    -0.152  &         0.880        &      -36.954    &       31.724     \\\\\n",
       "\\textbf{Rev\\_per\\_mile} &       0.0016  &        0.002     &     0.844  &         0.401        &       -0.002    &        0.005     \\\\\n",
       "\\textbf{Weight}         &       0.0023  &        0.002     &     1.427  &         0.158        &       -0.001    &        0.005     \\\\\n",
       "\\textbf{Length}         &      -0.0210  &        0.104     &    -0.203  &         0.840        &       -0.227    &        0.185     \\\\\n",
       "\\textbf{EngineSize}     &       5.7126  &        1.479     &     3.861  &         0.000        &        2.768    &        8.657     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 54.602 & \\textbf{  Durbin-Watson:     } &    1.203  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  252.601  \\\\\n",
       "\\textbf{Skew:}          &  2.010 & \\textbf{  Prob(JB):          } & 1.41e-55  \\\\\n",
       "\\textbf{Kurtosis:}      & 10.485 & \\textbf{  Cond. No.          } & 7.98e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 7.98e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.396\n",
       "Model:                            OLS   Adj. R-squared:                  0.366\n",
       "Method:                 Least Squares   F-statistic:                     12.96\n",
       "Date:                Sun, 16 Jun 2024   Prob (F-statistic):           3.69e-08\n",
       "Time:                        12:51:15   Log-Likelihood:                -288.33\n",
       "No. Observations:                  84   AIC:                             586.7\n",
       "Df Residuals:                      79   BIC:                             598.8\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           -2.6152     17.252     -0.152      0.880     -36.954      31.724\n",
       "Rev_per_mile     0.0016      0.002      0.844      0.401      -0.002       0.005\n",
       "Weight           0.0023      0.002      1.427      0.158      -0.001       0.005\n",
       "Length          -0.0210      0.104     -0.203      0.840      -0.227       0.185\n",
       "EngineSize       5.7126      1.479      3.861      0.000       2.768       8.657\n",
       "==============================================================================\n",
       "Omnibus:                       54.602   Durbin-Watson:                   1.203\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              252.601\n",
       "Skew:                           2.010   Prob(JB):                     1.41e-55\n",
       "Kurtosis:                      10.485   Cond. No.                     7.98e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.98e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396\n"
     ]
    }
   ],
   "source": [
    "# 결정 계수\n",
    "r_square = 0.396 \n",
    "print(r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023\n"
     ]
    }
   ],
   "source": [
    "# Weight의 추정 회귀계수\n",
    "b = 0.0023\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158\n"
     ]
    }
   ],
   "source": [
    "# Weight의 P > |t|을 통해 회귀계수 검정\n",
    "pval = 0.158\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-36.954452</td>\n",
       "      <td>31.723953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev_per_mile</th>\n",
       "      <td>-0.002173</td>\n",
       "      <td>0.005371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>-0.227167</td>\n",
       "      <td>0.185163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EngineSize</th>\n",
       "      <td>2.767785</td>\n",
       "      <td>8.657369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0          1\n",
       "const        -36.954452  31.723953\n",
       "Rev_per_mile  -0.002173   0.005371\n",
       "Weight        -0.000892   0.005406\n",
       "Length        -0.227167   0.185163\n",
       "EngineSize     2.767785   8.657369"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weight의 회귀계수에 대한 95% 신뢰구간\n",
    "result.conf_int(alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0054\n"
     ]
    }
   ],
   "source": [
    "upper = 0.005406\n",
    "upper = round(upper, 4)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08. job.csv는 취업 현황 분석을 위해 사용된 데이터의 일부이다. 여러 특성(x1, x2, x3)을 통해 취업 성공(y) 여부를 예측하는 로지스틱 회귀 분석을 하고자 한다. (x2 컬럼은 성별에 대한 정보로, 모형 적합 시 남자(M)을 1로, 여자(F)을 0으로 인코딩하여 분석하되, 별도의 규제화는 진행하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7759</td>\n",
       "      <td>M</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9397</td>\n",
       "      <td>M</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2241</td>\n",
       "      <td>M</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7759</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7759</td>\n",
       "      <td>M</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1 x2      x3  y\n",
       "0  0.7759  M  0.9167  0\n",
       "1  0.9397  M  0.1167  0\n",
       "2 -0.2241  M  0.3000  0\n",
       "3  0.7759  M  2.0333  0\n",
       "4  0.7759  M  0.5000  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "job = pd.read_csv('./data/job.csv')\n",
    "job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2컬럼 M -> 1, F -> 0\n",
    "job['x2'] = job['x2'].map({'M' : 1, 'F' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# y, X에 각각 할당\n",
    "y = job['y']\n",
    "X = job[['x1', 'x2', 'x3']]\n",
    "X = sm.add_constant(X) # 절편항 적합을 위해 상수벡터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 적합\n",
    "model = sm.GLM(y, X, family = sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -56.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 16 Jun 2024</td> <th>  Deviance:          </th> <td>  112.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:12:29</td>     <th>  Pearson chi2:      </th>  <td>  106.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.09941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.8077</td> <td>    0.696</td> <td>   -1.160</td> <td> 0.246</td> <td>   -2.173</td> <td>    0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.6233</td> <td>    0.198</td> <td>   -3.149</td> <td> 0.002</td> <td>   -1.011</td> <td>   -0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1575</td> <td>    0.684</td> <td>   -0.230</td> <td> 0.818</td> <td>   -1.498</td> <td>    1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.2153</td> <td>    0.309</td> <td>   -0.696</td> <td> 0.487</td> <td>   -0.822</td> <td>    0.391</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        y         & \\textbf{  No. Observations:  } &      105    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      101    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &        3    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -56.381   \\\\\n",
       "\\textbf{Date:}            & Sun, 16 Jun 2024 & \\textbf{  Deviance:          } &    112.76   \\\\\n",
       "\\textbf{Time:}            &     13:12:29     & \\textbf{  Pearson chi2:      } &     106.    \\\\\n",
       "\\textbf{No. Iterations:}  &        4         & \\textbf{  Pseudo R-squ. (CS):} &  0.09941    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.8077  &        0.696     &    -1.160  &         0.246        &       -2.173    &        0.557     \\\\\n",
       "\\textbf{x1}    &      -0.6233  &        0.198     &    -3.149  &         0.002        &       -1.011    &       -0.235     \\\\\n",
       "\\textbf{x2}    &      -0.1575  &        0.684     &    -0.230  &         0.818        &       -1.498    &        1.183     \\\\\n",
       "\\textbf{x3}    &      -0.2153  &        0.309     &    -0.696  &         0.487        &       -0.822    &        0.391     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  105\n",
       "Model:                            GLM   Df Residuals:                      101\n",
       "Model Family:                Binomial   Df Model:                            3\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -56.381\n",
       "Date:                Sun, 16 Jun 2024   Deviance:                       112.76\n",
       "Time:                        13:12:29   Pearson chi2:                     106.\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):            0.09941\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.8077      0.696     -1.160      0.246      -2.173       0.557\n",
       "x1            -0.6233      0.198     -3.149      0.002      -1.011      -0.235\n",
       "x2            -0.1575      0.684     -0.230      0.818      -1.498       1.183\n",
       "x3            -0.2153      0.309     -0.696      0.487      -0.822       0.391\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.808\n"
     ]
    }
   ],
   "source": [
    "# 절편항 추정 회귀계수\n",
    "b0 = -0.8077\n",
    "b0 = round(b0, 3)\n",
    "print(b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 여성에 비해 남성의 성공에 대한 오즈가 몇 배인지를 구하려면\n",
    "# 오즈비 = 남성의 성공 오즈 / 여성의 성공 오즈\n",
    "odds_ratio = round(np.exp(-0.1575), 3)\n",
    "print(odds_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5344\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 9번째 사람의 성공 예측 확률\n",
    "y_prob = round(result.predict(X)[8], 4)\n",
    "print(y_prob)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09. 영화_순위리스트.csv를 통해 장르별 예산의 평균에 차이가 있는 지를 분산분석(ANOVA)를 수행하기 전 등분산 검정(Homogeneity of Variance)인 Bartlett 검정을 수행하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번호</th>\n",
       "      <th>홍보비</th>\n",
       "      <th>제작비</th>\n",
       "      <th>예산</th>\n",
       "      <th>영화길이_분</th>\n",
       "      <th>남자_주연_배우_순위</th>\n",
       "      <th>여_주연_배우_순위</th>\n",
       "      <th>디렉터_순위</th>\n",
       "      <th>프로듀서_순위</th>\n",
       "      <th>비평가_순위</th>\n",
       "      <th>트레일러_뷰수</th>\n",
       "      <th>3D_가능여부</th>\n",
       "      <th>트위터_해시태그_수</th>\n",
       "      <th>장르</th>\n",
       "      <th>배우_평균_나이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20.1264</td>\n",
       "      <td>59.62</td>\n",
       "      <td>36524.125</td>\n",
       "      <td>138.7</td>\n",
       "      <td>7.825</td>\n",
       "      <td>8.095</td>\n",
       "      <td>7.910</td>\n",
       "      <td>7.995</td>\n",
       "      <td>7.94</td>\n",
       "      <td>527367</td>\n",
       "      <td>Y</td>\n",
       "      <td>223.840</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20.5462</td>\n",
       "      <td>69.14</td>\n",
       "      <td>35668.655</td>\n",
       "      <td>152.4</td>\n",
       "      <td>7.505</td>\n",
       "      <td>7.650</td>\n",
       "      <td>7.440</td>\n",
       "      <td>7.470</td>\n",
       "      <td>7.44</td>\n",
       "      <td>494055</td>\n",
       "      <td>N</td>\n",
       "      <td>243.456</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>20.5458</td>\n",
       "      <td>69.14</td>\n",
       "      <td>39912.675</td>\n",
       "      <td>134.6</td>\n",
       "      <td>7.485</td>\n",
       "      <td>7.570</td>\n",
       "      <td>7.495</td>\n",
       "      <td>7.515</td>\n",
       "      <td>7.44</td>\n",
       "      <td>547051</td>\n",
       "      <td>N</td>\n",
       "      <td>2022.400</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>20.6474</td>\n",
       "      <td>59.36</td>\n",
       "      <td>38873.890</td>\n",
       "      <td>119.3</td>\n",
       "      <td>6.895</td>\n",
       "      <td>7.035</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.020</td>\n",
       "      <td>8.26</td>\n",
       "      <td>516279</td>\n",
       "      <td>Y</td>\n",
       "      <td>225.344</td>\n",
       "      <td>Drama</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>21.3810</td>\n",
       "      <td>59.36</td>\n",
       "      <td>39701.585</td>\n",
       "      <td>127.7</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.070</td>\n",
       "      <td>6.815</td>\n",
       "      <td>7.070</td>\n",
       "      <td>8.26</td>\n",
       "      <td>531448</td>\n",
       "      <td>N</td>\n",
       "      <td>225.792</td>\n",
       "      <td>Drama</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   번호      홍보비    제작비         예산  영화길이_분  남자_주연_배우_순위  여_주연_배우_순위  디렉터_순위  \\\n",
       "0   2  20.1264  59.62  36524.125   138.7        7.825       8.095   7.910   \n",
       "1   3  20.5462  69.14  35668.655   152.4        7.505       7.650   7.440   \n",
       "2   4  20.5458  69.14  39912.675   134.6        7.485       7.570   7.495   \n",
       "3   5  20.6474  59.36  38873.890   119.3        6.895       7.035   6.920   \n",
       "4   6  21.3810  59.36  39701.585   127.7        6.920       7.070   6.815   \n",
       "\n",
       "   프로듀서_순위  비평가_순위  트레일러_뷰수 3D_가능여부  트위터_해시태그_수        장르  배우_평균_나이  \n",
       "0    7.995    7.94   527367       Y     223.840  Thriller        23  \n",
       "1    7.470    7.44   494055       N     243.456     Drama        42  \n",
       "2    7.515    7.44   547051       N    2022.400    Comedy        38  \n",
       "3    7.020    8.26   516279       Y     225.344     Drama        45  \n",
       "4    7.070    8.26   531448       N     225.792     Drama        55  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movie = pd.read_csv('./data/영화_순위리스트.csv', encoding = 'cp949')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼 각각 할당\n",
    "genre = movie['장르']\n",
    "budget = movie['예산']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Thriller', 'Drama', 'Comedy', 'Action'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 장르 unique 확인\n",
    "genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장르별 예산 값 할당\n",
    "budget_thriller = budget[genre == 'Thriller']\n",
    "budget_comedy = budget[genre == 'Comedy']\n",
    "budget_drama = budget[genre == 'Drama']\n",
    "budget_action = budget[genre == 'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.757 15.048 14.955 14.374]\n"
     ]
    }
   ],
   "source": [
    "# 합동분산\n",
    "\n",
    "# 집단별 표본 분산\n",
    "var_i = [budget_thriller.var(), budget_comedy.var(), budget_drama.var(), budget_action.var()]\n",
    "\n",
    "# 집단별 관측치 수\n",
    "n_i = [len(budget_thriller), len(budget_comedy), len(budget_drama), len(budget_action)]\n",
    "\n",
    "N = sum(n_i)\n",
    "k = 4 # 집단의 수\n",
    "\n",
    "import numpy as np\n",
    "log_sp2 = np.log((np.subtract(n_i, 1) * var_i) / (N-k))\n",
    "log_sp2 = np.round(log_sp2, 3)\n",
    "print(log_sp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bartlett Test 수행\n",
    "from scipy.stats import bartlett\n",
    "stat, pval = bartlett(budget_thriller, budget_comedy, budget_drama, budget_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.44\n"
     ]
    }
   ],
   "source": [
    "# 검정통계량\n",
    "stat = round(stat, 2)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "# p-값/기각여부\n",
    "pval = round(pval, 4)\n",
    "print(pval)\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모의고사 1회"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업형 - 제 1유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. 제공된 데이터(iris.csv)의 Sepal.Width 컬럼에 대해 Sepal.Width의 평균값을 기준으로 3배 표준편차 이상으로 떨어진 값들의 합을 구하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('./data/iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal_width 별도 저장\n",
    "sepal_width = iris['Sepal.Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sepal_width 평균 기준 3배 표준편차 이상 떨어진 데이터추출\n",
    "# sepal_width의 평균\n",
    "avg = sepal_width.mean()\n",
    "\n",
    "# sepal_width의 표준편차\n",
    "sd = sepal_width.std()\n",
    "\n",
    "# 상한과 하한\n",
    "upp = avg + 3 * sd\n",
    "low = avg - 3 * sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sepal_width 평균 기준 3배 표준편차 이상 벗어날 조건\n",
    "# 하한보다 작고 상한보다 큼\n",
    "cond = (sepal_width < low) | (sepal_width > upp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = sepal_width[cond].sum() # 떨어진 값들의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4\n"
     ]
    }
   ],
   "source": [
    "# 결과 추출\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. 제공된 데이터(mtcars1.csv)의 disp 컬럼에 대해서 순위를 부여한 후, 1위부터 20위까지의 값들의 표준편차를 구하고 소수점 셋째 자리에서 반올림하여 나타내어라. (단, 동점은 동일한 순위를 부여하되 상위 등수를 기준으로 하며 최댓값을 1위로 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mtcars1 = pd.read_csv('./data/mtcars1.csv')\n",
    "mtcars1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 컬럼 별도 저장\n",
    "disp = mtcars1['disp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 순위 부여\n",
    "rank = disp.rank(method = 'min', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1위부터 20위까지의 값\n",
    "rank20 = disp[rank <= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = round(rank20.std(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.47\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. 제공된 데이터(Cars93.csv)의 전체 레코드 수, 결측치가 있는 컬럼의 수, 전체 결측치 수, 결측치가 10개 이상인 컬럼들의 결측치가 있는 레코드만 삭제한 후의 전체 레코드의 수와 두 개 이상의 컬럼이 동시에 결측인 레코드의 행 번호들의 합을 구한 후 모두 합하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>MPG_city</th>\n",
       "      <th>MPG_highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn_circle</th>\n",
       "      <th>Rear_seat_room</th>\n",
       "      <th>Luggage_room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>0</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>71</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>1</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>32.3</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Driver &amp; Passenger</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>3</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>23.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>Driver only</td>\n",
       "      <td>Rear</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>4</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min_Price  Price  Max_Price  MPG_city  \\\n",
       "0        Acura  Integra    Small       12.9   15.9       18.8        25   \n",
       "1        Acura   Legend  Midsize       29.2   33.9       38.7        18   \n",
       "2         Audi       90  Compact       25.9   29.1       32.3        20   \n",
       "3         Audi      100  Midsize       30.8    NaN       44.6        19   \n",
       "4          BMW     535i  Midsize       23.7    NaN       36.2        22   \n",
       "\n",
       "   MPG_highway             AirBags DriveTrain  ... Length  Wheelbase  Width  \\\n",
       "0           31                 NaN      Front  ...    177        102     68   \n",
       "1           25  Driver & Passenger      Front  ...    195        115     71   \n",
       "2           26         Driver only      Front  ...    180        102     67   \n",
       "3           26  Driver & Passenger      Front  ...    193        106     70   \n",
       "4           30         Driver only       Rear  ...    186        109     69   \n",
       "\n",
       "   Turn_circle  Rear_seat_room Luggage_room  Weight   Origin  Unnamed: 26  \\\n",
       "0         37.0            26.5         11.0    2705  non-USA            0   \n",
       "1         38.0            30.0         15.0    3560  non-USA            1   \n",
       "2         37.0            28.0         14.0    3375  non-USA            2   \n",
       "3          NaN            31.0         17.0    3405  non-USA            3   \n",
       "4          NaN            27.0         13.0    3640  non-USA            4   \n",
       "\n",
       "            Make  \n",
       "0  Acura Integra  \n",
       "1   Acura Legend  \n",
       "2        Audi 90  \n",
       "3       Audi 100  \n",
       "4       BMW 535i  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Cars93 = pd.read_csv('./data/Cars93.csv')\n",
    "Cars93.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1. 전체 레코드 수\n",
    "case1 = Cars93.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case2. 결측치가 있는 컬럼의 수\n",
    "case2 = sum(Cars93.isna().sum() != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case3. 전체 결측치 수\n",
    "case3 = sum(Cars93.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case4. 결측치가 10개 이상인 컬럼들의 결측치가 있는 레코드만 삭제한 후의 전체 레코드의 수\n",
    "# 결측치의 수가 10개 이상인 컬럼명을 colnm_10over에 할당\n",
    "colnm_10over = Cars93.columns[Cars93.isna().sum() > 10]\n",
    "\n",
    "# 그 중에서 결측치가 없는 경우의 전체 레코드 수\n",
    "sub1 = Cars93[colnm_10over].copy()\n",
    "case4 = len(sub1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case5. 두 개 이상의 컬럼이 동시에 결측인 레코드의 행 번호들의 합\n",
    "# 결측치의 수가 2개 이상인 행 인덱스를 rownm_2over에 할당\n",
    "rownm_2over = Cars93.index[Cars93.isna().sum(axis = 1) >= 2]\n",
    "\n",
    "# 행 번호를 리스트로 반환한 후 합함\n",
    "sub2 = list(rownm_2over)\n",
    "case5 = sum(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당\n",
    "result = case1 + case2 + case3 + case4 + case5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업형 - 제 2유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉호의 탑승자들의 생존과 관련한 데이터이다. 주어진 데이터를 이용하여 예측 모형을 만들고 CSV 파일을 생성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv('./data/titanic3_X_train.csv')\n",
    "X_test = pd.read_csv('./data/titanic3_X_test.csv')\n",
    "y_train = pd.read_csv('./data/titanic3_y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  pclass      name   sex   age  sibsp  parch             ticket    fare  \\\n",
      "0   1       3  Sdy*****  male   NaN      0      0             349222  7.8958   \n",
      "1   2       3  Pel*****  male  25.0      0      0  STON/O 2. 3101291  7.9250   \n",
      "2   3       3  Kar*****  male  22.0      0      0             350060  7.5208   \n",
      "3   4       3  Saa*****  male   NaN      0      0               2676  7.2250   \n",
      "4   5       3  Cor*****  male  19.0      0      0             349231  7.8958   \n",
      "\n",
      "  cabin embarked  \n",
      "0   NaN        S  \n",
      "1   NaN        S  \n",
      "2   NaN        S  \n",
      "3   NaN        C  \n",
      "4   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  pclass      name     sex   age  sibsp  parch    ticket      fare  \\\n",
      "0  786       1  All*****  female   2.0      1      2    113781  151.5500   \n",
      "1  787       1  And*****    male  39.0      0      0    112050    0.0000   \n",
      "2  788       1  Bau*****    male   NaN      0      0  PC 17318   25.9250   \n",
      "3  789       1  Bax*****    male  24.0      0      1  PC 17558  247.5208   \n",
      "4  790       1  Bea*****    male  36.0      0      0     13050   75.2417   \n",
      "\n",
      "     cabin embarked  \n",
      "0  C22 C26        S  \n",
      "1      A36        S  \n",
      "2      NaN        S  \n",
      "3  B58 B60        C  \n",
      "4       C6        C  \n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  survived\n",
      "0   1         0\n",
      "1   2         0\n",
      "2   3         0\n",
      "3   4         0\n",
      "4   5         0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        785 non-null    int64  \n",
      " 1   pclass    785 non-null    int64  \n",
      " 2   name      785 non-null    object \n",
      " 3   sex       785 non-null    object \n",
      " 4   age       628 non-null    float64\n",
      " 5   sibsp     785 non-null    int64  \n",
      " 6   parch     785 non-null    int64  \n",
      " 7   ticket    785 non-null    object \n",
      " 8   fare      784 non-null    float64\n",
      " 9   cabin     171 non-null    object \n",
      " 10  embarked  784 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 67.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 요약 정보 확인\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 524 entries, 0 to 523\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        524 non-null    int64  \n",
      " 1   pclass    524 non-null    int64  \n",
      " 2   name      524 non-null    object \n",
      " 3   sex       524 non-null    object \n",
      " 4   age       418 non-null    float64\n",
      " 5   sibsp     524 non-null    int64  \n",
      " 6   parch     524 non-null    int64  \n",
      " 7   ticket    524 non-null    object \n",
      " 8   fare      524 non-null    float64\n",
      " 9   cabin     124 non-null    object \n",
      " 10  embarked  523 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 45.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 요약 정보 확인\n",
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   ID        785 non-null    int64\n",
      " 1   survived  785 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 12.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 요약 정보 확인\n",
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID      pclass         age       sibsp       parch        fare\n",
      "count  785.000000  785.000000  628.000000  785.000000  785.000000  784.000000\n",
      "mean   393.000000    2.296815   30.292994    0.501911    0.357962   33.454697\n",
      "std    226.754272    0.835929   14.660563    1.051146    0.781166   52.251342\n",
      "min      1.000000    1.000000    0.330000    0.000000    0.000000    0.000000\n",
      "25%    197.000000    2.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    393.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%    589.000000    3.000000   39.250000    1.000000    0.000000   30.771850\n",
      "max    785.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID      pclass         age       sibsp       parch       fare\n",
      "count   524.000000  524.000000  418.000000  524.000000  524.000000  524.00000\n",
      "mean   1047.500000    2.291985   29.262368    0.494275    0.425573   33.05726\n",
      "std     151.410039    0.841475   14.028790    1.028265    0.977859   51.06143\n",
      "min     786.000000    1.000000    0.170000    0.000000    0.000000    0.00000\n",
      "25%     916.750000    1.750000   21.000000    0.000000    0.000000    7.91770\n",
      "50%    1047.500000    3.000000   28.000000    0.000000    0.000000   14.45830\n",
      "75%    1178.250000    3.000000   37.750000    1.000000    0.000000   31.38750\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.32920\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID    survived\n",
      "count  785.000000  785.000000\n",
      "mean   393.000000    0.382166\n",
      "std    226.754272    0.486227\n",
      "min      1.000000    0.000000\n",
      "25%    197.000000    0.000000\n",
      "50%    393.000000    0.000000\n",
      "75%    589.000000    1.000000\n",
      "max    785.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "# 불필요한 컬럼 삭제\n",
    "# ID 컬럼은 탑승자에 대한 고유 정보로 key 역할로 모델에는 불필요함\n",
    "# 결과 제출 시에는 X_test의 ID 컬럼이 필요하기 때문에 별도 저장\n",
    "ID = X_test['ID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name은 텍스트 전처리 등의 방법으로 분석 가능하기도 하지만 편의상 제외\n",
    "# 데이터에서 ID, name 컬럼 삭제\n",
    "X_train = X_train.drop(columns = ['ID', 'name'])\n",
    "X_test = X_test.drop(columns = ['ID', 'name'])\n",
    "y_train = y_train.drop(columns = ['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         157\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          1\n",
       "cabin       614\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         106\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          0\n",
       "cabin       400\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age는 탑승자의 나이를 의미하고 survive와 상관관계가 낮으므로 컬럼을 삭제\n",
    "# 결측일 조건\n",
    "cond_na = X_train['age'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=-0.03894154189837852, pvalue=0.32990878593923834)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피어슨 상관계수\n",
    "from scipy.stats import pearsonr\n",
    "pearsonr(y_train['survived'][~cond_na], X_train['age'][~cond_na])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 컬럼 삭제\n",
    "X_train = X_train.drop('age', axis = 1)\n",
    "X_test = X_test.drop('age', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare는 티켓요금을 의미하고 train에만 결측치가 1개 존재하므로 레코드를 삭제함\n",
    "cond_na = X_train['fare'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 삭제\n",
    "X_train = X_train[~cond_na]\n",
    "y_train = y_train[~cond_na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabin은 선실번호를 의미하고 train은 레코드의 78%, test는 레코드의 76%가 결측이므로 컬럼을 삭제\n",
    "X_train = X_train.drop('cabin', axis = 1)\n",
    "X_test = X_test.drop('cabin', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked는 탑승한 곳을 의미하고 범주형으로 최다빈도를 가지는 범주로 대체함\n",
    "top = X_train['embarked'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대치\n",
    "X_train['embarked'] = X_train['embarked'].fillna(top)\n",
    "X_test['embarked'] = X_test['embarked'].fillna(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           3\n",
      "ticket      621\n",
      "embarked      3\n",
      "dtype: int64\n",
      "sex           3\n",
      "ticket      445\n",
      "embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 카테고리형 컬럼 전처리\n",
    "# 문자열(object) 컬럼들의 유일한 값 확인\n",
    "print(X_train.select_dtypes('object').nunique())\n",
    "print(X_test.select_dtypes('object').nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "male      517\n",
       "female    244\n",
       "F          23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여성에 대한 일부 카테고리가 'F'로 되어 있음\n",
    "X_train['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "male      325\n",
       "female    173\n",
       "F          26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여성에 대한 일부 카테고리가 'F'로 되어 있음\n",
    "X_test['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 모두 'F'를 'female'로 통일\n",
    "X_train['sex'] = X_train['sex'].map({'male' : 'male', 'female' : 'female', 'F' : 'female'})\n",
    "X_test['sex'] = X_test['sex'].map({'male' : 'male', 'female' : 'female', 'F' : 'female'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket 컬럼의 경우 대다수가 중복되지 않으므로 컬럼을 삭제하는 것으로 결정\n",
    "X_train = X_train.drop('ticket', axis = 1)\n",
    "X_test = X_test.drop('ticket', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제2회 기출문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP1. 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv('./data/stroke_X_train.csv')\n",
    "X_test = pd.read_csv('./data/stroke_X_test.csv')\n",
    "y_train = pd.read_csv('./data/stroke_y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>Urban</td>\n",
       "      <td>78.48</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126</td>\n",
       "      <td>Female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>82.72</td>\n",
       "      <td>29.8</td>\n",
       "      <td>smokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1125</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>119.62</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>67.92</td>\n",
       "      <td>31.1</td>\n",
       "      <td>formerly smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>948</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>146.44</td>\n",
       "      <td>22.8</td>\n",
       "      <td>formerly smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  gender   age  hypertension  heart_disease ever_married work_type  \\\n",
       "0   678    Male   8.0             0              0           No  children   \n",
       "1  1126  Female  65.0             0              0          Yes  Govt_job   \n",
       "2  1125  Female  79.0             1              0          Yes   Private   \n",
       "3  1016    Male  66.0             0              0          Yes   Private   \n",
       "4   948  Female  45.0             0              0          Yes   Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  \n",
       "0          Urban              78.48  16.1          Unknown  \n",
       "1          Urban              82.72  29.8           smokes  \n",
       "2          Rural             119.62  39.0          Unknown  \n",
       "3          Rural              67.92  31.1  formerly smoked  \n",
       "4          Urban             146.44  22.8  formerly smoked  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### STEP2. 데이터셋 확인하기\n",
    "###### STEP2-1. 데이터셋 일부 확인\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>119.03</td>\n",
       "      <td>31.0</td>\n",
       "      <td>never smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>101.19</td>\n",
       "      <td>29.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>182.52</td>\n",
       "      <td>30.1</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>80.21</td>\n",
       "      <td>27.8</td>\n",
       "      <td>formerly smoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>71.44</td>\n",
       "      <td>24.1</td>\n",
       "      <td>smokes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  gender   age  hypertension  heart_disease ever_married work_type  \\\n",
       "0   2  Female  78.0             0              0          Yes   Private   \n",
       "1   4  Female  59.0             0              0          Yes  Govt_job   \n",
       "2   5  Female  59.0             0              0          Yes   Private   \n",
       "3   6  Female  33.0             0              0           No   Private   \n",
       "4   8    Male  77.0             0              0          Yes   Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  \n",
       "0          Urban             119.03  31.0     never smoked  \n",
       "1          Urban             101.19  29.9  formerly smoked  \n",
       "2          Urban             182.52  30.1          Unknown  \n",
       "3          Rural              80.21  27.8  formerly smoked  \n",
       "4          Urban              71.44  24.1           smokes  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  stroke\n",
       "0   678       0\n",
       "1  1126       0\n",
       "2  1125       0\n",
       "3  1016       0\n",
       "4   948       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2399 entries, 0 to 2398\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 2399 non-null   int64  \n",
      " 1   gender             2399 non-null   object \n",
      " 2   age                2399 non-null   float64\n",
      " 3   hypertension       2399 non-null   int64  \n",
      " 4   heart_disease      2399 non-null   int64  \n",
      " 5   ever_married       2399 non-null   object \n",
      " 6   work_type          2399 non-null   object \n",
      " 7   Residence_type     2399 non-null   object \n",
      " 8   avg_glucose_level  2399 non-null   float64\n",
      " 9   bmi                2399 non-null   float64\n",
      " 10  smoking_status     2399 non-null   object \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 206.3+ KB\n"
     ]
    }
   ],
   "source": [
    "###### STEP2-2. 데이터셋 요약 정보 확인\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1601 entries, 0 to 1600\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 1601 non-null   int64  \n",
      " 1   gender             1601 non-null   object \n",
      " 2   age                1601 non-null   float64\n",
      " 3   hypertension       1601 non-null   int64  \n",
      " 4   heart_disease      1601 non-null   int64  \n",
      " 5   ever_married       1601 non-null   object \n",
      " 6   work_type          1601 non-null   object \n",
      " 7   Residence_type     1601 non-null   object \n",
      " 8   avg_glucose_level  1601 non-null   float64\n",
      " 9   bmi                1601 non-null   float64\n",
      " 10  smoking_status     1601 non-null   object \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 137.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2399 entries, 0 to 2398\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   id      2399 non-null   int64\n",
      " 1   stroke  2399 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 37.6 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2010.176323</td>\n",
       "      <td>60.180492</td>\n",
       "      <td>0.231346</td>\n",
       "      <td>0.154648</td>\n",
       "      <td>125.673135</td>\n",
       "      <td>30.187953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1162.012740</td>\n",
       "      <td>19.577115</td>\n",
       "      <td>0.421781</td>\n",
       "      <td>0.361644</td>\n",
       "      <td>59.512953</td>\n",
       "      <td>6.845468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>13.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>997.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.800000</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.540000</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3023.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.170000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>61.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id          age  hypertension  heart_disease  \\\n",
       "count  2399.000000  2399.000000   2399.000000    2399.000000   \n",
       "mean   2010.176323    60.180492      0.231346       0.154648   \n",
       "std    1162.012740    19.577115      0.421781       0.361644   \n",
       "min       1.000000     0.160000      0.000000       0.000000   \n",
       "25%     997.500000    51.000000      0.000000       0.000000   \n",
       "50%    1999.000000    65.000000      0.000000       0.000000   \n",
       "75%    3023.500000    77.000000      0.000000       0.000000   \n",
       "max    4000.000000    82.000000      1.000000       1.000000   \n",
       "\n",
       "       avg_glucose_level          bmi  \n",
       "count        2399.000000  2399.000000  \n",
       "mean          125.673135    30.187953  \n",
       "std            59.512953     6.845468  \n",
       "min            55.120000    13.800000  \n",
       "25%            78.800000    26.100000  \n",
       "50%           100.540000    29.500000  \n",
       "75%           185.170000    33.600000  \n",
       "max           271.740000    61.600000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP2-3. 기초통계량 확인\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1986.000625</td>\n",
       "      <td>60.909032</td>\n",
       "      <td>0.249219</td>\n",
       "      <td>0.148032</td>\n",
       "      <td>126.704941</td>\n",
       "      <td>30.053654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1144.228912</td>\n",
       "      <td>19.410576</td>\n",
       "      <td>0.432696</td>\n",
       "      <td>0.355243</td>\n",
       "      <td>58.661998</td>\n",
       "      <td>6.606219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.580000</td>\n",
       "      <td>10.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1005.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.080000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.060000</td>\n",
       "      <td>29.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2963.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.490000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3999.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id          age  hypertension  heart_disease  \\\n",
       "count  1601.000000  1601.000000   1601.000000    1601.000000   \n",
       "mean   1986.000625    60.909032      0.249219       0.148032   \n",
       "std    1144.228912    19.410576      0.432696       0.355243   \n",
       "min       2.000000     0.160000      0.000000       0.000000   \n",
       "25%    1005.000000    51.000000      0.000000       0.000000   \n",
       "50%    2007.000000    67.000000      0.000000       0.000000   \n",
       "75%    2963.000000    78.000000      0.000000       0.000000   \n",
       "max    3999.000000    82.000000      1.000000       1.000000   \n",
       "\n",
       "       avg_glucose_level          bmi  \n",
       "count        1601.000000  1601.000000  \n",
       "mean          126.704941    30.053654  \n",
       "std            58.661998     6.606219  \n",
       "min            55.580000    10.300000  \n",
       "25%            80.080000    26.000000  \n",
       "50%           103.060000    29.400000  \n",
       "75%           185.490000    33.600000  \n",
       "max           271.740000    97.600000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2010.176323</td>\n",
       "      <td>0.706961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1162.012740</td>\n",
       "      <td>0.455251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>997.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3023.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       stroke\n",
       "count  2399.000000  2399.000000\n",
       "mean   2010.176323     0.706961\n",
       "std    1162.012740     0.455251\n",
       "min       1.000000     0.000000\n",
       "25%     997.500000     0.000000\n",
       "50%    1999.000000     1.000000\n",
       "75%    3023.500000     1.000000\n",
       "max    4000.000000     1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP3. 데이터셋 전처리\n",
    "###### STEP3-1. 불필요한 컬럼 삭제\n",
    "# id컬럼은 환자에 대한 고유 정보로 key 역할로 모델에는 불필요함\n",
    "# 결과 제출 시에는 X_test의 id컬럼이 필요하기 때문에 별도 저장\n",
    "ID = X_test['id'].copy()\n",
    "\n",
    "# 데이터들에서 id컬럼 삭제\n",
    "X_train = X_train.drop(columns = 'id')\n",
    "X_test = X_test.drop(columns = 'id')\n",
    "y_train = y_train.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP3-2. 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking_status\n",
       "never smoked       957\n",
       "formerly smoked    548\n",
       "Unknown            458\n",
       "smokes             436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoking_status 내 'Unkonwn'은 정보에 대해 알 수 없는 것으로 결측임\n",
    "X_train['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking_status\n",
       "never smoked       632\n",
       "formerly smoked    391\n",
       "Unknown            291\n",
       "smokes             287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### smoking_status 컬럼(train : 458, test : 291 결측)\n",
    "# 컬럼 삭제\n",
    "X_train = X_train.drop(columns = 'smoking_status')\n",
    "X_test = X_test.drop(columns = 'smoking_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>Urban</td>\n",
       "      <td>78.48</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>82.72</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>119.62</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>67.92</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>146.44</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>Male</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>78.03</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>81.95</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>68.53</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>97.73</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>Male</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>86.62</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0       Male   8.0             0              0           No       children   \n",
       "1     Female  65.0             0              0          Yes       Govt_job   \n",
       "2     Female  79.0             1              0          Yes        Private   \n",
       "3       Male  66.0             0              0          Yes        Private   \n",
       "4     Female  45.0             0              0          Yes        Private   \n",
       "...      ...   ...           ...            ...          ...            ...   \n",
       "2394    Male  78.0             0              0          Yes        Private   \n",
       "2395  Female  81.0             0              0          Yes  Self-employed   \n",
       "2396    Male  80.0             0              1          Yes        Private   \n",
       "2397  Female  79.0             0              0          Yes        Private   \n",
       "2398    Male  82.0             0              0          Yes        Private   \n",
       "\n",
       "     Residence_type  avg_glucose_level   bmi  \n",
       "0             Urban              78.48  16.1  \n",
       "1             Urban              82.72  29.8  \n",
       "2             Rural             119.62  39.0  \n",
       "3             Rural              67.92  31.1  \n",
       "4             Urban             146.44  22.8  \n",
       "...             ...                ...   ...  \n",
       "2394          Rural              78.03  23.9  \n",
       "2395          Rural              81.95  16.9  \n",
       "2396          Urban              68.53  24.2  \n",
       "2397          Urban              97.73  21.5  \n",
       "2398          Rural              86.62  29.5  \n",
       "\n",
       "[2399 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-4. 수치형 컬럼 전처리\n",
    "###### age컬럼\n",
    "# 비닝하여 파생변수 age_gp에 할당, object형으로 변경\n",
    "X_train['age_gp'] = pd.cut(X_train['age'], bins = list(range(0, 100, 10))).astype('object')\n",
    "X_test['age_gp'] = pd.cut(X_test['age'], bins = list(range(0, 100, 10))).astype('object')\n",
    "\n",
    "# 완료 후 삭제\n",
    "X_train = X_train.drop(columns = 'age')\n",
    "X_test = X_test.drop(columns = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-5. 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state = 1234, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분할 후 shape 확인\n",
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-6. 인코딩\n",
    "# 카테고리형 컬럼에 대하여 원-핫 인코딩 수행\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 인코딩할 카테고리형 컬럼만 별도 저장\n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy()\n",
    "X_TEST_category = X_test.select_dtypes('object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "X_TRAIN_OH = OneHotEncoder(sparse_output = False).fit_transform(X_TRAIN_category)\n",
    "X_VAL_OH = OneHotEncoder(sparse_output = False).fit_transform(X_VAL_category)\n",
    "X_TEST_OH = OneHotEncoder(sparse_output = False).fit_transform(X_TEST_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-7. 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 스케일링할 컬럼만 별도 저장\n",
    "# .select_dtypes() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용\n",
    "X_TRAIN_conti = X_TRAIN.select_dtypes(exclude = 'object').copy()\n",
    "X_VAL_conti = X_VAL.select_dtypes(exclude = 'object').copy()\n",
    "X_TEST_conti = X_test.select_dtypes(exclude = 'object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 데이터 기준으로 스케일링 함\n",
    "# z-점수 표준화\n",
    "X_TRAIN_STD = StandardScaler().fit_transform(X_TRAIN_conti)\n",
    "X_VAL_STD = StandardScaler().fit_transform(X_VAL_conti)\n",
    "X_TEST_STD = StandardScaler().fit_transform(X_TEST_conti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-8. 입력 데이터셋 준비\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩과 스케일링된 넘파이 배열 연결\n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis = 1)\n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 평탄화\n",
    "y_TRAIN = y_TRAIN.values.ravel()\n",
    "y_VAL = y_VAL.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP4. 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-1. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 500,\n",
    "                            max_depth = 3,\n",
    "                            min_samples_leaf = 10,\n",
    "                            max_features = 2,\n",
    "                            random_state = 2022)\n",
    "model_rf = rf.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-2. XGBoost\n",
    "xgb = XGBClassifier(max_depth = 8,\n",
    "                    n_estimators = 500,\n",
    "                    nthread = 5,\n",
    "                    min_child_weight = 20,\n",
    "                    gamma = 0.5,\n",
    "                    objevtive = 'binary:logistic',\n",
    "                    use_label_encoder = False,\n",
    "                    random_state = 2022)\n",
    "\n",
    "model_xgb = xgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-3. LightGBM\n",
    "lgb = LGBMClassifier(max_depth = 8,\n",
    "                     n_estimators = 500,\n",
    "                     n_jobs = 30,\n",
    "                     min_child_weight = 10,\n",
    "                     learning_rate = 0.2,\n",
    "                     objective = 'binary',\n",
    "                     random_state = 2022)\n",
    "model_lgb = lgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-4. 성능평가(기준 : accuracy_score)를 통한 모델 선정\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검정용 데이터셋을 통한 예측\n",
    "pred_rf = model_rf.predict(X_VAL)\n",
    "pred_xgb = model_xgb.predict(X_VAL)\n",
    "pred_lgb = model_lgb.predict(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75625\n",
      "0.8520833333333333\n",
      "0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "# accuracy 계산\n",
    "acc_rf = accuracy_score(y_VAL, pred_rf)\n",
    "print(acc_rf)\n",
    "\n",
    "acc_xgb = accuracy_score(y_VAL, pred_xgb)\n",
    "print(acc_xgb)\n",
    "\n",
    "acc_lgb = accuracy_score(y_VAL, pred_lgb)\n",
    "print(acc_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP5. 결과 제출하기\n",
    "X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis = 1)\n",
    "y_pred = model_xgb.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = {'id' : ID,\n",
    "       'stroke' : y_pred}\n",
    "result = pd.DataFrame(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_161340\\1272037414.py:3: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  actual = actual['stroke'].ravel()\n"
     ]
    }
   ],
   "source": [
    "# 실제값\n",
    "actual = pd.read_csv('./data/stroke_y_test.csv')\n",
    "actual = actual['stroke'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488444722048719"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성과지표\n",
    "accuracy_score(actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제3회 기출문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP1. 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv('./data/job_change_X_train.csv')\n",
    "X_test = pd.read_csv('./data/job_change_X_test.csv')\n",
    "y_train = pd.read_csv('./data/job_change_y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6424</td>\n",
       "      <td>city_75</td>\n",
       "      <td>0.939</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>10</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18304</td>\n",
       "      <td>city_64</td>\n",
       "      <td>0.666</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22515</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15878</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>8</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Early Stage Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22128</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>6</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender relevent_experience  \\\n",
       "0         6424   city_75                   0.939   Male                 Has   \n",
       "1        18304   city_64                   0.666   Male                  No   \n",
       "2        22515  city_103                   0.920   Male                  No   \n",
       "3        15878   city_16                   0.910   Male                 Has   \n",
       "4        22128  city_103                   0.920   Male                 Has   \n",
       "\n",
       "  enrolled_university education_level major_discipline experience  \\\n",
       "0                  No        Graduate             STEM         10   \n",
       "1                Full            High              NaN          2   \n",
       "2                Full            High              NaN          4   \n",
       "3                  No        Graduate             STEM          8   \n",
       "4                  No        Graduate             STEM          6   \n",
       "\n",
       "  company_size         company_type last_new_job  training_hours  \n",
       "0        50-99              Pvt Ltd            1             176  \n",
       "1          NaN                  NaN            1             110  \n",
       "2          NaN                  NaN        never              44  \n",
       "3        50-99  Early Stage Startup            1              82  \n",
       "4       10000+              Pvt Ltd            1              70  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### STEP2. 데이터셋 확인하기\n",
    "###### STEP2-1. 데이터셋 일부 확인\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28806</td>\n",
       "      <td>city_160</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5826</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19061</td>\n",
       "      <td>city_114</td>\n",
       "      <td>0.926</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>11</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28476</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has</td>\n",
       "      <td>No</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Arts</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender relevent_experience  \\\n",
       "0          666  city_162                   0.767   Male                 Has   \n",
       "1        28806  city_160                   0.920   Male                 Has   \n",
       "2         5826   city_21                   0.624   Male                  No   \n",
       "3        19061  city_114                   0.926   Male                 Has   \n",
       "4        28476  city_103                   0.920   Male                 Has   \n",
       "\n",
       "  enrolled_university education_level major_discipline experience  \\\n",
       "0                  No         Masters             STEM        >20   \n",
       "1                  No            High              NaN          5   \n",
       "2                 NaN             NaN              NaN          2   \n",
       "3                  No         Masters             STEM         11   \n",
       "4                  No        Graduate             Arts          5   \n",
       "\n",
       "  company_size    company_type last_new_job  training_hours  \n",
       "0        50-99  Funded Startup            4               8  \n",
       "1        50-99  Funded Startup            1              24  \n",
       "2          NaN             NaN        never              24  \n",
       "3      100-500         Pvt Ltd            2              50  \n",
       "4          NaN             NaN            2              72  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id  target\n",
       "0         6424       0\n",
       "1        18304       0\n",
       "2        22515       0\n",
       "3        15878       0\n",
       "4        22128       0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10063 entries, 0 to 10062\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             10063 non-null  int64  \n",
      " 1   city                    10063 non-null  object \n",
      " 2   city_development_index  10063 non-null  float64\n",
      " 3   gender                  10063 non-null  object \n",
      " 4   relevent_experience     10063 non-null  object \n",
      " 5   enrolled_university     9921 non-null   object \n",
      " 6   education_level         9901 non-null   object \n",
      " 7   major_discipline        8740 non-null   object \n",
      " 8   experience              10063 non-null  object \n",
      " 9   company_size            7133 non-null   object \n",
      " 10  company_type            7048 non-null   object \n",
      " 11  last_new_job            10063 non-null  object \n",
      " 12  training_hours          10063 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 1022.2+ KB\n"
     ]
    }
   ],
   "source": [
    "###### STEP2-2. 데이터셋 요약 정보 확인\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4313 entries, 0 to 4312\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             4313 non-null   int64  \n",
      " 1   city                    4313 non-null   object \n",
      " 2   city_development_index  4313 non-null   float64\n",
      " 3   gender                  4313 non-null   object \n",
      " 4   relevent_experience     4313 non-null   object \n",
      " 5   enrolled_university     4262 non-null   object \n",
      " 6   education_level         4231 non-null   object \n",
      " 7   major_discipline        3724 non-null   object \n",
      " 8   experience              4313 non-null   object \n",
      " 9   company_size            3052 non-null   object \n",
      " 10  company_type            3024 non-null   object \n",
      " 11  last_new_job            4313 non-null   object \n",
      " 12  training_hours          4313 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 438.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10063 entries, 0 to 10062\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   enrollee_id  10063 non-null  int64\n",
      " 1   target       10063 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 157.4 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10063.000000</td>\n",
       "      <td>10063.000000</td>\n",
       "      <td>10063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17111.044619</td>\n",
       "      <td>0.839398</td>\n",
       "      <td>65.074332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9822.553276</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>59.490573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8607.000000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17339.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25937.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33380.000000</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id  city_development_index  training_hours\n",
       "count  10063.000000            10063.000000    10063.000000\n",
       "mean   17111.044619                0.839398       65.074332\n",
       "std     9822.553276                0.117685       59.490573\n",
       "min        4.000000                0.448000        1.000000\n",
       "25%     8607.000000                0.766000       23.000000\n",
       "50%    17339.000000                0.910000       47.000000\n",
       "75%    25937.000000                0.920000       88.000000\n",
       "max    33380.000000                0.949000      336.000000"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP2-3. 기초통계량 확인\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4313.000000</td>\n",
       "      <td>4313.000000</td>\n",
       "      <td>4313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17239.037793</td>\n",
       "      <td>0.841139</td>\n",
       "      <td>65.893114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9865.439926</td>\n",
       "      <td>0.115683</td>\n",
       "      <td>60.792871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8560.000000</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17564.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26204.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33379.000000</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id  city_development_index  training_hours\n",
       "count   4313.000000             4313.000000     4313.000000\n",
       "mean   17239.037793                0.841139       65.893114\n",
       "std     9865.439926                0.115683       60.792871\n",
       "min        1.000000                0.448000        2.000000\n",
       "25%     8560.000000                0.767000       24.000000\n",
       "50%    17564.000000                0.910000       48.000000\n",
       "75%    26204.000000                0.920000       88.000000\n",
       "max    33379.000000                0.949000      336.000000"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10063.000000</td>\n",
       "      <td>10063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17111.044619</td>\n",
       "      <td>0.230249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9822.553276</td>\n",
       "      <td>0.421013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8607.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17339.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25937.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33380.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id        target\n",
       "count  10063.000000  10063.000000\n",
       "mean   17111.044619      0.230249\n",
       "std     9822.553276      0.421013\n",
       "min        4.000000      0.000000\n",
       "25%     8607.000000      0.000000\n",
       "50%    17339.000000      0.000000\n",
       "75%    25937.000000      0.000000\n",
       "max    33380.000000      1.000000"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP3. 데이터셋 전처리\n",
    "###### STEP3-1. 불필요한 컬럼 삭제\n",
    "# enrollee_id 컬럼은 지원자의 고유 정보로 key 역할로 모델에는 불필요함\n",
    "# 결과 제출 시에는 X_test의 enrollee_id 컬럼이 필요하기 때문에 별도 저장\n",
    "enrollee_id = X_test['enrollee_id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터들에서 Data 컬럼 삭제\n",
    "X_train = X_train.drop(columns = 'enrollee_id')\n",
    "X_test = X_test.drop(columns = 'enrollee_id')\n",
    "y_train = y_train.drop(columns = 'enrollee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                         0\n",
       "city_development_index       0\n",
       "gender                       0\n",
       "relevent_experience          0\n",
       "enrolled_university        142\n",
       "education_level            162\n",
       "major_discipline          1323\n",
       "experience                   0\n",
       "company_size              2930\n",
       "company_type              3015\n",
       "last_new_job                 0\n",
       "training_hours               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP3-2. 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                         0\n",
       "city_development_index       0\n",
       "gender                       0\n",
       "relevent_experience          0\n",
       "enrolled_university         51\n",
       "education_level             82\n",
       "major_discipline           589\n",
       "experience                   0\n",
       "company_size              1261\n",
       "company_type              1289\n",
       "last_new_job                 0\n",
       "training_hours               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### train에서 1,000개가 넘는 공백이 있는 컬럼은 삭제\n",
    "# 1,000개가 넘을 조건\n",
    "cond_na1000 = (X_train.isna().sum() > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,000개가 넘는 컬럼명\n",
    "colnm_na1000 = X_train.columns[cond_na1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 삭제\n",
    "X_train = X_train.drop(colnm_na1000, axis = 1)\n",
    "X_test = X_test.drop(colnm_na1000, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### train에서 200개 미만의 결측치가 있는 컬럼은 결측치 대체\n",
    "####### enrolled_university 컬럼(train : 142, test : 51)\n",
    "# 최다빈도를 가지는 라벨로 대체\n",
    "mode_EU = X_train['enrolled_university'].value_counts().idxmax()\n",
    "X_train['enrolled_university'] = X_train['enrolled_university'].fillna(mode_EU)\n",
    "X_test['enrolled_university'] = X_test['enrolled_university'].fillna(mode_EU)\n",
    "\n",
    "####### education_level 컬럼(train : 162, test : 82)\n",
    "# 최다빈도를 가지는 라벨로 대체\n",
    "mode_EL = X_train['education_level'].value_counts().idxmax()\n",
    "X_train['education_level'] = X_train['education_level'].fillna(mode_EL)\n",
    "X_test['education_level'] = X_test['education_level'].fillna(mode_EL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-5. 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state = 1234, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8050, 9)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분할 후 shape 확인\n",
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 9)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8050, 1)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-6. 인코딩\n",
    "# 카테고리형 컬럼에 대하여 원-핫 인코딩 수행\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 인코딩할 카테고리형 컬럼만 별도 저장\n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy()\n",
    "X_TEST_category = X_test.select_dtypes('object').copy()\n",
    "\n",
    "# 원-핫 인코딩\n",
    "enc = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore').fit(X_TRAIN_category)\n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "X_TEST_OH = enc.transform(X_TEST_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-7. 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 스케일링할 컬럼만 별도 저장\n",
    "# .select_dtypes() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용\n",
    "X_TRAIN_conti = X_TRAIN.select_dtypes(exclude = 'object').copy()\n",
    "X_VAL_conti = X_VAL.select_dtypes(exclude = 'object').copy()\n",
    "X_TEST_conti = X_test.select_dtypes(exclude = 'object').copy()\n",
    "\n",
    "# z-점수 표준화\n",
    "X_TRAIN_STD = StandardScaler().fit_transform(X_TRAIN_conti)\n",
    "X_VAL_STD = StandardScaler().fit_transform(X_VAL_conti)\n",
    "X_TEST_STD = StandardScaler().fit_transform(X_TEST_conti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-8. 입력 데이터셋 준비\n",
    "import numpy as np\n",
    "\n",
    "# 인코딩과 스케일링된 넘파이 배열 연결\n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis = 1)\n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 평탄화\n",
    "y_TRAIN = y_TRAIN.values.ravel()\n",
    "y_VAL = y_VAL.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP4. 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-1. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 500,\n",
    "                            max_depth = 3,\n",
    "                            min_samples_leaf = 10,\n",
    "                            max_features = 'sqrt',\n",
    "                            random_state = 2022)\n",
    "model_rf = rf.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-2. XGBoost\n",
    "xgb = XGBClassifier(max_depth = 8,\n",
    "                    n_Estimators = 500,\n",
    "                    nthread = 5,\n",
    "                    min_child_weight = 20,\n",
    "                    gamma = 0.5,\n",
    "                    objective = 'binary:logistic',\n",
    "                    use_label_encoder = False,\n",
    "                    random_state = 2022)\n",
    "model_xgb = xgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-3. LightGBM\n",
    "lgb = LGBMClassifier(max_depth = 8,\n",
    "                     n_estimators = 500,\n",
    "                     n_jobs = 30,\n",
    "                     min_child_weight = 10,\n",
    "                     learning_rate = 0.2,\n",
    "                     objective = 'binary',\n",
    "                     random_state = 2022)\n",
    "model_lgb = lgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-4. 성능평가(기준 : AUC)를 통한 모델 선정\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측\n",
    "score_rf = model_rf.predict_proba(X_VAL)[:, 1]\n",
    "score_xgb = model_xgb.predict_proba(X_VAL)[:, 1]\n",
    "score_lgb = model_lgb.predict_proba(X_VAL)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7457271226847606\n"
     ]
    }
   ],
   "source": [
    "# AUC 계산\n",
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_rf)\n",
    "auc_rf = auc(fpr, tpr)\n",
    "print(auc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7388276037184894\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_xgb)\n",
    "auc_xgb = auc(fpr, tpr)\n",
    "print(auc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7073516342450874\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_lgb)\n",
    "auc_lgb = auc(fpr, tpr)\n",
    "print(auc_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제4회 기출문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP1. 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/bodyPerfor_train.csv')\n",
    "test = pd.read_csv('./data/bodyPerfor_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train데이터를 X_train과 X_test로 분할\n",
    "X_train = train.drop(columns = 'class').copy()\n",
    "y_train = train['class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test도 통일을 위해 X_test로 할당\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_fat</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>grip_force</th>\n",
       "      <th>sit_bend_forward</th>\n",
       "      <th>sit_ups</th>\n",
       "      <th>broad_jump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>920</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>173.8</td>\n",
       "      <td>73.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>148</td>\n",
       "      <td>46.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5998</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>176.2</td>\n",
       "      <td>73.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>119</td>\n",
       "      <td>47.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11457</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>169.2</td>\n",
       "      <td>73.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>128</td>\n",
       "      <td>49.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>39.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2898</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>170.3</td>\n",
       "      <td>76.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>154</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3141</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>171.3</td>\n",
       "      <td>68.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>145</td>\n",
       "      <td>42.7</td>\n",
       "      <td>23.2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age gender  height  weight  body_fat  diastolic  systolic  \\\n",
       "0    920   40      M   173.8    73.2      12.0       80.0       148   \n",
       "1   5998   35      M   176.2    73.7      15.7       64.0       119   \n",
       "2  11457   57      M   169.2    73.5      21.7       77.0       128   \n",
       "3   2898   45      M   170.3    76.7      17.0       86.0       154   \n",
       "4   3141   28      M   171.3    68.7      11.2       99.0       145   \n",
       "\n",
       "   grip_force  sit_bend_forward  sit_ups  broad_jump  \n",
       "0        46.9              15.0     50.0       250.0  \n",
       "1        47.6              18.0     46.0       226.0  \n",
       "2        49.5              14.8     39.0       206.0  \n",
       "3        50.8              19.5     43.0       214.0  \n",
       "4        42.7              23.2     71.0       269.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### STEP2. 데이터셋 확인하기\n",
    "###### STEP2-1. 데이터셋 일부 확인\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_fat</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>grip_force</th>\n",
       "      <th>sit_bend_forward</th>\n",
       "      <th>sit_ups</th>\n",
       "      <th>broad_jump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>169.2</td>\n",
       "      <td>65.4</td>\n",
       "      <td>19.3</td>\n",
       "      <td>63.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "      <td>155.9</td>\n",
       "      <td>62.7</td>\n",
       "      <td>30.2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>159.8</td>\n",
       "      <td>57.1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>63.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>180.1</td>\n",
       "      <td>82.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>158.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>86.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>28.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age gender  height  weight  body_fat  diastolic  systolic  grip_force  \\\n",
       "0  11   42      M   169.2    65.4      19.3       63.0     110.0        43.5   \n",
       "1  22   59      F   155.9    62.7      30.2       76.0     143.0        36.8   \n",
       "2  30   50      F   159.8    57.1      24.4       63.0     103.0        30.8   \n",
       "3  49   28      M   180.1    82.1      15.0       83.0     147.0        52.6   \n",
       "4  88   41      F   158.1    51.0      21.7       86.0     127.0        23.1   \n",
       "\n",
       "   sit_bend_forward  sit_ups  broad_jump  \n",
       "0              16.0     68.0         211  \n",
       "1              29.1     25.0         122  \n",
       "2              24.4     30.0         143  \n",
       "3              18.8     55.0         247  \n",
       "4              28.6     46.0         165  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "1    A\n",
       "2    A\n",
       "3    A\n",
       "4    A\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10713 entries, 0 to 10712\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                10713 non-null  int64  \n",
      " 1   age               10713 non-null  int64  \n",
      " 2   gender            10713 non-null  object \n",
      " 3   height            10713 non-null  float64\n",
      " 4   weight            10713 non-null  float64\n",
      " 5   body_fat          10713 non-null  float64\n",
      " 6   diastolic         10713 non-null  float64\n",
      " 7   systolic          10713 non-null  int64  \n",
      " 8   grip_force        10713 non-null  float64\n",
      " 9   sit_bend_forward  10713 non-null  float64\n",
      " 10  sit_ups           10713 non-null  float64\n",
      " 11  broad_jump        10713 non-null  float64\n",
      "dtypes: float64(8), int64(3), object(1)\n",
      "memory usage: 1004.5+ KB\n"
     ]
    }
   ],
   "source": [
    "###### STEP2-2. 데이터셋 요약 정보 확인\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2680 entries, 0 to 2679\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                2680 non-null   int64  \n",
      " 1   age               2680 non-null   int64  \n",
      " 2   gender            2680 non-null   object \n",
      " 3   height            2680 non-null   float64\n",
      " 4   weight            2680 non-null   float64\n",
      " 5   body_fat          2680 non-null   float64\n",
      " 6   diastolic         2680 non-null   float64\n",
      " 7   systolic          2680 non-null   float64\n",
      " 8   grip_force        2680 non-null   float64\n",
      " 9   sit_bend_forward  2680 non-null   float64\n",
      " 10  sit_ups           2680 non-null   float64\n",
      " 11  broad_jump        2680 non-null   int64  \n",
      "dtypes: float64(8), int64(3), object(1)\n",
      "memory usage: 251.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10713 entries, 0 to 10712\n",
      "Series name: class\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10713 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_fat</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>grip_force</th>\n",
       "      <th>sit_bend_forward</th>\n",
       "      <th>sit_ups</th>\n",
       "      <th>broad_jump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "      <td>10713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6705.064221</td>\n",
       "      <td>36.753664</td>\n",
       "      <td>168.554569</td>\n",
       "      <td>67.493615</td>\n",
       "      <td>23.240960</td>\n",
       "      <td>78.846159</td>\n",
       "      <td>130.338654</td>\n",
       "      <td>37.002717</td>\n",
       "      <td>15.202553</td>\n",
       "      <td>39.842024</td>\n",
       "      <td>190.273322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3864.549752</td>\n",
       "      <td>13.607601</td>\n",
       "      <td>8.372870</td>\n",
       "      <td>11.916531</td>\n",
       "      <td>7.247821</td>\n",
       "      <td>10.742433</td>\n",
       "      <td>14.652444</td>\n",
       "      <td>10.598279</td>\n",
       "      <td>8.572562</td>\n",
       "      <td>14.258093</td>\n",
       "      <td>39.990996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3347.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>162.500000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6705.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>169.200000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10049.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>174.700000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13393.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>193.800000</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>156.200000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           age        height        weight      body_fat  \\\n",
       "count  10713.000000  10713.000000  10713.000000  10713.000000  10713.000000   \n",
       "mean    6705.064221     36.753664    168.554569     67.493615     23.240960   \n",
       "std     3864.549752     13.607601      8.372870     11.916531      7.247821   \n",
       "min        1.000000     21.000000    125.000000     26.300000      3.000000   \n",
       "25%     3347.000000     25.000000    162.500000     58.200000     18.000000   \n",
       "50%     6705.000000     32.000000    169.200000     67.500000     22.800000   \n",
       "75%    10049.000000     48.000000    174.700000     75.400000     28.000000   \n",
       "max    13393.000000     64.000000    193.800000    138.100000     78.400000   \n",
       "\n",
       "          diastolic      systolic    grip_force  sit_bend_forward  \\\n",
       "count  10713.000000  10713.000000  10713.000000      10713.000000   \n",
       "mean      78.846159    130.338654     37.002717         15.202553   \n",
       "std       10.742433     14.652444     10.598279          8.572562   \n",
       "min        0.000000      0.000000      0.000000        -25.000000   \n",
       "25%       71.000000    120.000000     27.600000         10.900000   \n",
       "50%       79.000000    130.000000     38.000000         16.200000   \n",
       "75%       87.000000    141.000000     45.200000         20.800000   \n",
       "max      156.200000    201.000000     70.400000        213.000000   \n",
       "\n",
       "            sit_ups    broad_jump  \n",
       "count  10713.000000  10713.000000  \n",
       "mean      39.842024    190.273322  \n",
       "std       14.258093     39.990996  \n",
       "min        0.000000      0.000000  \n",
       "25%       30.000000    162.000000  \n",
       "50%       41.000000    194.000000  \n",
       "75%       51.000000    222.000000  \n",
       "max       80.000000    303.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP2-3. 기초통계량 확인\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_fat</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>grip_force</th>\n",
       "      <th>sit_bend_forward</th>\n",
       "      <th>sit_ups</th>\n",
       "      <th>broad_jump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "      <td>2680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6664.764179</td>\n",
       "      <td>36.860821</td>\n",
       "      <td>168.580746</td>\n",
       "      <td>67.262239</td>\n",
       "      <td>23.236985</td>\n",
       "      <td>78.599701</td>\n",
       "      <td>129.819739</td>\n",
       "      <td>36.808619</td>\n",
       "      <td>15.236112</td>\n",
       "      <td>39.488209</td>\n",
       "      <td>189.555224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3874.194251</td>\n",
       "      <td>13.699722</td>\n",
       "      <td>8.639518</td>\n",
       "      <td>12.081684</td>\n",
       "      <td>7.294158</td>\n",
       "      <td>10.740177</td>\n",
       "      <td>14.952870</td>\n",
       "      <td>10.731066</td>\n",
       "      <td>7.978120</td>\n",
       "      <td>14.350013</td>\n",
       "      <td>39.374656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>139.900000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>43.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3365.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>57.800000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>27.275000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>163.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6659.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>169.300000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>37.450000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10023.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13392.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>191.800000</td>\n",
       "      <td>119.800000</td>\n",
       "      <td>50.300000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>294.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          age       height       weight     body_fat  \\\n",
       "count   2680.000000  2680.000000  2680.000000  2680.000000  2680.000000   \n",
       "mean    6664.764179    36.860821   168.580746    67.262239    23.236985   \n",
       "std     3874.194251    13.699722     8.639518    12.081684     7.294158   \n",
       "min        9.000000    21.000000   139.900000    31.900000     3.000000   \n",
       "25%     3365.750000    25.000000   162.000000    57.800000    17.900000   \n",
       "50%     6659.000000    32.000000   169.300000    67.200000    22.700000   \n",
       "75%    10023.250000    48.000000   175.000000    75.100000    27.900000   \n",
       "max    13392.000000    64.000000   191.800000   119.800000    50.300000   \n",
       "\n",
       "         diastolic     systolic   grip_force  sit_bend_forward      sit_ups  \\\n",
       "count  2680.000000  2680.000000  2680.000000       2680.000000  2680.000000   \n",
       "mean     78.599701   129.819739    36.808619         15.236112    39.488209   \n",
       "std      10.740177    14.952870    10.731066          7.978120    14.350013   \n",
       "min       8.000000    43.900000     0.000000        -20.000000     0.000000   \n",
       "25%      71.000000   119.000000    27.275000         11.000000    31.000000   \n",
       "50%      79.000000   129.000000    37.450000         16.200000    41.000000   \n",
       "75%      86.000000   141.000000    44.900000         20.525000    50.000000   \n",
       "max     121.000000   195.000000    70.500000         42.000000    78.000000   \n",
       "\n",
       "        broad_jump  \n",
       "count  2680.000000  \n",
       "mean    189.555224  \n",
       "std      39.374656  \n",
       "min       0.000000  \n",
       "25%     163.000000  \n",
       "50%     191.000000  \n",
       "75%     220.000000  \n",
       "max     294.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10713\n",
       "unique        4\n",
       "top           C\n",
       "freq       2679\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP3. 데이터셋 전처리\n",
    "###### STEP3-1. 불필요한 컬럼 삭제\n",
    "# id 컬럼은 개인의 고유번호로 key 역할로 모델에는 불필요함\n",
    "\n",
    "# 데이터들에서 Data 컬럼 삭제\n",
    "X_train = X_train.drop(columns = 'id')\n",
    "X_test = X_test.drop(columns = 'id')\n",
    "y_train = y_train.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "gender              0\n",
       "height              0\n",
       "weight              0\n",
       "body_fat            0\n",
       "diastolic           0\n",
       "systolic            0\n",
       "grip_force          0\n",
       "sit_bend_forward    0\n",
       "sit_ups             0\n",
       "broad_jump          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP3-2. 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "gender              0\n",
       "height              0\n",
       "weight              0\n",
       "body_fat            0\n",
       "diastolic           0\n",
       "systolic            0\n",
       "grip_force          0\n",
       "sit_bend_forward    0\n",
       "sit_ups             0\n",
       "broad_jump          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-4. 수치형 컬럼 전처리\n",
    "####### age 컬럼\n",
    "# 비닝하여 파생변수 age_gp에 할당, object형으로 변경\n",
    "X_train['age_gp'] = pd.cut(X_train['age'], bins = list(range(0, 70, 10))).astype('object')\n",
    "X_test['age_gp'] = pd.cut(X_test['age'], bins = list(range(0, 70, 10))).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 삭제\n",
    "X_train = X_train.drop(columns = 'age')\n",
    "X_test = X_test.drop(columns = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-5. 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state = 1234, test_size = 0.3, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7499, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분할 후 shape 확인\n",
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7499,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_VAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-6. 인코딩\n",
    "# 카테고리형 컬럼에 대하여 원-핫 인코딩 수행\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 인코딩할 카테고리형 컬럼만 별도 저장\n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy()\n",
    "X_TEST_category = X_test.select_dtypes('object').copy()\n",
    "\n",
    "# 원-핫 인코딩\n",
    "enc = OneHotEncoder(sparse_output = False).fit(X_TRAIN_category)\n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "X_TEST_OH = enc.transform(X_TEST_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-7. 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 스케일링할 컬럼만 별도 저장\n",
    "# .select_dtypes() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용\n",
    "X_TRAIN_conti = X_TRAIN.select_dtypes(exclude = 'object').copy()\n",
    "X_VAL_conti = X_VAL.select_dtypes(exclude = 'object').copy()\n",
    "X_TEST_conti = X_test.select_dtypes(exclude = 'object').copy()\n",
    "\n",
    "# z-점수 표준화\n",
    "X_TRAIN_STD = StandardScaler().fit_transform(X_TRAIN_conti)\n",
    "X_VAL_STD = StandardScaler().fit_transform(X_VAL_conti)\n",
    "X_TEST_STD = StandardScaler().fit_transform(X_TEST_conti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-8. 입력 데이터셋 준비\n",
    "import numpy as np\n",
    "\n",
    "# 인코딩과 스케일링된 넘파이 배열 연결\n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis = 1)\n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'A' ~ 'D'를 0~3로 매핑\n",
    "y_TRAIN = y_TRAIN.map({'A' : 0, 'B' : 1, 'C' : 2, 'D' : 3})\n",
    "y_VAL = y_VAL.map({'A' : 0, 'B' : 1, 'C' : 2, 'D' : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 평탄화\n",
    "y_TRAIN = y_TRAIN.values.ravel()\n",
    "y_VAL = y_VAL.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP4. 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-1. Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 500,\n",
    "                            max_depth = 3,\n",
    "                            min_samples_leaf = 10,\n",
    "                            max_features = 'sqrt',\n",
    "                            random_state = 2022)\n",
    "model_rf = rf.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:47:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_Estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "###### STEP4-2. XGBoost\n",
    "xgb = XGBClassifier(max_depth = 8,\n",
    "                    n_Estimators = 500,\n",
    "                    nthread = 5,\n",
    "                    min_child_weight = 20,\n",
    "                    gamma = 0.5,\n",
    "                    objective = 'binary:softmax',\n",
    "                    use_label_encoder = False,\n",
    "                    random_state = 2022)\n",
    "model_xgb = xgb.fit(X_TRAIN, y_TRAIN, eval_metric = 'mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1693\n",
      "[LightGBM] [Info] Number of data points in the train set: 7499, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -1.386161\n",
      "[LightGBM] [Info] Start training from score -1.386694\n",
      "[LightGBM] [Info] Start training from score -1.386161\n",
      "[LightGBM] [Info] Start training from score -1.386161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "###### STEP4-3. LightGBM\n",
    "lgb = LGBMClassifier(max_depth = 8,\n",
    "                     n_estimators = 500,\n",
    "                     n_jobs = 30,\n",
    "                     min_child_weight = 10,\n",
    "                     learning_rate = 0.2,\n",
    "                     objective = 'multiclass',\n",
    "                     random_state = 2022)\n",
    "model_lgb = lgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4-4. 성능평가(기준 : AUC)를 통한 모델 선정\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측\n",
    "pred_rf = model_rf.predict(X_VAL)\n",
    "pred_xgb = model_xgb.predict(X_VAL)\n",
    "pred_lgb = model_lgb.predict(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5487910392294565\n"
     ]
    }
   ],
   "source": [
    "# macro f1-score 계산\n",
    "f1_rf = f1_score(y_VAL, pred_rf, average = 'macro')\n",
    "print(f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6987987858893204\n"
     ]
    }
   ],
   "source": [
    "f1_xgb = f1_score(y_VAL, pred_xgb, average = 'macro')\n",
    "print(f1_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976683281331036\n"
     ]
    }
   ],
   "source": [
    "f1_lgb = f1_score(y_VAL, pred_lgb, average = 'macro')\n",
    "print(f1_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제6회 기출문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 1유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sejong_fire = pd.read_csv('./data/sejong_fire.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화재 진압 시간 계산\n",
    "sejong_fire['접수일시'] = pd.to_datetime(sejong_fire['접수일시'])\n",
    "sejong_fire['상황종료일시'] = pd.to_datetime(sejong_fire['상황종료일시'])\n",
    "sejong_fire['화재진압시간'] = (sejong_fire['상황종료일시'] - sejong_fire['접수일시']).astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화재 진압 시간이 가장 큰 서센터의 평균 화재 진압 시간 계산\n",
    "# 화재 진압 시간이 가장 큰 서센터\n",
    "center_name = sejong_fire['서센터명'][sejong_fire['화재진압시간'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 센터에 대한 데이터만 복사\n",
    "df = sejong_fire.loc[sejong_fire['서센터명'] == center_name].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1 days 02:13:06')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['화재진압시간'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>student_1</th>\n",
       "      <th>student_2</th>\n",
       "      <th>student_3</th>\n",
       "      <th>student_4</th>\n",
       "      <th>student_5</th>\n",
       "      <th>student_6</th>\n",
       "      <th>teacher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광일초등학교</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>남성초등학교</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>대남초등학교</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대연초등학교</td>\n",
       "      <td>132</td>\n",
       "      <td>135</td>\n",
       "      <td>151</td>\n",
       "      <td>156</td>\n",
       "      <td>179</td>\n",
       "      <td>171</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>대천초등학교</td>\n",
       "      <td>90</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>106</td>\n",
       "      <td>126</td>\n",
       "      <td>118</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_name  student_1  student_2  student_3  student_4  student_5  \\\n",
       "0      광일초등학교         43         36         35         51         65   \n",
       "1      남성초등학교         86        100         99         71         78   \n",
       "2      대남초등학교         46         70         49         40         62   \n",
       "3      대연초등학교        132        135        151        156        179   \n",
       "4      대천초등학교         90        106         84        106        126   \n",
       "\n",
       "   student_6  teacher  \n",
       "0         60       16  \n",
       "1         49       22  \n",
       "2         56       20  \n",
       "3        171       45  \n",
       "4        118       34  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "busan_school_Info = pd.read_csv('./data/busan_school_Info.csv', encoding = 'cp949')\n",
    "busan_school_Info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학생 수의 교사 비율(교사 1인당 학생 수)이 가장 높은 학교의 교사 수\n",
    "# 교사 1인당 학생 계산\n",
    "ratio = busan_school_Info.iloc[:, 1:7].sum(axis = 1) / busan_school_Info['teacher']\n",
    "\n",
    "# 위의 값이 가장 큰 학교 데이터만 추출\n",
    "max_school_name = busan_school_Info['school_name'][ratio.argmax()]\n",
    "df = busan_school_Info.loc[busan_school_Info['school_name'] == max_school_name].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "result = df['teacher'][ratio.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연월</th>\n",
       "      <th>살인_발생건수</th>\n",
       "      <th>살인_검거건수</th>\n",
       "      <th>강도_발생건수</th>\n",
       "      <th>강도_검거건수</th>\n",
       "      <th>강간_강제추행_발생건수</th>\n",
       "      <th>강간_강제추행_검거건수</th>\n",
       "      <th>절도_발생건수</th>\n",
       "      <th>절도_검거건수</th>\n",
       "      <th>폭력_발생건수</th>\n",
       "      <th>폭력_검거건수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008. 01 월</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>191</td>\n",
       "      <td>186</td>\n",
       "      <td>1870</td>\n",
       "      <td>1166</td>\n",
       "      <td>5534</td>\n",
       "      <td>5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008. 02 월</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>1733</td>\n",
       "      <td>996</td>\n",
       "      <td>4534</td>\n",
       "      <td>4341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008. 03 월</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>262</td>\n",
       "      <td>255</td>\n",
       "      <td>2374</td>\n",
       "      <td>1687</td>\n",
       "      <td>5690</td>\n",
       "      <td>5464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008. 04 월</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>88</td>\n",
       "      <td>276</td>\n",
       "      <td>262</td>\n",
       "      <td>2513</td>\n",
       "      <td>1744</td>\n",
       "      <td>6080</td>\n",
       "      <td>5843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008. 05 월</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>79</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>290</td>\n",
       "      <td>2406</td>\n",
       "      <td>1375</td>\n",
       "      <td>6427</td>\n",
       "      <td>6135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           연월  살인_발생건수  살인_검거건수  강도_발생건수  강도_검거건수  강간_강제추행_발생건수  강간_강제추행_검거건수  \\\n",
       "0  2008. 01 월       19       18       49       49           191           186   \n",
       "1  2008. 02 월        9        9       43       36           184           182   \n",
       "2  2008. 03 월       14       10       78       75           262           255   \n",
       "3  2008. 04 월       19       20      102       88           276           262   \n",
       "4  2008. 05 월       23       23       79       71           297           290   \n",
       "\n",
       "   절도_발생건수  절도_검거건수  폭력_발생건수  폭력_검거건수  \n",
       "0     1870     1166     5534     5342  \n",
       "1     1733      996     4534     4341  \n",
       "2     2374     1687     5690     5464  \n",
       "3     2513     1744     6080     5843  \n",
       "4     2406     1375     6427     6135  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "five_crime = pd.read_csv('./data/five_crime.csv', encoding = 'cp949')\n",
    "five_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도별 범죄 총 발생건수 계산\n",
    "# 사이 공백들 처리 후 연도와 월을 문자열로 처리\n",
    "five_crime['연월'] = five_crime['연월'].str.replace(' ', '')\n",
    "five_crime['연월'] = five_crime['연월'].str.replace('월', '')\n",
    "five_crime['연도'] = five_crime['연월'].str[:4].copy()\n",
    "five_crime['월'] = five_crime['연월'].str[-2:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 발생 건수 컬럼 추가\n",
    "five_crime['총발생건수'] = five_crime.iloc[:,range(1, 11, 2)].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도별 범죄 총 발생건수의 월평균 계산\n",
    "연도별월평균 = five_crime.groupby('연도')['총발생건수'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taek5\\AppData\\Local\\Temp\\ipykernel_11280\\4010754138.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  result = five_crime.groupby('연도')['폭력_발생건수'].mean()[max_year]\n"
     ]
    }
   ],
   "source": [
    "# 월평균이 가장 큰 연도 찾은 후 해당연도의 월평균 폭력검거건수를 출력\n",
    "max_year = 연도별월평균.argmax()\n",
    "result = five_crime.groupby('연도')['폭력_발생건수'].mean()[max_year]\n",
    "result = round(result, 0).astype('int')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 2유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/Airline_train.csv')\n",
    "test = pd.read_csv('./data/Airline_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 X_train과 y_train으로 분할\n",
    "y_train = train['Satisfaction']\n",
    "X_train = train.drop('Satisfaction', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test도 통일을 위해 X_test로 할당\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender      Ages Customer_Type     Class  Inflight_wifi_service  \\\n",
      "0  Female  [10, 20)             L  Eco Plus                      1   \n",
      "1  Female  [10, 20)             L       Eco                      2   \n",
      "2  Female  [10, 20)            NL       Eco                      2   \n",
      "3    Male  [10, 20)            NL       Eco                      5   \n",
      "4    Male  [10, 20)             L  Business                      3   \n",
      "\n",
      "   Departure_Arrival_time_convenient  Ease_of_Online_booking  Gate_location  \\\n",
      "0                                  3                       1              3   \n",
      "1                                  4                       2              4   \n",
      "2                                  2                       1              4   \n",
      "3                                  3                       5              3   \n",
      "4                                  3                       3              3   \n",
      "\n",
      "   Food_and_drink  Online_boarding  Seat_comfort  Inflight_entertainment  \\\n",
      "0               1                1             1                       1   \n",
      "1               1                2             1                       1   \n",
      "2               4                1             4                       4   \n",
      "3               1                5             1                       1   \n",
      "4               3                3             3                       3   \n",
      "\n",
      "   On_board_service  Leg_room_service  Baggage_handling  Checkin_service  \\\n",
      "0                 2                 1                 2                4   \n",
      "1                 3                 3                 4                4   \n",
      "2                 4                 4                 3                2   \n",
      "3                 2                 4                 3                1   \n",
      "4                 4                 2                 4                1   \n",
      "\n",
      "   Inflight_service  Cleanliness  Departure_Delay_in_Minutes  \\\n",
      "0                 2            1                           0   \n",
      "1                 4            1                           0   \n",
      "2                 3            4                           3   \n",
      "3                 1            1                           0   \n",
      "4                 4            3                           0   \n",
      "\n",
      "   Arrival_Delay_in_Minutes  \n",
      "0                         0  \n",
      "1                         0  \n",
      "2                         0  \n",
      "3                         0  \n",
      "4                         0  \n",
      "   Gender      Ages Customer_Type Class  Inflight_wifi_service  \\\n",
      "0    Male  [10, 20)             L   Eco                      4   \n",
      "1  Female  [10, 20)             L   Eco                      4   \n",
      "2  Female  [10, 20)             L   Eco                      0   \n",
      "3  Female  [10, 20)             L   Eco                      4   \n",
      "4    Male  [10, 20)             L   Eco                      1   \n",
      "\n",
      "   Departure_Arrival_time_convenient  Ease_of_Online_booking  Gate_location  \\\n",
      "0                                  2                       4              4   \n",
      "1                                  1                       5              5   \n",
      "2                                  3                       0              3   \n",
      "3                                  1                       4              4   \n",
      "4                                  5                       0              3   \n",
      "\n",
      "   Food_and_drink  Online_boarding  Seat_comfort  Inflight_entertainment  \\\n",
      "0               2                4             2                       2   \n",
      "1               4                4             3                       4   \n",
      "2               0                3             3                       4   \n",
      "3               2                4             2                       2   \n",
      "4               2                0             5                       2   \n",
      "\n",
      "   On_board_service  Leg_room_service  Baggage_handling  Checkin_service  \\\n",
      "0                 1                 2                 3                1   \n",
      "1                 5                 5                 3                4   \n",
      "2                 3                 4                 4                3   \n",
      "3                 2                 5                 4                1   \n",
      "4                 2                 4                 4                2   \n",
      "\n",
      "   Inflight_service  Cleanliness  Departure_Delay_in_Minutes  \\\n",
      "0                 4            2                          20   \n",
      "1                 1            4                           0   \n",
      "2                 2            3                         151   \n",
      "3                 3            2                           0   \n",
      "4                 3            2                           0   \n",
      "\n",
      "   Arrival_Delay_in_Minutes  \n",
      "0                        11  \n",
      "1                         0  \n",
      "2                       214  \n",
      "3                         0  \n",
      "4                         0  \n",
      "0     No\n",
      "1     No\n",
      "2     No\n",
      "3    Yes\n",
      "4     No\n",
      "Name: Satisfaction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확인하기\n",
    "# 데이터셋 일부 확인\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender      Ages Customer_Type Class  Inflight_wifi_service  \\\n",
      "0    Male  [10, 20)             L   Eco                      4   \n",
      "1  Female  [10, 20)             L   Eco                      4   \n",
      "2  Female  [10, 20)             L   Eco                      0   \n",
      "3  Female  [10, 20)             L   Eco                      4   \n",
      "4    Male  [10, 20)             L   Eco                      1   \n",
      "\n",
      "   Departure_Arrival_time_convenient  Ease_of_Online_booking  Gate_location  \\\n",
      "0                                  2                       4              4   \n",
      "1                                  1                       5              5   \n",
      "2                                  3                       0              3   \n",
      "3                                  1                       4              4   \n",
      "4                                  5                       0              3   \n",
      "\n",
      "   Food_and_drink  Online_boarding  Seat_comfort  Inflight_entertainment  \\\n",
      "0               2                4             2                       2   \n",
      "1               4                4             3                       4   \n",
      "2               0                3             3                       4   \n",
      "3               2                4             2                       2   \n",
      "4               2                0             5                       2   \n",
      "\n",
      "   On_board_service  Leg_room_service  Baggage_handling  Checkin_service  \\\n",
      "0                 1                 2                 3                1   \n",
      "1                 5                 5                 3                4   \n",
      "2                 3                 4                 4                3   \n",
      "3                 2                 5                 4                1   \n",
      "4                 2                 4                 4                2   \n",
      "\n",
      "   Inflight_service  Cleanliness  Departure_Delay_in_Minutes  \\\n",
      "0                 4            2                          20   \n",
      "1                 1            4                           0   \n",
      "2                 2            3                         151   \n",
      "3                 3            2                           0   \n",
      "4                 3            2                           0   \n",
      "\n",
      "   Arrival_Delay_in_Minutes  \n",
      "0                        11  \n",
      "1                         0  \n",
      "2                       214  \n",
      "3                         0  \n",
      "4                         0  \n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 일부 확인\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     No\n",
      "1     No\n",
      "2     No\n",
      "3    Yes\n",
      "4     No\n",
      "Name: Satisfaction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 일부 확인\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6434 entries, 0 to 6433\n",
      "Data columns (total 20 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   Gender                             6434 non-null   object\n",
      " 1   Ages                               6434 non-null   object\n",
      " 2   Customer_Type                      6434 non-null   object\n",
      " 3   Class                              6434 non-null   object\n",
      " 4   Inflight_wifi_service              6434 non-null   int64 \n",
      " 5   Departure_Arrival_time_convenient  6434 non-null   int64 \n",
      " 6   Ease_of_Online_booking             6434 non-null   int64 \n",
      " 7   Gate_location                      6434 non-null   int64 \n",
      " 8   Food_and_drink                     6434 non-null   int64 \n",
      " 9   Online_boarding                    6434 non-null   int64 \n",
      " 10  Seat_comfort                       6434 non-null   int64 \n",
      " 11  Inflight_entertainment             6434 non-null   int64 \n",
      " 12  On_board_service                   6434 non-null   int64 \n",
      " 13  Leg_room_service                   6434 non-null   int64 \n",
      " 14  Baggage_handling                   6434 non-null   int64 \n",
      " 15  Checkin_service                    6434 non-null   int64 \n",
      " 16  Inflight_service                   6434 non-null   int64 \n",
      " 17  Cleanliness                        6434 non-null   int64 \n",
      " 18  Departure_Delay_in_Minutes         6434 non-null   int64 \n",
      " 19  Arrival_Delay_in_Minutes           6434 non-null   int64 \n",
      "dtypes: int64(16), object(4)\n",
      "memory usage: 1005.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1612 entries, 0 to 1611\n",
      "Data columns (total 20 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   Gender                             1612 non-null   object\n",
      " 1   Ages                               1612 non-null   object\n",
      " 2   Customer_Type                      1612 non-null   object\n",
      " 3   Class                              1612 non-null   object\n",
      " 4   Inflight_wifi_service              1612 non-null   int64 \n",
      " 5   Departure_Arrival_time_convenient  1612 non-null   int64 \n",
      " 6   Ease_of_Online_booking             1612 non-null   int64 \n",
      " 7   Gate_location                      1612 non-null   int64 \n",
      " 8   Food_and_drink                     1612 non-null   int64 \n",
      " 9   Online_boarding                    1612 non-null   int64 \n",
      " 10  Seat_comfort                       1612 non-null   int64 \n",
      " 11  Inflight_entertainment             1612 non-null   int64 \n",
      " 12  On_board_service                   1612 non-null   int64 \n",
      " 13  Leg_room_service                   1612 non-null   int64 \n",
      " 14  Baggage_handling                   1612 non-null   int64 \n",
      " 15  Checkin_service                    1612 non-null   int64 \n",
      " 16  Inflight_service                   1612 non-null   int64 \n",
      " 17  Cleanliness                        1612 non-null   int64 \n",
      " 18  Departure_Delay_in_Minutes         1612 non-null   int64 \n",
      " 19  Arrival_Delay_in_Minutes           1612 non-null   int64 \n",
      "dtypes: int64(16), object(4)\n",
      "memory usage: 252.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 6434 entries, 0 to 6433\n",
      "Series name: Satisfaction\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6434 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 50.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인\n",
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Inflight_wifi_service  Departure_Arrival_time_convenient  \\\n",
      "count            6434.000000                        6434.000000   \n",
      "mean                2.737333                           3.037613   \n",
      "std                 1.362034                           1.547572   \n",
      "min                 0.000000                           0.000000   \n",
      "25%                 2.000000                           2.000000   \n",
      "50%                 3.000000                           3.000000   \n",
      "75%                 4.000000                           4.000000   \n",
      "max                 5.000000                           5.000000   \n",
      "\n",
      "       Ease_of_Online_booking  Gate_location  Food_and_drink  Online_boarding  \\\n",
      "count             6434.000000    6434.000000     6434.000000      6434.000000   \n",
      "mean                 2.799036       3.016164        3.194591         3.282872   \n",
      "std                  1.433383       1.292237        1.334611         1.359697   \n",
      "min                  0.000000       1.000000        0.000000         0.000000   \n",
      "25%                  2.000000       2.000000        2.000000         2.000000   \n",
      "50%                  3.000000       3.000000        3.000000         4.000000   \n",
      "75%                  4.000000       4.000000        4.000000         4.000000   \n",
      "max                  5.000000       5.000000        5.000000         5.000000   \n",
      "\n",
      "       Seat_comfort  Inflight_entertainment  On_board_service  \\\n",
      "count   6434.000000             6434.000000       6434.000000   \n",
      "mean       3.461921                3.379235          3.420423   \n",
      "std        1.320489                1.334279          1.280846   \n",
      "min        1.000000                0.000000          0.000000   \n",
      "25%        2.000000                2.000000          3.000000   \n",
      "50%        4.000000                4.000000          4.000000   \n",
      "75%        5.000000                4.000000          4.000000   \n",
      "max        5.000000                5.000000          5.000000   \n",
      "\n",
      "       Leg_room_service  Baggage_handling  Checkin_service  Inflight_service  \\\n",
      "count       6434.000000       6434.000000      6434.000000       6434.000000   \n",
      "mean           3.383743          3.682313         3.345197          3.671433   \n",
      "std            1.310823          1.159491         1.267827          1.159274   \n",
      "min            0.000000          1.000000         1.000000          0.000000   \n",
      "25%            2.000000          3.000000         3.000000          3.000000   \n",
      "50%            4.000000          4.000000         3.000000          4.000000   \n",
      "75%            4.000000          5.000000         4.000000          5.000000   \n",
      "max            5.000000          5.000000         5.000000          5.000000   \n",
      "\n",
      "       Cleanliness  Departure_Delay_in_Minutes  Arrival_Delay_in_Minutes  \n",
      "count  6434.000000                 6434.000000               6434.000000  \n",
      "mean      3.284426                   15.092633                 15.686820  \n",
      "std       1.313427                   44.029329                 44.297168  \n",
      "min       0.000000                    0.000000                  0.000000  \n",
      "25%       2.000000                    0.000000                  0.000000  \n",
      "50%       3.000000                    0.000000                  0.000000  \n",
      "75%       4.000000                   12.000000                 13.000000  \n",
      "max       5.000000                 1592.000000               1584.000000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Inflight_wifi_service  Departure_Arrival_time_convenient  \\\n",
      "count            1612.000000                        1612.000000   \n",
      "mean                2.741935                           2.981390   \n",
      "std                 1.318033                           1.526395   \n",
      "min                 0.000000                           0.000000   \n",
      "25%                 2.000000                           2.000000   \n",
      "50%                 3.000000                           3.000000   \n",
      "75%                 4.000000                           4.000000   \n",
      "max                 5.000000                           5.000000   \n",
      "\n",
      "       Ease_of_Online_booking  Gate_location  Food_and_drink  Online_boarding  \\\n",
      "count             1612.000000    1612.000000     1612.000000       1612.00000   \n",
      "mean                 2.732010       2.934243        3.199752          3.23263   \n",
      "std                  1.386784       1.290040        1.319218          1.34302   \n",
      "min                  0.000000       1.000000        0.000000          0.00000   \n",
      "25%                  2.000000       2.000000        2.000000          2.00000   \n",
      "50%                  3.000000       3.000000        3.000000          3.00000   \n",
      "75%                  4.000000       4.000000        4.000000          4.00000   \n",
      "max                  5.000000       5.000000        5.000000          5.00000   \n",
      "\n",
      "       Seat_comfort  Inflight_entertainment  On_board_service  \\\n",
      "count   1612.000000             1612.000000       1612.000000   \n",
      "mean       3.445409                3.403846          3.375931   \n",
      "std        1.319339                1.317432          1.306097   \n",
      "min        1.000000                0.000000          1.000000   \n",
      "25%        3.000000                2.000000          2.000000   \n",
      "50%        4.000000                4.000000          4.000000   \n",
      "75%        5.000000                4.000000          4.000000   \n",
      "max        5.000000                5.000000          5.000000   \n",
      "\n",
      "       Leg_room_service  Baggage_handling  Checkin_service  Inflight_service  \\\n",
      "count       1612.000000       1612.000000      1612.000000       1612.000000   \n",
      "mean           3.414392          3.682382         3.276055          3.699752   \n",
      "std            1.306809          1.153996         1.285974          1.150575   \n",
      "min            0.000000          1.000000         1.000000          1.000000   \n",
      "25%            2.000000          3.000000         2.000000          3.000000   \n",
      "50%            4.000000          4.000000         3.000000          4.000000   \n",
      "75%            4.000000          5.000000         4.000000          5.000000   \n",
      "max            5.000000          5.000000         5.000000          5.000000   \n",
      "\n",
      "       Cleanliness  Departure_Delay_in_Minutes  Arrival_Delay_in_Minutes  \n",
      "count  1612.000000                 1612.000000               1612.000000  \n",
      "mean      3.310794                   15.045285                 15.887717  \n",
      "std       1.322886                   35.557908                 37.669515  \n",
      "min       0.000000                    0.000000                  0.000000  \n",
      "25%       2.000000                    0.000000                  0.000000  \n",
      "50%       3.000000                    0.000000                  0.000000  \n",
      "75%       4.000000                   14.000000                 15.000000  \n",
      "max       5.000000                  426.000000                427.000000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     6434\n",
      "unique       2\n",
      "top         No\n",
      "freq      3437\n",
      "Name: Satisfaction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                               0\n",
       "Ages                                 0\n",
       "Customer_Type                        0\n",
       "Class                                0\n",
       "Inflight_wifi_service                0\n",
       "Departure_Arrival_time_convenient    0\n",
       "Ease_of_Online_booking               0\n",
       "Gate_location                        0\n",
       "Food_and_drink                       0\n",
       "Online_boarding                      0\n",
       "Seat_comfort                         0\n",
       "Inflight_entertainment               0\n",
       "On_board_service                     0\n",
       "Leg_room_service                     0\n",
       "Baggage_handling                     0\n",
       "Checkin_service                      0\n",
       "Inflight_service                     0\n",
       "Cleanliness                          0\n",
       "Departure_Delay_in_Minutes           0\n",
       "Arrival_Delay_in_Minutes             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 전처리\n",
    "# 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                               0\n",
       "Ages                                 0\n",
       "Customer_Type                        0\n",
       "Class                                0\n",
       "Inflight_wifi_service                0\n",
       "Departure_Arrival_time_convenient    0\n",
       "Ease_of_Online_booking               0\n",
       "Gate_location                        0\n",
       "Food_and_drink                       0\n",
       "Online_boarding                      0\n",
       "Seat_comfort                         0\n",
       "Inflight_entertainment               0\n",
       "On_board_service                     0\n",
       "Leg_room_service                     0\n",
       "Baggage_handling                     0\n",
       "Checkin_service                      0\n",
       "Inflight_service                     0\n",
       "Cleanliness                          0\n",
       "Departure_Delay_in_Minutes           0\n",
       "Arrival_Delay_in_Minutes             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state = 1234, test_size = 0.3, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4503, 20)\n",
      "(1931, 20)\n",
      "(4503,)\n",
      "(1931,)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인\n",
    "print(X_TRAIN.shape)\n",
    "print(X_VAL.shape)\n",
    "print(y_TRAIN.shape)\n",
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩\n",
    "# 카테고리형 컬럼에 대하여 라벨 인코딩 수행\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 인코딩할 카테고리형 컬럼만 별도 저장\n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy()\n",
    "X_test_category = X_test.select_dtypes('object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "enc = OneHotEncoder(sparse_output = False).fit(X_TRAIN_category)\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "X_test_OH = enc.transform(X_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "# 별도 스케일링은 하지 않고 수치형 컬럼만 별도 저장\n",
    "X_TRAIN_conti = X_TRAIN.select_dtypes(exclude = 'object').copy()\n",
    "X_VAL_conti = X_VAL.select_dtypes(exclude = 'object').copy()\n",
    "X_test_conti = X_test.select_dtypes(exclude = 'object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터셋 준비\n",
    "import numpy as np\n",
    "\n",
    "# 인코딩과 스케일링된 넘파이 배열 연결\n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_conti], axis = 1)\n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_conti], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Yes'와 'No'를 각각 1,0에 매핑\n",
    "y_TRAIN = y_TRAIN.map({'No':0, 'Yes':1})\n",
    "y_VAL = y_VAL.map({'No':0, 'Yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 평탄화\n",
    "y_TRAIN = y_TRAIN.values.ravel()\n",
    "y_VAL = y_VAL.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 500,\n",
    "                            max_depth = 3,\n",
    "                            min_samples_leaf = 10,\n",
    "                            max_features = 'sqrt',\n",
    "                            random_state = 2022)\n",
    "\n",
    "model_rf = rf.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능평가(기준:F1-Score)를 통한 모델 선정\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측\n",
    "pred_rf = model_rf.predict(X_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 3유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_Grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_Grade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x\n",
       "0  3_Grade\n",
       "1  2_Grade\n",
       "2  2_Grade\n",
       "3  1_Grade\n",
       "4  3_Grade"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cancer = pd.read_csv('./data/cancer.csv', encoding = 'cp949')\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적합도 검정 수행\n",
    "from scipy.stats import chisquare\n",
    "n = cancer.shape[0]\n",
    "x = cancer.value_counts().to_numpy()\n",
    "x = np.append(x, [81])\n",
    "e_x = np.array([0.05, 0.05, 0.1, 0.8]) * n\n",
    "chi, pval = chisquare(x, e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# 항암약의 '부작용 없음'에 해당하는 관찰도수\n",
    "print(x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11766.270625000001\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 검정통계량과 p-value\n",
    "print(chi)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. 제공된 데이터(StudentsPerformance.csv)는 학생들의 시험 성적 데이터과 관련된 데이터의 일부이다. 여러 독립 변수들을 통해 성별(Gender)을 예측하는 로지스틱 회귀분석을 하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender     race  math score  reading score  writing score\n",
       "0  female  group B          72             72             74\n",
       "1  female  group C          69             90             88\n",
       "2  female  group B          90             95             93\n",
       "3    male  group A          47             57             44\n",
       "4    male  group C          76             78             75"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 패키지, 클래스 호출\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "StudentsPerformance = pd.read_csv('./data/StudentsPerformance.csv')\n",
    "StudentsPerformance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male -> 1, female -> 0로 인코딩\n",
    "StudentsPerformance['gender'] = StudentsPerformance['gender'].map({'male' : 1, 'female' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race 컬럼(범주형) 더미변수로 변환\n",
    "StudentsPerformance = pd.get_dummies(StudentsPerformance, columns = ['race'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습용과 평가용으로 나누기\n",
    "train = StudentsPerformance.iloc[0:800] # 1부터 800번까지\n",
    "test = StudentsPerformance.iloc[800:1000] # 801부터 1,000번까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터로 독립변수와 종속변수 지정\n",
    "y_train = train['gender'] # 종속변수\n",
    "X_train = train.drop('gender', axis = 1) # 독립변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>race_group B</th>\n",
       "      <th>race_group C</th>\n",
       "      <th>race_group D</th>\n",
       "      <th>race_group E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>70</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>69</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     math score  reading score  writing score  race_group B  race_group C  \\\n",
       "0            72             72             74          True         False   \n",
       "1            69             90             88         False          True   \n",
       "2            90             95             93          True         False   \n",
       "3            47             57             44         False         False   \n",
       "4            76             78             75         False          True   \n",
       "..          ...            ...            ...           ...           ...   \n",
       "795          57             68             73         False         False   \n",
       "796          70             70             70         False         False   \n",
       "797          70             84             81         False         False   \n",
       "798          69             60             54         False         False   \n",
       "799          52             55             57         False          True   \n",
       "\n",
       "     race_group D  race_group E  \n",
       "0           False         False  \n",
       "1           False         False  \n",
       "2           False         False  \n",
       "3           False         False  \n",
       "4           False         False  \n",
       "..            ...           ...  \n",
       "795         False          True  \n",
       "796          True         False  \n",
       "797         False          True  \n",
       "798         False          True  \n",
       "799         False         False  \n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:326\u001b[0m, in \u001b[0;36mGLM.__init__\u001b[1;34m(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights \u001b[38;5;241m=\u001b[39m freq_weights\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights \u001b[38;5;241m=\u001b[39m var_weights\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexposure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfreq_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvar_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_inputs(family, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog,\n\u001b[0;32m    331\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "sm.GLM(y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 로지스틱 회귀분석\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# GLM 객체 생성 후 적합\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamilies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:326\u001b[0m, in \u001b[0;36mGLM.__init__\u001b[1;34m(self, endog, exog, family, offset, exposure, freq_weights, var_weights, missing, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights \u001b[38;5;241m=\u001b[39m freq_weights\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights \u001b[38;5;241m=\u001b[39m var_weights\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexposure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfreq_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvar_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_inputs(family, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog,\n\u001b[0;32m    331\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_weights)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀분석\n",
    "# GLM 객체 생성 후 적합\n",
    "sm.GLM(y_train, X_train, family = sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. 제공된 데이터(mtcars.csv)는 자동차 32종의 정보를 담고 있는 데이터로 알려져있다. 배기량, 마력, 기어, 무게를 입력하면 연비를 예측하는 다중 선형 회귀 분석을 하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mtcars = pd.read_csv('./data/mtcars.csv', encoding = 'cp949')\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)독립변수들 중 종속변수와 가장 높은 선형성을 가지는 변수의 상관계수\n",
    "df = mtcars[['mpg', 'disp', 'hp', 'drat', 'wt']]\n",
    "\n",
    "# 종속변수와 각 변수들 간의 상관계수 계산한 후 가장 큰 상관계수를 구하면 됨\n",
    "corr = df.corr()['mpg'].abs().sort_values(ascending = False)[1]\n",
    "result1 = round(corr, 3)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)적합된 회귀모형의 결정계수\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "X = df[['disp', 'hp', 'drat', 'wt']]\n",
    "y = df[['mpg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수항 추가\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.838\n",
      "Model:                            OLS   Adj. R-squared:                  0.814\n",
      "Method:                 Least Squares   F-statistic:                     34.82\n",
      "Date:                Mon, 03 Jun 2024   Prob (F-statistic):           2.70e-10\n",
      "Time:                        23:34:46   Log-Likelihood:                -73.292\n",
      "No. Observations:                  32   AIC:                             156.6\n",
      "Df Residuals:                      27   BIC:                             163.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         29.1487      6.294      4.631      0.000      16.235      42.062\n",
      "disp           0.0038      0.011      0.353      0.727      -0.018       0.026\n",
      "hp            -0.0348      0.012     -2.999      0.006      -0.059      -0.011\n",
      "drat           1.7680      1.320      1.340      0.192      -0.940       4.476\n",
      "wt            -3.4797      1.078     -3.227      0.003      -5.692      -1.267\n",
      "==============================================================================\n",
      "Omnibus:                        5.267   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.899   Prob(JB):                        0.115\n",
      "Kurtosis:                       3.102   Cond. No.                     4.26e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.26e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# 다중선형회귀모형\n",
    "# OLS 객체 생성 후 적합\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary()) # 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838\n"
     ]
    }
   ],
   "source": [
    "# 회귀모형의 결정계수 출력\n",
    "# 위의 결과에서 R-squared값을 입력\n",
    "print(0.838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004\n"
     ]
    }
   ],
   "source": [
    "# 독립 변수들 중 가장 유의하지 않은 독립변수의 회귀계수 추정값\n",
    "# 위의 결과에서 P>|t|값이 가장 큰 변수명을 찾으면 됨\n",
    "# disp가 가장 p-value가 크므로 disp의 회귀계수 추정값 계산\n",
    "# 위의 결과애서 disp의 coef값을 입력해도 됨\n",
    "print(0.004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빅데이터 분석기사 제7회 기출문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 1유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연도</th>\n",
       "      <th>직종</th>\n",
       "      <th>회차</th>\n",
       "      <th>일련번호</th>\n",
       "      <th>과목명</th>\n",
       "      <th>과목별점수</th>\n",
       "      <th>총점</th>\n",
       "      <th>합격여부</th>\n",
       "      <th>성별</th>\n",
       "      <th>연령대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>간호사</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>지역사회간호학</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>결시</td>\n",
       "      <td>여</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>간호사</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>아동간호학</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>결시</td>\n",
       "      <td>여</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>간호사</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>성인간호학</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>결시</td>\n",
       "      <td>여</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>간호사</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>보건의약관계 법규</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>결시</td>\n",
       "      <td>여</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>간호사</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>기본간호학</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>결시</td>\n",
       "      <td>여</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     연도                                     직종    회차  일련번호        과목명  과목별점수  \\\n",
       "0  2023  간호사                                    63.0     1    지역사회간호학    0.0   \n",
       "1  2023  간호사                                    63.0     1      아동간호학    0.0   \n",
       "2  2023  간호사                                    63.0     1      성인간호학    0.0   \n",
       "3  2023  간호사                                    63.0     1  보건의약관계 법규    0.0   \n",
       "4  2023  간호사                                    63.0     1      기본간호학    0.0   \n",
       "\n",
       "    총점 합격여부 성별  연령대  \n",
       "0  0.0   결시  여   50  \n",
       "1  0.0   결시  여   50  \n",
       "2  0.0   결시  여   50  \n",
       "3  0.0   결시  여   50  \n",
       "4  0.0   결시  여   50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_score = pd.read_csv('./data/test_score.csv', encoding = 'cp949')\n",
    "test_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행, 열 확인\n",
    "test_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 응시자가 가장 많은 연령대를 추출\n",
    "# 결측값이 존재하는 행 제외\n",
    "test_score = test_score.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응시자가 가장 많은 연령대 추출\n",
    "age = test_score['연령대'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 20대의 기본간호학 과목의 가장 높은 표준화된 점수 출력\n",
    "# 20대의 기본간호학 과목 점수 표준화\n",
    "cond = (test_score['연령대'] == age) & (test_score['과목명'] == '기본간호학')\n",
    "score = test_score[cond]['과목별점수'] # 20대의 기본간호학 과목의 점수\n",
    "score_std = (score - score.mean()) / score.std() # 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 높은 표준화된 점수\n",
    "result = score_std.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5963\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "result = round(result, 4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  progression  \n",
       "0 -0.002592  0.019907 -0.017646        151.0  \n",
       "1 -0.039493 -0.068332 -0.092204         75.0  \n",
       "2 -0.002592  0.002861 -0.025930        141.0  \n",
       "3  0.034309  0.022688 -0.009362        206.0  \n",
       "4 -0.002592 -0.031988 -0.046641        135.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diabetes = pd.read_csv('./data/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### progression 컬럼과 가장 상관관계가 높은 컬럼\n",
    "# progression 컬럼과 다른 컬럼들 간의 모든 상관관계를 계산하고 절댓값을 취한 후 순서대로 정렬\n",
    "corr = diabetes.corr()['progression'].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계가 가장 높은 컬럼명\n",
    "high_corr = corr.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 상관관계가 가장 높은 컬럼의 최댓값\n",
    "# 선택된 컬럼의 최댓값\n",
    "result = diabetes[high_corr].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "##### 결과 출력\n",
    "result = round(result, 2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('./data/iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### sepal_length의 이상치 탐색\n",
    "# sepal_length 변수의 결측치를 중앙값으로 대체\n",
    "med = iris['sepal_length'].median() # sepal_length 컬럼의 결측치를 제외한 중앙값\n",
    "iris['sepal_length'] = iris['sepal_length'].fillna(med) # 결측치 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR = Q3 - Q1 계산\n",
    "q1 = iris['sepal_length'].quantile(0.25)\n",
    "q3 = iris['sepal_length'].quantile(0.75)\n",
    "iqr = q3 - q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR을 벗어난 데이터\n",
    "outlier = iris[(iris['sepal_length'] < (q1-1.5*iqr)) | (iris['sepal_length'] > (q3+1.5*iqr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "##### 결과 출력\n",
    "result = len(outlier['sepal_length'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP1. 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/Flight_train.csv')\n",
    "test = pd.read_csv('./data/Flight_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 X_train과 y_train으로 분할\n",
    "y_train = train['price']\n",
    "X_train = train.drop('price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test도 통일을 위해 X_test로 할당\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-874</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Economy</td>\n",
       "      <td>5.58</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-687</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>zero</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Business</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-830</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Economy</td>\n",
       "      <td>23.25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO_FIRST</td>\n",
       "      <td>G8-803</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Late_Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>7.17</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>6E-5338</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Economy</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline   flight source_city departure_time stops arrival_time  \\\n",
       "0    Vistara   UK-874   Hyderabad        Morning   one    Afternoon   \n",
       "1  Air_India   AI-687      Mumbai      Afternoon  zero      Evening   \n",
       "2    Vistara   UK-830   Hyderabad        Morning   one      Morning   \n",
       "3   GO_FIRST   G8-803   Bangalore        Evening   one   Late_Night   \n",
       "4     Indigo  6E-5338      Mumbai        Morning   one    Afternoon   \n",
       "\n",
       "  destination_city     class  duration  days_left  \n",
       "0            Delhi   Economy      5.58         10  \n",
       "1            Delhi  Business      2.25         12  \n",
       "2          Kolkata   Economy     23.25         19  \n",
       "3           Mumbai   Economy      7.17         37  \n",
       "4          Kolkata   Economy      7.33          8  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### STEP2. 데이터셋 확인하기\n",
    "###### STEP2-1. 데이터셋 일부 확인\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>6E-6219</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Economy</td>\n",
       "      <td>4.92</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air_India</td>\n",
       "      <td>AI-503</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Economy</td>\n",
       "      <td>18.08</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-830</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-877</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>1.50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>6E-5366</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Economy</td>\n",
       "      <td>1.83</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline   flight source_city departure_time stops arrival_time  \\\n",
       "0     Indigo  6E-6219     Chennai        Morning   one    Afternoon   \n",
       "1  Air_India   AI-503   Bangalore        Evening   one      Morning   \n",
       "2    Vistara   UK-830   Hyderabad        Morning   one      Evening   \n",
       "3    Vistara   UK-877      Mumbai        Morning  zero    Afternoon   \n",
       "4     Indigo  6E-5366      Mumbai        Morning  zero      Morning   \n",
       "\n",
       "  destination_city     class  duration  days_left  \n",
       "0            Delhi   Economy      4.92         10  \n",
       "1        Hyderabad   Economy     18.08         46  \n",
       "2          Chennai   Economy      6.00          4  \n",
       "3        Hyderabad  Business      1.50         25  \n",
       "4        Bangalore   Economy      1.83         26  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10018\n",
       "1    30080\n",
       "2     5960\n",
       "3     4354\n",
       "4    10406\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7203 entries, 0 to 7202\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           7203 non-null   object \n",
      " 1   flight            7203 non-null   object \n",
      " 2   source_city       7203 non-null   object \n",
      " 3   departure_time    7203 non-null   object \n",
      " 4   stops             7203 non-null   object \n",
      " 5   arrival_time      7203 non-null   object \n",
      " 6   destination_city  7203 non-null   object \n",
      " 7   class             7203 non-null   object \n",
      " 8   duration          7203 non-null   float64\n",
      " 9   days_left         7203 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 562.9+ KB\n"
     ]
    }
   ],
   "source": [
    "###### STEP2-2. 데이터셋 요약 정보 확인\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1801 entries, 0 to 1800\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           1801 non-null   object \n",
      " 1   flight            1801 non-null   object \n",
      " 2   source_city       1801 non-null   object \n",
      " 3   departure_time    1801 non-null   object \n",
      " 4   stops             1801 non-null   object \n",
      " 5   arrival_time      1801 non-null   object \n",
      " 6   destination_city  1801 non-null   object \n",
      " 7   class             1801 non-null   object \n",
      " 8   duration          1801 non-null   float64\n",
      " 9   days_left         1801 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 7203 entries, 0 to 7202\n",
      "Series name: price\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "7203 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 56.4 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7203.000000</td>\n",
       "      <td>7203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.133993</td>\n",
       "      <td>25.891434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.141223</td>\n",
       "      <td>13.565403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.670000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.080000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.750000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration    days_left\n",
       "count  7203.000000  7203.000000\n",
       "mean     12.133993    25.891434\n",
       "std       7.141223    13.565403\n",
       "min       0.920000     1.000000\n",
       "25%       6.670000    14.000000\n",
       "50%      11.250000    26.000000\n",
       "75%      16.080000    38.000000\n",
       "max      39.750000    49.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP2-3. 기초통계량 확인\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1801.000000</td>\n",
       "      <td>1801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.987307</td>\n",
       "      <td>25.828984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.166587</td>\n",
       "      <td>13.596881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.670000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.830000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.330000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration    days_left\n",
       "count  1801.000000  1801.000000\n",
       "mean     11.987307    25.828984\n",
       "std       7.166587    13.596881\n",
       "min       1.000000     1.000000\n",
       "25%       6.670000    14.000000\n",
       "50%      11.000000    26.000000\n",
       "75%      15.830000    37.000000\n",
       "max      38.330000    49.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      7203.000000\n",
       "mean      21072.043593\n",
       "std       22674.141358\n",
       "min        1105.000000\n",
       "25%        4750.500000\n",
       "50%        7488.000000\n",
       "75%       44144.000000\n",
       "max      116562.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP3. 데이터셋 전처리\n",
    "###### STEP3-1. 불필요한 컬럼 삭제\n",
    "# flight 컬럼 삭제\n",
    "X_train = X_train.drop(columns = 'flight')\n",
    "X_test = X_test.drop(columns = 'flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline             0\n",
       "source_city         0\n",
       "departure_time      0\n",
       "stops               0\n",
       "arrival_time        0\n",
       "destination_city    0\n",
       "class               0\n",
       "duration            0\n",
       "days_left           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### STEP3-2. 결측치 처리\n",
    "# 결측치 확인\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline             0\n",
       "source_city         0\n",
       "departure_time      0\n",
       "stops               0\n",
       "arrival_time        0\n",
       "destination_city    0\n",
       "class               0\n",
       "duration            0\n",
       "days_left           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-3. 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용로 분할\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state = 2024, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5762, 9)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인\n",
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1441, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5762,)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1441,)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-4. 인코딩\n",
    "# 카테고리형 컬럼에 대하여 라벨 인코딩 수행\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 인코딩할 카테고리형 컬럼만 별도 저장\n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy()\n",
    "X_test_category = X_test.select_dtypes('object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "enc = OneHotEncoder(sparse_output=False).fit(X_TRAIN_category)\n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "X_test_OH = enc.transform(X_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-5. 스케일링\n",
    "X_TRAIN_conti = X_TRAIN.select_dtypes(exclude = 'object').copy()\n",
    "X_VAL_conti = X_VAL.select_dtypes(exclude = 'object').copy()\n",
    "X_test_conti = X_test.select_dtypes(exclude = 'object').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP3-6. 입력 데이터셋 준비\n",
    "import numpy as np\n",
    "\n",
    "# 인코딩과 스케일링된 넘파이 배열 연결\n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_conti], axis = 1)\n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_conti], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP4. 모델 학습\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STEP4-1. Random Forest\n",
    "rf = RandomForestRegressor(n_estimators = 100,\n",
    "                            max_depth = 3,\n",
    "                            min_samples_leaf = 10,\n",
    "                            max_features = 15,\n",
    "                            random_state = 2024)\n",
    "model_rf = rf.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "####### STEP4-2. XGBoost\n",
    "xgb = XGBRegressor(n_estimators = 100,\n",
    "                   nthread = 5,\n",
    "                   min_child_weight = 20,\n",
    "                   gamma = 0.5,\n",
    "                   objective = 'reg:squarederror',\n",
    "                   use_label_encoder = False,\n",
    "                   random_state = 2024)\n",
    "model_xgb = xgb.fit(X_TRAIN, y_TRAIN, eval_metric = 'rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375\n",
      "[LightGBM] [Info] Number of data points in the train set: 5762, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 21107.638841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "####### STEP4-3. LightGBM\n",
    "lgb = LGBMRegressor(max_depth = 8,\n",
    "                    n_estimators = 100,\n",
    "                    n_jobs = 30,\n",
    "                    min_child_weight = 10,\n",
    "                    learning_rate = 0.2,\n",
    "                    objective = 'regression',\n",
    "                    random_state = 2024)\n",
    "model_lgb = lgb.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STEP4-4. 성능평가(RMSE)를 통한 모델 선정\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측\n",
    "pred_rf = model_rf.predict(X_VAL)\n",
    "pred_xgb = model_xgb.predict(X_VAL)\n",
    "pred_lgb = model_lgb.predict(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5877.324696221526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# RMSE 계산\n",
    "rmse_rt = mean_squared_error(y_VAL, pred_rf, squared = False)\n",
    "print(rmse_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4572.601687977391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse_xgb = mean_squared_error(y_VAL, pred_xgb, squared = False)\n",
    "print(rmse_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4516.864616984586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taek5\\Desktop\\BigDataAnalysis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse_lgb = mean_squared_error(y_VAL, pred_lgb, squared = False)\n",
    "print(rmse_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STEP5. 결과 제출하기\n",
    "X_TEST = np.concatenate([X_test_OH, X_test_conti], axis = 1) \n",
    "y_pred = model_xgb.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = {'pred' : y_pred}\n",
    "result = pd.DataFrame(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.linear_model in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.linear_model - The :mod:`sklearn.linear_model` module implements a variety of linear models.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _base\n",
      "    _bayes\n",
      "    _cd_fast\n",
      "    _coordinate_descent\n",
      "    _glm (package)\n",
      "    _huber\n",
      "    _least_angle\n",
      "    _linear_loss\n",
      "    _logistic\n",
      "    _omp\n",
      "    _passive_aggressive\n",
      "    _perceptron\n",
      "    _quantile\n",
      "    _ransac\n",
      "    _ridge\n",
      "    _sag\n",
      "    _sag_fast\n",
      "    _sgd_fast\n",
      "    _stochastic_gradient\n",
      "    _theil_sen\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    sklearn.base.BaseEstimator(sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin, sklearn.utils._metadata_requests._MetadataRequester)\n",
      "        sklearn.linear_model._huber.HuberRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._logistic.LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      "            sklearn.linear_model._logistic.LogisticRegressionCV(sklearn.linear_model._logistic.LogisticRegression, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._quantile.QuantileRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._ransac.RANSACRegressor(sklearn.base.MetaEstimatorMixin, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.base.MetaEstimatorMixin(builtins.object)\n",
      "        sklearn.linear_model._ransac.RANSACRegressor(sklearn.base.MetaEstimatorMixin, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.base.MultiOutputMixin(builtins.object)\n",
      "        sklearn.linear_model._base.LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._coordinate_descent.ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._coordinate_descent.Lasso\n",
      "                sklearn.linear_model._coordinate_descent.MultiTaskElasticNet\n",
      "                    sklearn.linear_model._coordinate_descent.MultiTaskLasso\n",
      "        sklearn.linear_model._least_angle.Lars(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._least_angle.LarsCV\n",
      "                sklearn.linear_model._least_angle.LassoLarsCV\n",
      "            sklearn.linear_model._least_angle.LassoLars\n",
      "                sklearn.linear_model._least_angle.LassoLarsIC\n",
      "        sklearn.linear_model._omp.OrthogonalMatchingPursuit(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._ransac.RANSACRegressor(sklearn.base.MetaEstimatorMixin, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._ridge.Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidge)\n",
      "        sklearn.linear_model._ridge.RidgeCV(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidgeCV)\n",
      "    sklearn.base.OutlierMixin(builtins.object)\n",
      "        sklearn.linear_model._stochastic_gradient.SGDOneClassSVM(sklearn.linear_model._stochastic_gradient.BaseSGD, sklearn.base.OutlierMixin)\n",
      "    sklearn.base.RegressorMixin(builtins.object)\n",
      "        sklearn.linear_model._base.LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._bayes.ARDRegression(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._bayes.BayesianRidge(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._coordinate_descent.ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._coordinate_descent.Lasso\n",
      "                sklearn.linear_model._coordinate_descent.MultiTaskElasticNet\n",
      "                    sklearn.linear_model._coordinate_descent.MultiTaskLasso\n",
      "        sklearn.linear_model._coordinate_descent.ElasticNetCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.LassoCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.MultiTaskLassoCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._huber.HuberRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._least_angle.Lars(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._least_angle.LarsCV\n",
      "                sklearn.linear_model._least_angle.LassoLarsCV\n",
      "            sklearn.linear_model._least_angle.LassoLars\n",
      "                sklearn.linear_model._least_angle.LassoLarsIC\n",
      "        sklearn.linear_model._omp.OrthogonalMatchingPursuit(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._omp.OrthogonalMatchingPursuitCV(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._quantile.QuantileRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._ransac.RANSACRegressor(sklearn.base.MetaEstimatorMixin, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._ridge.Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidge)\n",
      "        sklearn.linear_model._ridge.RidgeCV(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidgeCV)\n",
      "        sklearn.linear_model._theil_sen.TheilSenRegressor(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "    sklearn.linear_model._base.LinearClassifierMixin(sklearn.base.ClassifierMixin)\n",
      "        sklearn.linear_model._logistic.LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      "            sklearn.linear_model._logistic.LogisticRegressionCV(sklearn.linear_model._logistic.LogisticRegression, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.linear_model._base.LinearModel(sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._base.LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._bayes.ARDRegression(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._bayes.BayesianRidge(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._coordinate_descent.ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._coordinate_descent.Lasso\n",
      "                sklearn.linear_model._coordinate_descent.MultiTaskElasticNet\n",
      "                    sklearn.linear_model._coordinate_descent.MultiTaskLasso\n",
      "        sklearn.linear_model._huber.HuberRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._least_angle.Lars(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "            sklearn.linear_model._least_angle.LarsCV\n",
      "                sklearn.linear_model._least_angle.LassoLarsCV\n",
      "            sklearn.linear_model._least_angle.LassoLars\n",
      "                sklearn.linear_model._least_angle.LassoLarsIC\n",
      "        sklearn.linear_model._omp.OrthogonalMatchingPursuit(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._omp.OrthogonalMatchingPursuitCV(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._quantile.QuantileRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._theil_sen.TheilSenRegressor(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "    sklearn.linear_model._base.SparseCoefMixin(builtins.object)\n",
      "        sklearn.linear_model._logistic.LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      "            sklearn.linear_model._logistic.LogisticRegressionCV(sklearn.linear_model._logistic.LogisticRegression, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.linear_model._coordinate_descent.LinearModelCV(sklearn.base.MultiOutputMixin, sklearn.linear_model._base.LinearModel, abc.ABC)\n",
      "        sklearn.linear_model._coordinate_descent.ElasticNetCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.LassoCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "        sklearn.linear_model._coordinate_descent.MultiTaskLassoCV(sklearn.base.RegressorMixin, sklearn.linear_model._coordinate_descent.LinearModelCV)\n",
      "    sklearn.linear_model._glm.glm._GeneralizedLinearRegressor(sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._glm.glm.GammaRegressor\n",
      "        sklearn.linear_model._glm.glm.PoissonRegressor\n",
      "        sklearn.linear_model._glm.glm.TweedieRegressor\n",
      "    sklearn.linear_model._ridge._BaseRidge(sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._ridge.Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidge)\n",
      "        sklearn.linear_model._ridge.RidgeClassifier(sklearn.linear_model._ridge._RidgeClassifierMixin, sklearn.linear_model._ridge._BaseRidge)\n",
      "    sklearn.linear_model._ridge._BaseRidgeCV(sklearn.linear_model._base.LinearModel)\n",
      "        sklearn.linear_model._ridge.RidgeCV(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._ridge._BaseRidgeCV)\n",
      "        sklearn.linear_model._ridge.RidgeClassifierCV(sklearn.linear_model._ridge._RidgeClassifierMixin, sklearn.linear_model._ridge._BaseRidgeCV)\n",
      "    sklearn.linear_model._ridge._RidgeClassifierMixin(sklearn.linear_model._base.LinearClassifierMixin)\n",
      "        sklearn.linear_model._ridge.RidgeClassifier(sklearn.linear_model._ridge._RidgeClassifierMixin, sklearn.linear_model._ridge._BaseRidge)\n",
      "        sklearn.linear_model._ridge.RidgeClassifierCV(sklearn.linear_model._ridge._RidgeClassifierMixin, sklearn.linear_model._ridge._BaseRidgeCV)\n",
      "    sklearn.linear_model._sgd_fast.Classification(sklearn.linear_model._sgd_fast.LossFunction)\n",
      "        sklearn.linear_model._sgd_fast.Hinge\n",
      "        sklearn.linear_model._sgd_fast.Log\n",
      "        sklearn.linear_model._sgd_fast.ModifiedHuber\n",
      "    sklearn.linear_model._sgd_fast.Regression(sklearn.linear_model._sgd_fast.LossFunction)\n",
      "        sklearn.linear_model._sgd_fast.Huber\n",
      "        sklearn.linear_model._sgd_fast.SquaredLoss\n",
      "    sklearn.linear_model._stochastic_gradient.BaseSGD(sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.linear_model._stochastic_gradient.SGDOneClassSVM(sklearn.linear_model._stochastic_gradient.BaseSGD, sklearn.base.OutlierMixin)\n",
      "    sklearn.linear_model._stochastic_gradient.BaseSGDClassifier(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._stochastic_gradient.BaseSGD)\n",
      "        sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier\n",
      "        sklearn.linear_model._perceptron.Perceptron\n",
      "        sklearn.linear_model._stochastic_gradient.SGDClassifier\n",
      "    sklearn.linear_model._stochastic_gradient.BaseSGDRegressor(sklearn.base.RegressorMixin, sklearn.linear_model._stochastic_gradient.BaseSGD)\n",
      "        sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor\n",
      "        sklearn.linear_model._stochastic_gradient.SGDRegressor\n",
      "\n",
      "    class ARDRegression(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  ARDRegression(*, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, compute_score=False, threshold_lambda=10000.0, fit_intercept=True, copy_X=True, verbose=False)\n",
      "     |\n",
      "     |  Bayesian ARD regression.\n",
      "     |\n",
      "     |  Fit the weights of a regression model, using an ARD prior. The weights of\n",
      "     |  the regression model are assumed to be in Gaussian distributions.\n",
      "     |  Also estimate the parameters lambda (precisions of the distributions of the\n",
      "     |  weights) and alpha (precision of the distribution of the noise).\n",
      "     |  The estimation is done by an iterative procedures (Evidence Maximization)\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <bayesian_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  max_iter : int, default=300\n",
      "     |      Maximum number of iterations.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.3\n",
      "     |\n",
      "     |  tol : float, default=1e-3\n",
      "     |      Stop the algorithm if w has converged.\n",
      "     |\n",
      "     |  alpha_1 : float, default=1e-6\n",
      "     |      Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "     |      over the alpha parameter.\n",
      "     |\n",
      "     |  alpha_2 : float, default=1e-6\n",
      "     |      Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "     |      Gamma distribution prior over the alpha parameter.\n",
      "     |\n",
      "     |  lambda_1 : float, default=1e-6\n",
      "     |      Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "     |      over the lambda parameter.\n",
      "     |\n",
      "     |  lambda_2 : float, default=1e-6\n",
      "     |      Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "     |      Gamma distribution prior over the lambda parameter.\n",
      "     |\n",
      "     |  compute_score : bool, default=False\n",
      "     |      If True, compute the objective function at each step of the model.\n",
      "     |\n",
      "     |  threshold_lambda : float, default=10 000\n",
      "     |      Threshold for removing (pruning) weights with high precision from\n",
      "     |      the computation.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  verbose : bool, default=False\n",
      "     |      Verbose mode when fitting the model.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array-like of shape (n_features,)\n",
      "     |      Coefficients of the regression model (mean of distribution)\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |     estimated precision of the noise.\n",
      "     |\n",
      "     |  lambda_ : array-like of shape (n_features,)\n",
      "     |     estimated precisions of the weights.\n",
      "     |\n",
      "     |  sigma_ : array-like of shape (n_features, n_features)\n",
      "     |      estimated variance-covariance matrix of the weights\n",
      "     |\n",
      "     |  scores_ : float\n",
      "     |      if computed, value of the objective function (to be maximized)\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      ``fit_intercept = False``.\n",
      "     |\n",
      "     |  X_offset_ : float\n",
      "     |      If `fit_intercept=True`, offset subtracted for centering data to a\n",
      "     |      zero mean. Set to np.zeros(n_features) otherwise.\n",
      "     |\n",
      "     |  X_scale_ : float\n",
      "     |      Set to np.ones(n_features).\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  BayesianRidge : Bayesian ridge regression.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  For an example, see :ref:`examples/linear_model/plot_ard.py\n",
      "     |  <sphx_glr_auto_examples_linear_model_plot_ard.py>`.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  D. J. C. MacKay, Bayesian nonlinear modeling for the prediction\n",
      "     |  competition, ASHRAE Transactions, 1994.\n",
      "     |\n",
      "     |  R. Salakhutdinov, Lecture notes on Statistical Machine Learning,\n",
      "     |  http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15\n",
      "     |  Their beta is our ``self.alpha_``\n",
      "     |  Their alpha is our ``self.lambda_``\n",
      "     |  ARD is a little different than the slide: only dimensions/features for\n",
      "     |  which ``self.lambda_ < self.threshold_lambda`` are kept and the rest are\n",
      "     |  discarded.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.ARDRegression()\n",
      "     |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      "     |  ARDRegression()\n",
      "     |  >>> clf.predict([[1, 1]])\n",
      "     |  array([1.])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ARDRegression\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, compute_score=False, threshold_lambda=10000.0, fit_intercept=True, copy_X=True, verbose=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit the model according to the given training data and parameters.\n",
      "     |\n",
      "     |      Iterative procedure to maximize the evidence\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vector, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values (integers). Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  predict(self, X, return_std=False)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      In addition to the mean of the predictive distribution, also its\n",
      "     |      standard deviation can be returned.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      return_std : bool, default=False\n",
      "     |          Whether to return the standard deviation of posterior prediction.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_mean : array-like of shape (n_samples,)\n",
      "     |          Mean of predictive distribution of query points.\n",
      "     |\n",
      "     |      y_std : array-like of shape (n_samples,)\n",
      "     |          Standard deviation of predictive distribution of query points.\n",
      "     |\n",
      "     |  set_predict_request(self: sklearn.linear_model._bayes.ARDRegression, *, return_std: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._bayes.ARDRegression\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      return_std : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``return_std`` parameter in ``predict``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._bayes.ARDRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._bayes.ARDRegression\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class BayesianRidge(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  BayesianRidge(*, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, alpha_init=None, lambda_init=None, compute_score=False, fit_intercept=True, copy_X=True, verbose=False)\n",
      "     |\n",
      "     |  Bayesian ridge regression.\n",
      "     |\n",
      "     |  Fit a Bayesian ridge model. See the Notes section for details on this\n",
      "     |  implementation and the optimization of the regularization parameters\n",
      "     |  lambda (precision of the weights) and alpha (precision of the noise).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <bayesian_regression>`.\n",
      "     |  For an intuitive visualization of how the sinusoid is approximated by\n",
      "     |  a polynomial using different pairs of initial values, see\n",
      "     |  :ref:`sphx_glr_auto_examples_linear_model_plot_bayesian_ridge_curvefit.py`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  max_iter : int, default=300\n",
      "     |      Maximum number of iterations over the complete dataset before\n",
      "     |      stopping independently of any early stopping criterion.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.3\n",
      "     |\n",
      "     |  tol : float, default=1e-3\n",
      "     |      Stop the algorithm if w has converged.\n",
      "     |\n",
      "     |  alpha_1 : float, default=1e-6\n",
      "     |      Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "     |      over the alpha parameter.\n",
      "     |\n",
      "     |  alpha_2 : float, default=1e-6\n",
      "     |      Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "     |      Gamma distribution prior over the alpha parameter.\n",
      "     |\n",
      "     |  lambda_1 : float, default=1e-6\n",
      "     |      Hyper-parameter : shape parameter for the Gamma distribution prior\n",
      "     |      over the lambda parameter.\n",
      "     |\n",
      "     |  lambda_2 : float, default=1e-6\n",
      "     |      Hyper-parameter : inverse scale parameter (rate parameter) for the\n",
      "     |      Gamma distribution prior over the lambda parameter.\n",
      "     |\n",
      "     |  alpha_init : float, default=None\n",
      "     |      Initial value for alpha (precision of the noise).\n",
      "     |      If not set, alpha_init is 1/Var(y).\n",
      "     |\n",
      "     |          .. versionadded:: 0.22\n",
      "     |\n",
      "     |  lambda_init : float, default=None\n",
      "     |      Initial value for lambda (precision of the weights).\n",
      "     |      If not set, lambda_init is 1.\n",
      "     |\n",
      "     |          .. versionadded:: 0.22\n",
      "     |\n",
      "     |  compute_score : bool, default=False\n",
      "     |      If True, compute the log marginal likelihood at each iteration of the\n",
      "     |      optimization.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model.\n",
      "     |      The intercept is not treated as a probabilistic parameter\n",
      "     |      and thus has no associated variance. If set\n",
      "     |      to False, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  verbose : bool, default=False\n",
      "     |      Verbose mode when fitting the model.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array-like of shape (n_features,)\n",
      "     |      Coefficients of the regression model (mean of distribution)\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      `fit_intercept = False`.\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |     Estimated precision of the noise.\n",
      "     |\n",
      "     |  lambda_ : float\n",
      "     |     Estimated precision of the weights.\n",
      "     |\n",
      "     |  sigma_ : array-like of shape (n_features, n_features)\n",
      "     |      Estimated variance-covariance matrix of the weights\n",
      "     |\n",
      "     |  scores_ : array-like of shape (n_iter_+1,)\n",
      "     |      If computed_score is True, value of the log marginal likelihood (to be\n",
      "     |      maximized) at each iteration of the optimization. The array starts\n",
      "     |      with the value of the log marginal likelihood obtained for the initial\n",
      "     |      values of alpha and lambda and ends with the value obtained for the\n",
      "     |      estimated alpha and lambda.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |\n",
      "     |  X_offset_ : ndarray of shape (n_features,)\n",
      "     |      If `fit_intercept=True`, offset subtracted for centering data to a\n",
      "     |      zero mean. Set to np.zeros(n_features) otherwise.\n",
      "     |\n",
      "     |  X_scale_ : ndarray of shape (n_features,)\n",
      "     |      Set to np.ones(n_features).\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  ARDRegression : Bayesian ARD regression.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  There exist several strategies to perform Bayesian ridge regression. This\n",
      "     |  implementation is based on the algorithm described in Appendix A of\n",
      "     |  (Tipping, 2001) where updates of the regularization parameters are done as\n",
      "     |  suggested in (MacKay, 1992). Note that according to A New\n",
      "     |  View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these\n",
      "     |  update rules do not guarantee that the marginal likelihood is increasing\n",
      "     |  between two consecutive iterations of the optimization.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  D. J. C. MacKay, Bayesian Interpolation, Computation and Neural Systems,\n",
      "     |  Vol. 4, No. 3, 1992.\n",
      "     |\n",
      "     |  M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine,\n",
      "     |  Journal of Machine Learning Research, Vol. 1, 2001.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.BayesianRidge()\n",
      "     |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      "     |  BayesianRidge()\n",
      "     |  >>> clf.predict([[1, 1]])\n",
      "     |  array([1.])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      BayesianRidge\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, max_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, alpha_init=None, lambda_init=None, compute_score=False, fit_intercept=True, copy_X=True, verbose=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : ndarray of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample.\n",
      "     |\n",
      "     |          .. versionadded:: 0.20\n",
      "     |             parameter *sample_weight* support to BayesianRidge.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |\n",
      "     |  predict(self, X, return_std=False)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      In addition to the mean of the predictive distribution, also its\n",
      "     |      standard deviation can be returned.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      return_std : bool, default=False\n",
      "     |          Whether to return the standard deviation of posterior prediction.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_mean : array-like of shape (n_samples,)\n",
      "     |          Mean of predictive distribution of query points.\n",
      "     |\n",
      "     |      y_std : array-like of shape (n_samples,)\n",
      "     |          Standard deviation of predictive distribution of query points.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._bayes.BayesianRidge, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._bayes.BayesianRidge\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_predict_request(self: sklearn.linear_model._bayes.BayesianRidge, *, return_std: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._bayes.BayesianRidge\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      return_std : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``return_std`` parameter in ``predict``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._bayes.BayesianRidge, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._bayes.BayesianRidge\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |\n",
      "     |  Minimizes the objective function::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |  If you are interested in controlling the L1 and L2 penalty\n",
      "     |  separately, keep in mind that this is equivalent to::\n",
      "     |\n",
      "     |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      "     |\n",
      "     |  where::\n",
      "     |\n",
      "     |          alpha = a + b and l1_ratio = a / (a + b)\n",
      "     |\n",
      "     |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      "     |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      "     |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      "     |  unless you supply your own sequence of alpha.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      "     |      See the notes for the exact mathematical meaning of this\n",
      "     |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      "     |      solved by the :class:`LinearRegression` object. For numerical\n",
      "     |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      "     |      Given this, you should use the :class:`LinearRegression` object.\n",
      "     |\n",
      "     |  l1_ratio : float, default=0.5\n",
      "     |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      "     |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      "     |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      "     |      combination of L1 and L2.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If ``False``, the\n",
      "     |      data is assumed to be already centered.\n",
      "     |\n",
      "     |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. The Gram matrix can also be passed as argument.\n",
      "     |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      "     |      Check :ref:`an example on how to use a precomputed Gram Matrix in ElasticNet\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py>`\n",
      "     |      for details.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``, see Notes below.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the cost function formula).\n",
      "     |\n",
      "     |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "     |      Sparse representation of the `coef_`.\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : list of int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance.\n",
      "     |\n",
      "     |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "     |      Given param alpha, the dual gaps at the end of the optimization,\n",
      "     |      same shape as each observation of y.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  ElasticNetCV : Elastic net model with best model selection by\n",
      "     |      cross-validation.\n",
      "     |  SGDRegressor : Implements elastic net regression with incremental training.\n",
      "     |  SGDClassifier : Implements logistic regression with elastic net penalty\n",
      "     |      (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      "     |  should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |  The precise stopping criteria based on `tol` are the following: First, check that\n",
      "     |  that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      "     |  is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      "     |  If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      "     |  :math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import ElasticNet\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |\n",
      "     |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      "     |  >>> regr = ElasticNet(random_state=0)\n",
      "     |  >>> regr.fit(X, y)\n",
      "     |  ElasticNet(random_state=0)\n",
      "     |  >>> print(regr.coef_)\n",
      "     |  [18.83816048 64.55968825]\n",
      "     |  >>> print(regr.intercept_)\n",
      "     |  1.451...\n",
      "     |  >>> print(regr.predict([[0, 0]]))\n",
      "     |  [1.451...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ElasticNet\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      "     |      Fit model with coordinate descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {ndarray, sparse matrix, sparse array} of (n_samples, n_features)\n",
      "     |          Data.\n",
      "     |\n",
      "     |          Note that large sparse matrices and arrays requiring `int64`\n",
      "     |          indices are not accepted.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights. Internally, the `sample_weight` vector will be\n",
      "     |          rescaled to sum to `n_samples`.\n",
      "     |\n",
      "     |          .. versionadded:: 0.23\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          Allow to bypass several input checking.\n",
      "     |          Don't use this parameter unless you know what you do.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Coordinate descent is an algorithm that considers each column of\n",
      "     |      data at a time hence it will automatically convert the X input\n",
      "     |      as a Fortran-contiguous numpy array if necessary.\n",
      "     |\n",
      "     |      To avoid memory re-allocation it is advised to allocate the\n",
      "     |      initial data in memory directly using that format.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.ElasticNet, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNet\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.ElasticNet, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNet\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  sparse_coef_\n",
      "     |      Sparse representation of the fitted `coef_`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class ElasticNetCV(sklearn.base.RegressorMixin, LinearModelCV)\n",
      "     |  ElasticNetCV(*, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, precompute='auto', max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  l1_ratio : float or list of float, default=0.5\n",
      "     |      Float between 0 and 1 passed to ElasticNet (scaling between\n",
      "     |      l1 and l2 penalties). For ``l1_ratio = 0``\n",
      "     |      the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.\n",
      "     |      For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2\n",
      "     |      This parameter can be a list, in which case the different\n",
      "     |      values are tested by cross-validation and the one giving the best\n",
      "     |      prediction score is used. Note that a good choice of list of\n",
      "     |      values for l1_ratio is often to put more values close to 1\n",
      "     |      (i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,\n",
      "     |      .9, .95, .99, 1]``.\n",
      "     |\n",
      "     |  eps : float, default=1e-3\n",
      "     |      Length of the path. ``eps=1e-3`` means that\n",
      "     |      ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |  n_alphas : int, default=100\n",
      "     |      Number of alphas along the regularization path, used for each l1_ratio.\n",
      "     |\n",
      "     |  alphas : array-like, default=None\n",
      "     |      List of alphas where to compute the models.\n",
      "     |      If None alphas are set automatically.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |      matrix can also be passed as argument.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - int, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  verbose : bool or int, default=0\n",
      "     |      Amount of verbosity.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  alpha_ : float\n",
      "     |      The amount of penalization chosen by cross validation.\n",
      "     |\n",
      "     |  l1_ratio_ : float\n",
      "     |      The compromise between l1 and l2 penalization chosen by\n",
      "     |      cross validation.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the cost function formula).\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets, n_features)\n",
      "     |      Independent term in the decision function.\n",
      "     |\n",
      "     |  mse_path_ : ndarray of shape (n_l1_ratio, n_alpha, n_folds)\n",
      "     |      Mean square error for the test set on each fold, varying l1_ratio and\n",
      "     |      alpha.\n",
      "     |\n",
      "     |  alphas_ : ndarray of shape (n_alphas,) or (n_l1_ratio, n_alphas)\n",
      "     |      The grid of alphas used for fitting, for each l1_ratio.\n",
      "     |\n",
      "     |  dual_gap_ : float\n",
      "     |      The dual gaps at the end of the optimization for the optimal alpha.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance for the optimal alpha.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  enet_path : Compute elastic net path with coordinate descent.\n",
      "     |  ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  In `fit`, once the best parameters `l1_ratio` and `alpha` are found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the `X` argument of the `fit`\n",
      "     |  method should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |  The parameter `l1_ratio` corresponds to alpha in the glmnet R package\n",
      "     |  while alpha corresponds to the lambda parameter in glmnet.\n",
      "     |  More specifically, the optimization objective is::\n",
      "     |\n",
      "     |      1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |      + alpha * l1_ratio * ||w||_1\n",
      "     |      + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |  If you are interested in controlling the L1 and L2 penalty\n",
      "     |  separately, keep in mind that this is equivalent to::\n",
      "     |\n",
      "     |      a * L1 + b * L2\n",
      "     |\n",
      "     |  for::\n",
      "     |\n",
      "     |      alpha = a + b and l1_ratio = a / (a + b).\n",
      "     |\n",
      "     |  For an example, see\n",
      "     |  :ref:`examples/linear_model/plot_lasso_model_selection.py\n",
      "     |  <sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py>`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import ElasticNetCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |\n",
      "     |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      "     |  >>> regr = ElasticNetCV(cv=5, random_state=0)\n",
      "     |  >>> regr.fit(X, y)\n",
      "     |  ElasticNetCV(cv=5, random_state=0)\n",
      "     |  >>> print(regr.alpha_)\n",
      "     |  0.199...\n",
      "     |  >>> print(regr.intercept_)\n",
      "     |  0.398...\n",
      "     |  >>> print(regr.predict([[0, 0]]))\n",
      "     |  [0.398...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ElasticNetCV\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      LinearModelCV\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, precompute='auto', max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.ElasticNetCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNetCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.ElasticNetCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNetCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LinearModelCV:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, **params)\n",
      "     |      Fit linear model with coordinate descent.\n",
      "     |\n",
      "     |      Fit is on grid of alphas and best alpha estimated by cross-validation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data\n",
      "     |          to avoid unnecessary memory duplication. If y is mono-output,\n",
      "     |          X can be sparse. Note that large sparse matrices and arrays\n",
      "     |          requiring `int64` indices are not accepted.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : float or array-like of shape (n_samples,),                 default=None\n",
      "     |          Sample weights used for fitting and evaluation of the weighted\n",
      "     |          mean squared error of each cv-fold. Note that the cross validated\n",
      "     |          MSE that is finally used to find the best model is the unweighted\n",
      "     |          mean over the (weighted) MSEs of each test fold.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of fitted model.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class GammaRegressor(_GeneralizedLinearRegressor)\n",
      "     |  GammaRegressor(*, alpha=1.0, fit_intercept=True, solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |\n",
      "     |  Generalized Linear Model with a Gamma distribution.\n",
      "     |\n",
      "     |  This regressor uses the 'log' link function.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <Generalized_linear_models>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.23\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1\n",
      "     |      Constant that multiplies the L2 penalty term and determines the\n",
      "     |      regularization strength. ``alpha = 0`` is equivalent to unpenalized\n",
      "     |      GLMs. In this case, the design matrix `X` must have full column rank\n",
      "     |      (no collinearities).\n",
      "     |      Values of `alpha` must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "     |      added to the linear predictor `X @ coef_ + intercept_`.\n",
      "     |\n",
      "     |  solver : {'lbfgs', 'newton-cholesky'}, default='lbfgs'\n",
      "     |      Algorithm to use in the optimization problem:\n",
      "     |\n",
      "     |      'lbfgs'\n",
      "     |          Calls scipy's L-BFGS-B optimizer.\n",
      "     |\n",
      "     |      'newton-cholesky'\n",
      "     |          Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to\n",
      "     |          iterated reweighted least squares) with an inner Cholesky based solver.\n",
      "     |          This solver is a good choice for `n_samples` >> `n_features`, especially\n",
      "     |          with one-hot encoded categorical features with rare categories. Be aware\n",
      "     |          that the memory usage of this solver has a quadratic dependency on\n",
      "     |          `n_features` because it explicitly computes the Hessian matrix.\n",
      "     |\n",
      "     |          .. versionadded:: 1.2\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      The maximal number of iterations for the solver.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      Stopping criterion. For the lbfgs solver,\n",
      "     |      the iteration will stop when ``max{|g_j|, j = 1, ..., d} <= tol``\n",
      "     |      where ``g_j`` is the j-th component of the gradient (derivative) of\n",
      "     |      the objective function.\n",
      "     |      Values must be in the range `(0.0, inf)`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      If set to ``True``, reuse the solution of the previous call to ``fit``\n",
      "     |      as initialization for `coef_` and `intercept_`.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      For the lbfgs solver set verbose to any positive number for verbosity.\n",
      "     |      Values must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array of shape (n_features,)\n",
      "     |      Estimated coefficients for the linear predictor (`X @ coef_ +\n",
      "     |      intercept_`) in the GLM.\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Intercept (a.k.a. bias) added to linear predictor.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Actual number of iterations used in the solver.\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  PoissonRegressor : Generalized Linear Model with a Poisson distribution.\n",
      "     |  TweedieRegressor : Generalized Linear Model with a Tweedie distribution.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.GammaRegressor()\n",
      "     |  >>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]\n",
      "     |  >>> y = [19, 26, 33, 30]\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  GammaRegressor()\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.773...\n",
      "     |  >>> clf.coef_\n",
      "     |  array([0.072..., 0.066...])\n",
      "     |  >>> clf.intercept_\n",
      "     |  2.896...\n",
      "     |  >>> clf.predict([[1, 0], [2, 8]])\n",
      "     |  array([19.483..., 35.795...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      GammaRegressor\n",
      "     |      _GeneralizedLinearRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, alpha=1.0, fit_intercept=True, solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._glm.glm.GammaRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.GammaRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._glm.glm.GammaRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.GammaRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _GeneralizedLinearRegressor:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit a Generalized Linear Model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted model.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using GLM with feature matrix X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array of shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Compute D^2, the percentage of deviance explained.\n",
      "     |\n",
      "     |      D^2 is a generalization of the coefficient of determination R^2.\n",
      "     |      R^2 uses squared error and D^2 uses the deviance of this GLM, see the\n",
      "     |      :ref:`User Guide <regression_metrics>`.\n",
      "     |\n",
      "     |      D^2 is defined as\n",
      "     |      :math:`D^2 = 1-\\frac{D(y_{true},y_{pred})}{D_{null}}`,\n",
      "     |      :math:`D_{null}` is the null deviance, i.e. the deviance of a model\n",
      "     |      with intercept alone, which corresponds to :math:`y_{pred} = \\bar{y}`.\n",
      "     |      The mean :math:`\\bar{y}` is averaged by sample_weight.\n",
      "     |      Best possible score is 1.0 and it can be negative (because the model\n",
      "     |      can be arbitrarily worse).\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          True values of target.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          D^2 of self.predict(X) w.r.t. y.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Hinge(Classification)\n",
      "     |  Hinge loss for binary classification tasks with y in {-1,1}\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |\n",
      "     |  threshold : float > 0.0\n",
      "     |      Margin threshold. When threshold=1.0, one gets the loss used by SVM.\n",
      "     |      When threshold=0.0, one gets the loss used by the Perceptron.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Hinge\n",
      "     |      Classification\n",
      "     |      LossFunction\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __reduce__(self)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Classification:\n",
      "     |\n",
      "     |  __reduce_cython__(self)\n",
      "     |\n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |\n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LossFunction:\n",
      "     |\n",
      "     |  py_dloss(self, p, y)\n",
      "     |      Python version of `dloss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The derivative of the loss function with regards to `p`.\n",
      "     |\n",
      "     |  py_loss(self, p, y)\n",
      "     |      Python version of `loss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x + intercept`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The loss evaluated at `p` and `y`.\n",
      "\n",
      "    class Huber(Regression)\n",
      "     |  Huber regression loss\n",
      "     |\n",
      "     |  Variant of the SquaredLoss that is robust to outliers (quadratic near zero,\n",
      "     |  linear in for large errors).\n",
      "     |\n",
      "     |  https://en.wikipedia.org/wiki/Huber_Loss_Function\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Huber\n",
      "     |      Regression\n",
      "     |      LossFunction\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __reduce__(self)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Regression:\n",
      "     |\n",
      "     |  __reduce_cython__(self)\n",
      "     |\n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |\n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LossFunction:\n",
      "     |\n",
      "     |  py_dloss(self, p, y)\n",
      "     |      Python version of `dloss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The derivative of the loss function with regards to `p`.\n",
      "     |\n",
      "     |  py_loss(self, p, y)\n",
      "     |      Python version of `loss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x + intercept`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The loss evaluated at `p` and `y`.\n",
      "\n",
      "    class HuberRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "     |  HuberRegressor(*, epsilon=1.35, max_iter=100, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05)\n",
      "     |\n",
      "     |  L2-regularized linear regression model that is robust to outliers.\n",
      "     |\n",
      "     |  The Huber Regressor optimizes the squared loss for the samples where\n",
      "     |  ``|(y - Xw - c) / sigma| < epsilon`` and the absolute loss for the samples\n",
      "     |  where ``|(y - Xw - c) / sigma| > epsilon``, where the model coefficients\n",
      "     |  ``w``, the intercept ``c`` and the scale ``sigma`` are parameters\n",
      "     |  to be optimized. The parameter sigma makes sure that if y is scaled up\n",
      "     |  or down by a certain factor, one does not need to rescale epsilon to\n",
      "     |  achieve the same robustness. Note that this does not take into account\n",
      "     |  the fact that the different features of X may be of different scales.\n",
      "     |\n",
      "     |  The Huber loss function has the advantage of not being heavily influenced\n",
      "     |  by the outliers while not completely ignoring their effect.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <huber_regression>`\n",
      "     |\n",
      "     |  .. versionadded:: 0.18\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  epsilon : float, default=1.35\n",
      "     |      The parameter epsilon controls the number of samples that should be\n",
      "     |      classified as outliers. The smaller the epsilon, the more robust it is\n",
      "     |      to outliers. Epsilon must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      Maximum number of iterations that\n",
      "     |      ``scipy.optimize.minimize(method=\"L-BFGS-B\")`` should run for.\n",
      "     |\n",
      "     |  alpha : float, default=0.0001\n",
      "     |      Strength of the squared L2 regularization. Note that the penalty is\n",
      "     |      equal to ``alpha * ||w||^2``.\n",
      "     |      Must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      This is useful if the stored attributes of a previously used model\n",
      "     |      has to be reused. If set to False, then the coefficients will\n",
      "     |      be rewritten for every call to fit.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether or not to fit the intercept. This can be set to False\n",
      "     |      if the data is already centered around the origin.\n",
      "     |\n",
      "     |  tol : float, default=1e-05\n",
      "     |      The iteration will stop when\n",
      "     |      ``max{|proj g_i | i = 1, ..., n}`` <= ``tol``\n",
      "     |      where pg_i is the i-th component of the projected gradient.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array, shape (n_features,)\n",
      "     |      Features got by optimizing the L2-regularized Huber loss.\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Bias.\n",
      "     |\n",
      "     |  scale_ : float\n",
      "     |      The value by which ``|y - Xw - c|`` is scaled down.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations that\n",
      "     |      ``scipy.optimize.minimize(method=\"L-BFGS-B\")`` has run for.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.20\n",
      "     |\n",
      "     |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      "     |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      "     |\n",
      "     |  outliers_ : array, shape (n_samples,)\n",
      "     |      A boolean mask which is set to True where the samples are identified\n",
      "     |      as outliers.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  RANSACRegressor : RANSAC (RANdom SAmple Consensus) algorithm.\n",
      "     |  TheilSenRegressor : Theil-Sen Estimator robust multivariate regression model.\n",
      "     |  SGDRegressor : Fitted by minimizing a regularized empirical loss with SGD.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics\n",
      "     |         Concomitant scale estimates, pg 172\n",
      "     |  .. [2] Art B. Owen (2006), A robust hybrid of lasso and ridge regression.\n",
      "     |         https://statweb.stanford.edu/~owen/reports/hhu.pdf\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.linear_model import HuberRegressor, LinearRegression\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> X, y, coef = make_regression(\n",
      "     |  ...     n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)\n",
      "     |  >>> X[:4] = rng.uniform(10, 20, (4, 2))\n",
      "     |  >>> y[:4] = rng.uniform(10, 20, 4)\n",
      "     |  >>> huber = HuberRegressor().fit(X, y)\n",
      "     |  >>> huber.score(X, y)\n",
      "     |  -7.284...\n",
      "     |  >>> huber.predict(X[:1,])\n",
      "     |  array([806.7200...])\n",
      "     |  >>> linear = LinearRegression().fit(X, y)\n",
      "     |  >>> print(\"True coefficients:\", coef)\n",
      "     |  True coefficients: [20.4923...  34.1698...]\n",
      "     |  >>> print(\"Huber coefficients:\", huber.coef_)\n",
      "     |  Huber coefficients: [17.7906... 31.0106...]\n",
      "     |  >>> print(\"Linear Regression coefficients:\", linear.coef_)\n",
      "     |  Linear Regression coefficients: [-1.9221...  7.0226...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      HuberRegressor\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, epsilon=1.35, max_iter=100, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training vector, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      y : array-like, shape (n_samples,)\n",
      "     |          Target vector relative to X.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,)\n",
      "     |          Weight given to each sample.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted `HuberRegressor` estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._huber.HuberRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._huber.HuberRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._huber.HuberRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._huber.HuberRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Lars(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  Lars(*, fit_intercept=True, verbose=False, precompute='auto', n_nonzero_coefs=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, jitter=None, random_state=None)\n",
      "     |\n",
      "     |  Least Angle Regression model a.k.a. LAR.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  precompute : bool, 'auto' or array-like , default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |      matrix can also be passed as argument.\n",
      "     |\n",
      "     |  n_nonzero_coefs : int, default=500\n",
      "     |      Target number of non-zero coefficients. Use ``np.inf`` for no limit.\n",
      "     |\n",
      "     |  eps : float, default=np.finfo(float).eps\n",
      "     |      The machine-precision regularization in the computation of the\n",
      "     |      Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "     |      systems. Unlike the ``tol`` parameter in some iterative\n",
      "     |      optimization-based algorithms, this parameter does not control\n",
      "     |      the tolerance of the optimization.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  fit_path : bool, default=True\n",
      "     |      If True the full path is stored in the ``coef_path_`` attribute.\n",
      "     |      If you compute the solution for a large problem or many targets,\n",
      "     |      setting ``fit_path`` to ``False`` will lead to a speedup, especially\n",
      "     |      with a small alpha.\n",
      "     |\n",
      "     |  jitter : float, default=None\n",
      "     |      Upper bound on a uniform noise parameter to be added to the\n",
      "     |      `y` values, to satisfy the model's assumption of\n",
      "     |      one-at-a-time computations. Might help with stability.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      Determines random number generation for jittering. Pass an int\n",
      "     |      for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`. Ignored if `jitter` is None.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  alphas_ : array-like of shape (n_alphas + 1,) or list of such arrays\n",
      "     |      Maximum of covariances (in absolute value) at each iteration.\n",
      "     |      ``n_alphas`` is either ``max_iter``, ``n_features`` or the\n",
      "     |      number of nodes in the path with ``alpha >= alpha_min``, whichever\n",
      "     |      is smaller. If this is a list of array-like, the length of the outer\n",
      "     |      list is `n_targets`.\n",
      "     |\n",
      "     |  active_ : list of shape (n_alphas,) or list of such lists\n",
      "     |      Indices of active variables at the end of the path.\n",
      "     |      If this is a list of list, the length of the outer list is `n_targets`.\n",
      "     |\n",
      "     |  coef_path_ : array-like of shape (n_features, n_alphas + 1) or list             of such arrays\n",
      "     |      The varying values of the coefficients along the path. It is not\n",
      "     |      present if the ``fit_path`` parameter is ``False``. If this is a list\n",
      "     |      of array-like, the length of the outer list is `n_targets`.\n",
      "     |\n",
      "     |  coef_ : array-like of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the formulation formula).\n",
      "     |\n",
      "     |  intercept_ : float or array-like of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : array-like or int\n",
      "     |      The number of iterations taken by lars_path to find the\n",
      "     |      grid of alphas for each target.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path: Compute Least Angle Regression or Lasso\n",
      "     |      path using LARS algorithm.\n",
      "     |  LarsCV : Cross-validated Least Angle Regression model.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> reg = linear_model.Lars(n_nonzero_coefs=1)\n",
      "     |  >>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])\n",
      "     |  Lars(n_nonzero_coefs=1)\n",
      "     |  >>> print(reg.coef_)\n",
      "     |  [ 0. -1.11...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Lars\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, fit_intercept=True, verbose=False, precompute='auto', n_nonzero_coefs=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, jitter=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, Xy=None)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),                 default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._least_angle.Lars, *, Xy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.Lars\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``Xy`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._least_angle.Lars, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.Lars\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  method = 'lar'\n",
      "     |\n",
      "     |  positive = False\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LarsCV(Lars)\n",
      "     |  LarsCV(*, fit_intercept=True, verbose=False, max_iter=500, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True)\n",
      "     |\n",
      "     |  Cross-validated Least Angle Regression model.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  max_iter : int, default=500\n",
      "     |      Maximum number of iterations to perform.\n",
      "     |\n",
      "     |  precompute : bool, 'auto' or array-like , default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram matrix\n",
      "     |      cannot be passed as argument since we will use only subsets of X.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For integer/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  max_n_alphas : int, default=1000\n",
      "     |      The maximum number of points on the path used to compute the\n",
      "     |      residuals in the cross-validation.\n",
      "     |\n",
      "     |  n_jobs : int or None, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  eps : float, default=np.finfo(float).eps\n",
      "     |      The machine-precision regularization in the computation of the\n",
      "     |      Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "     |      systems. Unlike the ``tol`` parameter in some iterative\n",
      "     |      optimization-based algorithms, this parameter does not control\n",
      "     |      the tolerance of the optimization.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  active_ : list of length n_alphas or list of such lists\n",
      "     |      Indices of active variables at the end of the path.\n",
      "     |      If this is a list of lists, the outer list length is `n_targets`.\n",
      "     |\n",
      "     |  coef_ : array-like of shape (n_features,)\n",
      "     |      parameter vector (w in the formulation formula)\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      independent term in decision function\n",
      "     |\n",
      "     |  coef_path_ : array-like of shape (n_features, n_alphas)\n",
      "     |      the varying values of the coefficients along the path\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      the estimated regularization parameter alpha\n",
      "     |\n",
      "     |  alphas_ : array-like of shape (n_alphas,)\n",
      "     |      the different values of alpha along the path\n",
      "     |\n",
      "     |  cv_alphas_ : array-like of shape (n_cv_alphas,)\n",
      "     |      all the values of alpha along the path for the different folds\n",
      "     |\n",
      "     |  mse_path_ : array-like of shape (n_folds, n_cv_alphas)\n",
      "     |      the mean square error on left-out for each fold along the path\n",
      "     |      (alpha values given by ``cv_alphas``)\n",
      "     |\n",
      "     |  n_iter_ : array-like or int\n",
      "     |      the number of iterations run by Lars with the optimal alpha.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso\n",
      "     |      path using LARS algorithm.\n",
      "     |  lasso_path : Compute Lasso path with coordinate descent.\n",
      "     |  Lasso : Linear Model trained with L1 prior as\n",
      "     |      regularizer (aka the Lasso).\n",
      "     |  LassoCV : Lasso linear model with iterative fitting\n",
      "     |      along a regularization path.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  LassoLarsIC : Lasso model fit with Lars using BIC\n",
      "     |      or AIC for model selection.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  In `fit`, once the best parameter `alpha` is found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import LarsCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(n_samples=200, noise=4.0, random_state=0)\n",
      "     |  >>> reg = LarsCV(cv=5).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9996...\n",
      "     |  >>> reg.alpha_\n",
      "     |  0.2961...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([154.3996...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LarsCV\n",
      "     |      Lars\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, fit_intercept=True, verbose=False, max_iter=500, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, **params)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._least_angle.LarsCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LarsCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  method = 'lar'\n",
      "     |\n",
      "     |  parameter = 'random_state'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lars:\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._least_angle.LarsCV, *, Xy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LarsCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``Xy`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Lars:\n",
      "     |\n",
      "     |  positive = False\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Lasso(ElasticNet)\n",
      "     |  Lasso(alpha=1.0, *, fit_intercept=True, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Linear Model trained with L1 prior as regularizer (aka the Lasso).\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |  Technically the Lasso model is optimizing the same objective function as\n",
      "     |  the Elastic Net with ``l1_ratio=1.0`` (no L2 penalty).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <lasso>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Constant that multiplies the L1 term, controlling regularization\n",
      "     |      strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.\n",
      "     |\n",
      "     |      When `alpha = 0`, the objective is equivalent to ordinary least\n",
      "     |      squares, solved by the :class:`LinearRegression` object. For numerical\n",
      "     |      reasons, using `alpha = 0` with the `Lasso` object is not advised.\n",
      "     |      Instead, you should use the :class:`LinearRegression` object.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to False, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. The Gram matrix can also be passed as argument.\n",
      "     |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``, see Notes below.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the cost function formula).\n",
      "     |\n",
      "     |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "     |      Given param alpha, the dual gaps at the end of the optimization,\n",
      "     |      same shape as each observation of y.\n",
      "     |\n",
      "     |  sparse_coef_ : sparse matrix of shape (n_features, 1) or             (n_targets, n_features)\n",
      "     |      Readonly property derived from ``coef_``.\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : int or list of int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Regularization path using LARS.\n",
      "     |  lasso_path : Regularization path using Lasso.\n",
      "     |  LassoLars : Lasso Path along the regularization parameter using LARS algorithm.\n",
      "     |  LassoCV : Lasso alpha parameter by cross-validation.\n",
      "     |  LassoLarsCV : Lasso least angle parameter algorithm by cross-validation.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding array estimator.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The algorithm used to fit the model is coordinate descent.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      "     |  should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |  Regularization improves the conditioning of the problem and\n",
      "     |  reduces the variance of the estimates. Larger values specify stronger\n",
      "     |  regularization. Alpha corresponds to `1 / (2C)` in other linear\n",
      "     |  models such as :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "     |  :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      "     |  assumed to be specific to the targets. Hence they must correspond in\n",
      "     |  number.\n",
      "     |\n",
      "     |  The precise stopping criteria based on `tol` are the following: First, check that\n",
      "     |  that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      "     |  is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      "     |  If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      "     |  :math:`||y||_2^2 / n_{\\text{samples}}`.\n",
      "     |\n",
      "     |  The target can be a 2-dimensional array, resulting in the optimization of the\n",
      "     |  following objective::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||Y - XW||^2_F + alpha * ||W||_11\n",
      "     |\n",
      "     |  where :math:`||W||_{1,1}` is the sum of the magnitude of the matrix coefficients.\n",
      "     |  It should not be confused with :class:`~sklearn.linear_model.MultiTaskLasso` which\n",
      "     |  instead penalizes the :math:`L_{2,1}` norm of the coefficients, yielding row-wise\n",
      "     |  sparsity in the coefficients.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.Lasso(alpha=0.1)\n",
      "     |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      "     |  Lasso(alpha=0.1)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [0.85 0.  ]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  0.15...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Lasso\n",
      "     |      ElasticNet\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, fit_intercept=True, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.Lasso, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.Lasso\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.Lasso, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.Lasso\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ElasticNet:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      "     |      Fit model with coordinate descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {ndarray, sparse matrix, sparse array} of (n_samples, n_features)\n",
      "     |          Data.\n",
      "     |\n",
      "     |          Note that large sparse matrices and arrays requiring `int64`\n",
      "     |          indices are not accepted.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights. Internally, the `sample_weight` vector will be\n",
      "     |          rescaled to sum to `n_samples`.\n",
      "     |\n",
      "     |          .. versionadded:: 0.23\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          Allow to bypass several input checking.\n",
      "     |          Don't use this parameter unless you know what you do.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Coordinate descent is an algorithm that considers each column of\n",
      "     |      data at a time hence it will automatically convert the X input\n",
      "     |      as a Fortran-contiguous numpy array if necessary.\n",
      "     |\n",
      "     |      To avoid memory re-allocation it is advised to allocate the\n",
      "     |      initial data in memory directly using that format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ElasticNet:\n",
      "     |\n",
      "     |  sparse_coef_\n",
      "     |      Sparse representation of the fitted `coef_`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LassoCV(sklearn.base.RegressorMixin, LinearModelCV)\n",
      "     |  LassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Lasso linear model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  The best model is selected by cross-validation.\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <lasso>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  eps : float, default=1e-3\n",
      "     |      Length of the path. ``eps=1e-3`` means that\n",
      "     |      ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |  n_alphas : int, default=100\n",
      "     |      Number of alphas along the regularization path.\n",
      "     |\n",
      "     |  alphas : array-like, default=None\n",
      "     |      List of alphas where to compute the models.\n",
      "     |      If ``None`` alphas are set automatically.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |      matrix can also be passed as argument.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - int, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Amount of verbosity.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      If positive, restrict regression coefficients to be positive.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  alpha_ : float\n",
      "     |      The amount of penalization chosen by cross validation.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the cost function formula).\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  mse_path_ : ndarray of shape (n_alphas, n_folds)\n",
      "     |      Mean square error for the test set on each fold, varying alpha.\n",
      "     |\n",
      "     |  alphas_ : ndarray of shape (n_alphas,)\n",
      "     |      The grid of alphas used for fitting.\n",
      "     |\n",
      "     |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      "     |      The dual gap at the end of the optimization for the optimal alpha\n",
      "     |      (``alpha_``).\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance for the optimal alpha.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso path using LARS\n",
      "     |      algorithm.\n",
      "     |  lasso_path : Compute Lasso path with coordinate descent.\n",
      "     |  Lasso : The Lasso is a linear model that estimates sparse coefficients.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  LassoCV : Lasso linear model with iterative fitting along a regularization\n",
      "     |      path.\n",
      "     |  LassoLarsCV : Cross-validated Lasso using the LARS algorithm.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  In `fit`, once the best parameter `alpha` is found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the `X` argument of the `fit`\n",
      "     |  method should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |   For an example, see\n",
      "     |   :ref:`examples/linear_model/plot_lasso_model_selection.py\n",
      "     |   <sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py>`.\n",
      "     |\n",
      "     |  :class:`LassoCV` leads to different results than a hyperparameter\n",
      "     |  search using :class:`~sklearn.model_selection.GridSearchCV` with a\n",
      "     |  :class:`Lasso` model. In :class:`LassoCV`, a model for a given\n",
      "     |  penalty `alpha` is warm started using the coefficients of the\n",
      "     |  closest model (trained at the previous iteration) on the\n",
      "     |  regularization path. It tends to speed up the hyperparameter\n",
      "     |  search.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import LassoCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(noise=4, random_state=0)\n",
      "     |  >>> reg = LassoCV(cv=5, random_state=0).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9993...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-78.4951...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LassoCV\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      LinearModelCV\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.LassoCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.LassoCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.LassoCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.LassoCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = lasso_path(X, y, *, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, **params)\n",
      "     |      Compute Lasso path with coordinate descent.\n",
      "     |\n",
      "     |      The Lasso optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <lasso>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If ``None`` alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      lars_path : Compute Least Angle Regression or Lasso path using LARS\n",
      "     |          algorithm.\n",
      "     |      Lasso : The Lasso is a linear model that estimates sparse coefficients.\n",
      "     |      LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |      LassoCV : Lasso linear model with iterative fitting along a regularization\n",
      "     |          path.\n",
      "     |      LassoLarsCV : Cross-validated Lasso using the LARS algorithm.\n",
      "     |      sklearn.decomposition.sparse_encode : Estimator that can be used to\n",
      "     |          transform signals into sparse linear combination of atoms from a fixed.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      To avoid unnecessary memory duplication the X argument of the fit method\n",
      "     |      should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |      Note that in certain cases, the Lars solver may be significantly\n",
      "     |      faster to implement this functionality. In particular, linear\n",
      "     |      interpolation can be used to retrieve model coefficients between the\n",
      "     |      values output by lars_path\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |\n",
      "     |      Comparing lasso_path and lars_path with interpolation:\n",
      "     |\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from sklearn.linear_model import lasso_path\n",
      "     |      >>> X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n",
      "     |      >>> y = np.array([1, 2, 3.1])\n",
      "     |      >>> # Use lasso_path to compute a coefficient path\n",
      "     |      >>> _, coef_path, _ = lasso_path(X, y, alphas=[5., 1., .5])\n",
      "     |      >>> print(coef_path)\n",
      "     |      [[0.         0.         0.46874778]\n",
      "     |       [0.2159048  0.4425765  0.23689075]]\n",
      "     |\n",
      "     |      >>> # Now use lars_path and 1D linear interpolation to compute the\n",
      "     |      >>> # same path\n",
      "     |      >>> from sklearn.linear_model import lars_path\n",
      "     |      >>> alphas, active, coef_path_lars = lars_path(X, y, method='lasso')\n",
      "     |      >>> from scipy import interpolate\n",
      "     |      >>> coef_path_continuous = interpolate.interp1d(alphas[::-1],\n",
      "     |      ...                                             coef_path_lars[:, ::-1])\n",
      "     |      >>> print(coef_path_continuous([5., 1., .5]))\n",
      "     |      [[0.         0.         0.46915237]\n",
      "     |       [0.2159048  0.4425765  0.23668876]]\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LinearModelCV:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, **params)\n",
      "     |      Fit linear model with coordinate descent.\n",
      "     |\n",
      "     |      Fit is on grid of alphas and best alpha estimated by cross-validation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data\n",
      "     |          to avoid unnecessary memory duplication. If y is mono-output,\n",
      "     |          X can be sparse. Note that large sparse matrices and arrays\n",
      "     |          requiring `int64` indices are not accepted.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : float or array-like of shape (n_samples,),                 default=None\n",
      "     |          Sample weights used for fitting and evaluation of the weighted\n",
      "     |          mean squared error of each cv-fold. Note that the cross validated\n",
      "     |          MSE that is finally used to find the best model is the unweighted\n",
      "     |          mean over the (weighted) MSEs of each test fold.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of fitted model.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LassoLars(Lars)\n",
      "     |  LassoLars(alpha=1.0, *, fit_intercept=True, verbose=False, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None)\n",
      "     |\n",
      "     |  Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |\n",
      "     |  It is a Linear Model trained with an L1 prior as regularizer.\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Constant that multiplies the penalty term. Defaults to 1.0.\n",
      "     |      ``alpha = 0`` is equivalent to an ordinary least square, solved\n",
      "     |      by :class:`LinearRegression`. For numerical reasons, using\n",
      "     |      ``alpha = 0`` with the LassoLars object is not advised and you\n",
      "     |      should prefer the LinearRegression object.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  precompute : bool, 'auto' or array-like, default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |      matrix can also be passed as argument.\n",
      "     |\n",
      "     |  max_iter : int, default=500\n",
      "     |      Maximum number of iterations to perform.\n",
      "     |\n",
      "     |  eps : float, default=np.finfo(float).eps\n",
      "     |      The machine-precision regularization in the computation of the\n",
      "     |      Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "     |      systems. Unlike the ``tol`` parameter in some iterative\n",
      "     |      optimization-based algorithms, this parameter does not control\n",
      "     |      the tolerance of the optimization.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  fit_path : bool, default=True\n",
      "     |      If ``True`` the full path is stored in the ``coef_path_`` attribute.\n",
      "     |      If you compute the solution for a large problem or many targets,\n",
      "     |      setting ``fit_path`` to ``False`` will lead to a speedup, especially\n",
      "     |      with a small alpha.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      Restrict coefficients to be >= 0. Be aware that you might want to\n",
      "     |      remove fit_intercept which is set True by default.\n",
      "     |      Under the positive restriction the model coefficients will not converge\n",
      "     |      to the ordinary-least-squares solution for small values of alpha.\n",
      "     |      Only coefficients up to the smallest alpha value (``alphas_[alphas_ >\n",
      "     |      0.].min()`` when fit_path=True) reached by the stepwise Lars-Lasso\n",
      "     |      algorithm are typically in congruence with the solution of the\n",
      "     |      coordinate descent Lasso estimator.\n",
      "     |\n",
      "     |  jitter : float, default=None\n",
      "     |      Upper bound on a uniform noise parameter to be added to the\n",
      "     |      `y` values, to satisfy the model's assumption of\n",
      "     |      one-at-a-time computations. Might help with stability.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      Determines random number generation for jittering. Pass an int\n",
      "     |      for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`. Ignored if `jitter` is None.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  alphas_ : array-like of shape (n_alphas + 1,) or list of such arrays\n",
      "     |      Maximum of covariances (in absolute value) at each iteration.\n",
      "     |      ``n_alphas`` is either ``max_iter``, ``n_features`` or the\n",
      "     |      number of nodes in the path with ``alpha >= alpha_min``, whichever\n",
      "     |      is smaller. If this is a list of array-like, the length of the outer\n",
      "     |      list is `n_targets`.\n",
      "     |\n",
      "     |  active_ : list of length n_alphas or list of such lists\n",
      "     |      Indices of active variables at the end of the path.\n",
      "     |      If this is a list of list, the length of the outer list is `n_targets`.\n",
      "     |\n",
      "     |  coef_path_ : array-like of shape (n_features, n_alphas + 1) or list             of such arrays\n",
      "     |      If a list is passed it's expected to be one of n_targets such arrays.\n",
      "     |      The varying values of the coefficients along the path. It is not\n",
      "     |      present if the ``fit_path`` parameter is ``False``. If this is a list\n",
      "     |      of array-like, the length of the outer list is `n_targets`.\n",
      "     |\n",
      "     |  coef_ : array-like of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the formulation formula).\n",
      "     |\n",
      "     |  intercept_ : float or array-like of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : array-like or int\n",
      "     |      The number of iterations taken by lars_path to find the\n",
      "     |      grid of alphas for each target.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso\n",
      "     |      path using LARS algorithm.\n",
      "     |  lasso_path : Compute Lasso path with coordinate descent.\n",
      "     |  Lasso : Linear Model trained with L1 prior as\n",
      "     |      regularizer (aka the Lasso).\n",
      "     |  LassoCV : Lasso linear model with iterative fitting\n",
      "     |      along a regularization path.\n",
      "     |  LassoLarsCV: Cross-validated Lasso, using the LARS algorithm.\n",
      "     |  LassoLarsIC : Lasso model fit with Lars using BIC\n",
      "     |      or AIC for model selection.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> reg = linear_model.LassoLars(alpha=0.01)\n",
      "     |  >>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1, 0, -1])\n",
      "     |  LassoLars(alpha=0.01)\n",
      "     |  >>> print(reg.coef_)\n",
      "     |  [ 0.         -0.955...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LassoLars\n",
      "     |      Lars\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, fit_intercept=True, verbose=False, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._least_angle.LassoLars, *, Xy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLars\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``Xy`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._least_angle.LassoLars, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLars\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  method = 'lasso'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lars:\n",
      "     |\n",
      "     |  fit(self, X, y, Xy=None)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),                 default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Lars:\n",
      "     |\n",
      "     |  positive = False\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LassoLarsCV(LarsCV)\n",
      "     |  LassoLarsCV(*, fit_intercept=True, verbose=False, max_iter=500, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True, positive=False)\n",
      "     |\n",
      "     |  Cross-validated Lasso, using the LARS algorithm.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  max_iter : int, default=500\n",
      "     |      Maximum number of iterations to perform.\n",
      "     |\n",
      "     |  precompute : bool or 'auto' , default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram matrix\n",
      "     |      cannot be passed as argument since we will use only subsets of X.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For integer/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  max_n_alphas : int, default=1000\n",
      "     |      The maximum number of points on the path used to compute the\n",
      "     |      residuals in the cross-validation.\n",
      "     |\n",
      "     |  n_jobs : int or None, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  eps : float, default=np.finfo(float).eps\n",
      "     |      The machine-precision regularization in the computation of the\n",
      "     |      Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "     |      systems. Unlike the ``tol`` parameter in some iterative\n",
      "     |      optimization-based algorithms, this parameter does not control\n",
      "     |      the tolerance of the optimization.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      Restrict coefficients to be >= 0. Be aware that you might want to\n",
      "     |      remove fit_intercept which is set True by default.\n",
      "     |      Under the positive restriction the model coefficients do not converge\n",
      "     |      to the ordinary-least-squares solution for small values of alpha.\n",
      "     |      Only coefficients up to the smallest alpha value (``alphas_[alphas_ >\n",
      "     |      0.].min()`` when fit_path=True) reached by the stepwise Lars-Lasso\n",
      "     |      algorithm are typically in congruence with the solution of the\n",
      "     |      coordinate descent Lasso estimator.\n",
      "     |      As a consequence using LassoLarsCV only makes sense for problems where\n",
      "     |      a sparse solution is expected and/or reached.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array-like of shape (n_features,)\n",
      "     |      parameter vector (w in the formulation formula)\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      independent term in decision function.\n",
      "     |\n",
      "     |  coef_path_ : array-like of shape (n_features, n_alphas)\n",
      "     |      the varying values of the coefficients along the path\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      the estimated regularization parameter alpha\n",
      "     |\n",
      "     |  alphas_ : array-like of shape (n_alphas,)\n",
      "     |      the different values of alpha along the path\n",
      "     |\n",
      "     |  cv_alphas_ : array-like of shape (n_cv_alphas,)\n",
      "     |      all the values of alpha along the path for the different folds\n",
      "     |\n",
      "     |  mse_path_ : array-like of shape (n_folds, n_cv_alphas)\n",
      "     |      the mean square error on left-out for each fold along the path\n",
      "     |      (alpha values given by ``cv_alphas``)\n",
      "     |\n",
      "     |  n_iter_ : array-like or int\n",
      "     |      the number of iterations run by Lars with the optimal alpha.\n",
      "     |\n",
      "     |  active_ : list of int\n",
      "     |      Indices of active variables at the end of the path.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso\n",
      "     |      path using LARS algorithm.\n",
      "     |  lasso_path : Compute Lasso path with coordinate descent.\n",
      "     |  Lasso : Linear Model trained with L1 prior as\n",
      "     |      regularizer (aka the Lasso).\n",
      "     |  LassoCV : Lasso linear model with iterative fitting\n",
      "     |      along a regularization path.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  LassoLarsIC : Lasso model fit with Lars using BIC\n",
      "     |      or AIC for model selection.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The object solves the same problem as the\n",
      "     |  :class:`~sklearn.linear_model.LassoCV` object. However, unlike the\n",
      "     |  :class:`~sklearn.linear_model.LassoCV`, it find the relevant alphas values\n",
      "     |  by itself. In general, because of this property, it will be more stable.\n",
      "     |  However, it is more fragile to heavily multicollinear datasets.\n",
      "     |\n",
      "     |  It is more efficient than the :class:`~sklearn.linear_model.LassoCV` if\n",
      "     |  only a small number of features are selected compared to the total number,\n",
      "     |  for instance if there are very few samples compared to the number of\n",
      "     |  features.\n",
      "     |\n",
      "     |  In `fit`, once the best parameter `alpha` is found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import LassoLarsCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(noise=4.0, random_state=0)\n",
      "     |  >>> reg = LassoLarsCV(cv=5).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9993...\n",
      "     |  >>> reg.alpha_\n",
      "     |  0.3972...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-78.4831...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LassoLarsCV\n",
      "     |      LarsCV\n",
      "     |      Lars\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, fit_intercept=True, verbose=False, max_iter=500, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True, positive=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._least_angle.LassoLarsCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLarsCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  method = 'lasso'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LarsCV:\n",
      "     |\n",
      "     |  fit(self, X, y, **params)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from LarsCV:\n",
      "     |\n",
      "     |  parameter = 'random_state'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lars:\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._least_angle.LassoLarsCV, *, Xy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLarsCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``Xy`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Lars:\n",
      "     |\n",
      "     |  positive = False\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LassoLarsIC(LassoLars)\n",
      "     |  LassoLarsIC(criterion='aic', *, fit_intercept=True, verbose=False, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, positive=False, noise_variance=None)\n",
      "     |\n",
      "     |  Lasso model fit with Lars using BIC or AIC for model selection.\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |  (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |  AIC is the Akaike information criterion [2]_ and BIC is the Bayes\n",
      "     |  Information criterion [3]_. Such criteria are useful to select the value\n",
      "     |  of the regularization parameter by making a trade-off between the\n",
      "     |  goodness of fit and the complexity of the model. A good model should\n",
      "     |  explain well the data while being simple.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <lasso_lars_ic>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  criterion : {'aic', 'bic'}, default='aic'\n",
      "     |      The type of criterion to use.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  precompute : bool, 'auto' or array-like, default='auto'\n",
      "     |      Whether to use a precomputed Gram matrix to speed up\n",
      "     |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |      matrix can also be passed as argument.\n",
      "     |\n",
      "     |  max_iter : int, default=500\n",
      "     |      Maximum number of iterations to perform. Can be used for\n",
      "     |      early stopping.\n",
      "     |\n",
      "     |  eps : float, default=np.finfo(float).eps\n",
      "     |      The machine-precision regularization in the computation of the\n",
      "     |      Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "     |      systems. Unlike the ``tol`` parameter in some iterative\n",
      "     |      optimization-based algorithms, this parameter does not control\n",
      "     |      the tolerance of the optimization.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      Restrict coefficients to be >= 0. Be aware that you might want to\n",
      "     |      remove fit_intercept which is set True by default.\n",
      "     |      Under the positive restriction the model coefficients do not converge\n",
      "     |      to the ordinary-least-squares solution for small values of alpha.\n",
      "     |      Only coefficients up to the smallest alpha value (``alphas_[alphas_ >\n",
      "     |      0.].min()`` when fit_path=True) reached by the stepwise Lars-Lasso\n",
      "     |      algorithm are typically in congruence with the solution of the\n",
      "     |      coordinate descent Lasso estimator.\n",
      "     |      As a consequence using LassoLarsIC only makes sense for problems where\n",
      "     |      a sparse solution is expected and/or reached.\n",
      "     |\n",
      "     |  noise_variance : float, default=None\n",
      "     |      The estimated noise variance of the data. If `None`, an unbiased\n",
      "     |      estimate is computed by an OLS model. However, it is only possible\n",
      "     |      in the case where `n_samples > n_features + fit_intercept`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array-like of shape (n_features,)\n",
      "     |      parameter vector (w in the formulation formula)\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      independent term in decision function.\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      the alpha parameter chosen by the information criterion\n",
      "     |\n",
      "     |  alphas_ : array-like of shape (n_alphas + 1,) or list of such arrays\n",
      "     |      Maximum of covariances (in absolute value) at each iteration.\n",
      "     |      ``n_alphas`` is either ``max_iter``, ``n_features`` or the\n",
      "     |      number of nodes in the path with ``alpha >= alpha_min``, whichever\n",
      "     |      is smaller. If a list, it will be of length `n_targets`.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      number of iterations run by lars_path to find the grid of\n",
      "     |      alphas.\n",
      "     |\n",
      "     |  criterion_ : array-like of shape (n_alphas,)\n",
      "     |      The value of the information criteria ('aic', 'bic') across all\n",
      "     |      alphas. The alpha which has the smallest information criterion is\n",
      "     |      chosen, as specified in [1]_.\n",
      "     |\n",
      "     |  noise_variance_ : float\n",
      "     |      The estimated noise variance from the data used to compute the\n",
      "     |      criterion.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso\n",
      "     |      path using LARS algorithm.\n",
      "     |  lasso_path : Compute Lasso path with coordinate descent.\n",
      "     |  Lasso : Linear Model trained with L1 prior as\n",
      "     |      regularizer (aka the Lasso).\n",
      "     |  LassoCV : Lasso linear model with iterative fitting\n",
      "     |      along a regularization path.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  LassoLarsCV: Cross-validated Lasso, using the LARS algorithm.\n",
      "     |  sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The number of degrees of freedom is computed as in [1]_.\n",
      "     |\n",
      "     |  To have more details regarding the mathematical formulation of the\n",
      "     |  AIC and BIC criteria, please refer to :ref:`User Guide <lasso_lars_ic>`.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] :arxiv:`Zou, Hui, Trevor Hastie, and Robert Tibshirani.\n",
      "     |          \"On the degrees of freedom of the lasso.\"\n",
      "     |          The Annals of Statistics 35.5 (2007): 2173-2192.\n",
      "     |          <0712.0881>`\n",
      "     |\n",
      "     |  .. [2] `Wikipedia entry on the Akaike information criterion\n",
      "     |          <https://en.wikipedia.org/wiki/Akaike_information_criterion>`_\n",
      "     |\n",
      "     |  .. [3] `Wikipedia entry on the Bayesian information criterion\n",
      "     |          <https://en.wikipedia.org/wiki/Bayesian_information_criterion>`_\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> reg = linear_model.LassoLarsIC(criterion='bic')\n",
      "     |  >>> X = [[-2, 2], [-1, 1], [0, 0], [1, 1], [2, 2]]\n",
      "     |  >>> y = [-2.2222, -1.1111, 0, -1.1111, -2.2222]\n",
      "     |  >>> reg.fit(X, y)\n",
      "     |  LassoLarsIC(criterion='bic')\n",
      "     |  >>> print(reg.coef_)\n",
      "     |  [ 0.  -1.11...]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LassoLarsIC\n",
      "     |      LassoLars\n",
      "     |      Lars\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, criterion='aic', *, fit_intercept=True, verbose=False, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, positive=False, noise_variance=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, copy_X=None)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      copy_X : bool, default=None\n",
      "     |          If provided, this parameter will override the choice\n",
      "     |          of copy_X made at instance creation.\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._least_angle.LassoLarsIC, *, copy_X: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLarsIC\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy_X : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy_X`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._least_angle.LassoLarsIC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._least_angle.LassoLarsIC\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  parameter = 'random_state'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from LassoLars:\n",
      "     |\n",
      "     |  method = 'lasso'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Lars:\n",
      "     |\n",
      "     |  positive = False\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      "     |  LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      "     |\n",
      "     |  Ordinary least squares Linear Regression.\n",
      "     |\n",
      "     |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      "     |  to minimize the residual sum of squares between the observed targets in\n",
      "     |  the dataset, and the targets predicted by the linear approximation.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to False, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      The number of jobs to use for the computation. This will only provide\n",
      "     |      speedup in case of sufficiently large problems, that is if firstly\n",
      "     |      `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
      "     |      to `True`. ``None`` means 1 unless in a\n",
      "     |      :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      "     |      processors. See :term:`Glossary <n_jobs>` for more details.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive. This\n",
      "     |      option is only supported for dense arrays.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      "     |      Estimated coefficients for the linear regression problem.\n",
      "     |      If multiple targets are passed during the fit (y 2D), this\n",
      "     |      is a 2D array of shape (n_targets, n_features), while if only\n",
      "     |      one target is passed, this is a 1D array of length n_features.\n",
      "     |\n",
      "     |  rank_ : int\n",
      "     |      Rank of matrix `X`. Only available when `X` is dense.\n",
      "     |\n",
      "     |  singular_ : array of shape (min(X, y),)\n",
      "     |      Singular values of `X`. Only available when `X` is dense.\n",
      "     |\n",
      "     |  intercept_ : float or array of shape (n_targets,)\n",
      "     |      Independent term in the linear model. Set to 0.0 if\n",
      "     |      `fit_intercept = False`.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Ridge : Ridge regression addresses some of the\n",
      "     |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      "     |      size of the coefficients with l2 regularization.\n",
      "     |  Lasso : The Lasso is a linear model that estimates\n",
      "     |      sparse coefficients with l1 regularization.\n",
      "     |  ElasticNet : Elastic-Net is a linear regression\n",
      "     |      model trained with both l1 and l2 -norm regularization of the\n",
      "     |      coefficients.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  From the implementation point of view, this is just plain Ordinary\n",
      "     |  Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
      "     |  (scipy.optimize.nnls) wrapped as a predictor object.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.linear_model import LinearRegression\n",
      "     |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      "     |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      "     |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      "     |  >>> reg = LinearRegression().fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  1.0\n",
      "     |  >>> reg.coef_\n",
      "     |  array([1., 2.])\n",
      "     |  >>> reg.intercept_\n",
      "     |  3.0...\n",
      "     |  >>> reg.predict(np.array([[3, 5]]))\n",
      "     |  array([16.])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LinearRegression\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample.\n",
      "     |\n",
      "     |          .. versionadded:: 0.17\n",
      "     |             parameter *sample_weight* support to LinearRegression.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted Estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._base.LinearRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._base.LinearRegression\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._base.LinearRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._base.LinearRegression\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Log(Classification)\n",
      "     |  Logistic regression loss for binary classification with y in {-1, 1}\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Log\n",
      "     |      Classification\n",
      "     |      LossFunction\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __reduce__(self)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Classification:\n",
      "     |\n",
      "     |  __reduce_cython__(self)\n",
      "     |\n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |\n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LossFunction:\n",
      "     |\n",
      "     |  py_dloss(self, p, y)\n",
      "     |      Python version of `dloss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The derivative of the loss function with regards to `p`.\n",
      "     |\n",
      "     |  py_loss(self, p, y)\n",
      "     |      Python version of `loss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x + intercept`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The loss evaluated at `p` and `y`.\n",
      "\n",
      "    class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      "     |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      "     |\n",
      "     |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      "     |\n",
      "     |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      "     |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      "     |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      "     |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      "     |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      "     |\n",
      "     |  This class implements regularized logistic regression using the\n",
      "     |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      "     |  that regularization is applied by default**. It can handle both dense\n",
      "     |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      "     |  floats for optimal performance; any other input format will be converted\n",
      "     |  (and copied).\n",
      "     |\n",
      "     |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      "     |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      "     |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      "     |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      "     |  'saga' solver.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  penalty : {'l1', 'l2', 'elasticnet', None}, default='l2'\n",
      "     |      Specify the norm of the penalty:\n",
      "     |\n",
      "     |      - `None`: no penalty is added;\n",
      "     |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      "     |      - `'l1'`: add a L1 penalty term;\n",
      "     |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      "     |\n",
      "     |      .. warning::\n",
      "     |         Some penalties may not work with some solvers. See the parameter\n",
      "     |         `solver` below, to know the compatibility between the penalty and\n",
      "     |         solver.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      "     |\n",
      "     |  dual : bool, default=False\n",
      "     |      Dual (constrained) or primal (regularized, see also\n",
      "     |      :ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation\n",
      "     |      is only implemented for l2 penalty with liblinear solver. Prefer dual=False when\n",
      "     |      n_samples > n_features.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      Tolerance for stopping criteria.\n",
      "     |\n",
      "     |  C : float, default=1.0\n",
      "     |      Inverse of regularization strength; must be a positive float.\n",
      "     |      Like in support vector machines, smaller values specify stronger\n",
      "     |      regularization.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "     |      added to the decision function.\n",
      "     |\n",
      "     |  intercept_scaling : float, default=1\n",
      "     |      Useful only when the solver 'liblinear' is used\n",
      "     |      and self.fit_intercept is set to True. In this case, x becomes\n",
      "     |      [x, self.intercept_scaling],\n",
      "     |      i.e. a \"synthetic\" feature with constant value equal to\n",
      "     |      intercept_scaling is appended to the instance vector.\n",
      "     |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      "     |\n",
      "     |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "     |      as all other features.\n",
      "     |      To lessen the effect of regularization on synthetic feature weight\n",
      "     |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "     |\n",
      "     |  class_weight : dict or 'balanced', default=None\n",
      "     |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      "     |      If not given, all classes are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |      Note that these weights will be multiplied with sample_weight (passed\n",
      "     |      through the fit method) if sample_weight is specified.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *class_weight='balanced'*\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      "     |      data. See :term:`Glossary <random_state>` for details.\n",
      "     |\n",
      "     |  solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'\n",
      "     |\n",
      "     |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      "     |      To choose a solver, you might want to consider the following aspects:\n",
      "     |\n",
      "     |      - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      "     |        and 'saga' are faster for large ones;\n",
      "     |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      "     |        'lbfgs' handle multinomial loss;\n",
      "     |      - 'liblinear' and 'newton-cholesky' can only handle binary classification\n",
      "     |        by default. To apply a one-versus-rest scheme for the multiclass setting\n",
      "     |        one can wrapt it with the `OneVsRestClassifier`.\n",
      "     |      - 'newton-cholesky' is a good choice for `n_samples` >> `n_features`,\n",
      "     |        especially with one-hot encoded categorical features with rare\n",
      "     |        categories. Be aware that the memory usage of this solver has a quadratic\n",
      "     |        dependency on `n_features` because it explicitly computes the Hessian\n",
      "     |        matrix.\n",
      "     |\n",
      "     |      .. warning::\n",
      "     |         The choice of the algorithm depends on the penalty chosen and on\n",
      "     |         (multinomial) multiclass support:\n",
      "     |\n",
      "     |         ================= ============================== ======================\n",
      "     |         solver            penalty                        multinomial multiclass\n",
      "     |         ================= ============================== ======================\n",
      "     |         'lbfgs'           'l2', None                     yes\n",
      "     |         'liblinear'       'l1', 'l2'                     no\n",
      "     |         'newton-cg'       'l2', None                     yes\n",
      "     |         'newton-cholesky' 'l2', None                     no\n",
      "     |         'sag'             'l2', None                     yes\n",
      "     |         'saga'            'elasticnet', 'l1', 'l2', None yes\n",
      "     |         ================= ============================== ======================\n",
      "     |\n",
      "     |      .. note::\n",
      "     |         'sag' and 'saga' fast convergence is only guaranteed on features\n",
      "     |         with approximately the same scale. You can preprocess the data with\n",
      "     |         a scaler from :mod:`sklearn.preprocessing`.\n",
      "     |\n",
      "     |      .. seealso::\n",
      "     |         Refer to the User Guide for more information regarding\n",
      "     |         :class:`LogisticRegression` and more specifically the\n",
      "     |         :ref:`Table <Logistic_regression>`\n",
      "     |         summarizing solver/penalty supports.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         Stochastic Average Gradient descent solver.\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         SAGA solver.\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      "     |      .. versionadded:: 1.2\n",
      "     |         newton-cholesky solver.\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      Maximum number of iterations taken for the solvers to converge.\n",
      "     |\n",
      "     |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      "     |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      "     |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      "     |      across the entire probability distribution, *even when the data is\n",
      "     |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      "     |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      "     |      and otherwise selects 'multinomial'.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      "     |      .. deprecated:: 1.5\n",
      "     |         ``multi_class`` was deprecated in version 1.5 and will be removed in 1.7.\n",
      "     |         From then on, the recommended 'multinomial' will always be used for\n",
      "     |         `n_classes >= 3`.\n",
      "     |         Solvers that do not support 'multinomial' will raise an error.\n",
      "     |         Use `sklearn.multiclass.OneVsRestClassifier(LogisticRegression())` if you\n",
      "     |         still want to use OvR.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      "     |      number for verbosity.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPU cores used when parallelizing over classes if\n",
      "     |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      "     |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      "     |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "     |      context. ``-1`` means using all processors.\n",
      "     |      See :term:`Glossary <n_jobs>` for more details.\n",
      "     |\n",
      "     |  l1_ratio : float, default=None\n",
      "     |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      "     |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      "     |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      "     |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      "     |      combination of L1 and L2.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |\n",
      "     |  classes_ : ndarray of shape (n_classes, )\n",
      "     |      A list of class labels known to the classifier.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "     |      Coefficient of the features in the decision function.\n",
      "     |\n",
      "     |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      "     |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      "     |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      "     |      Intercept (a.k.a. bias) added to the decision function.\n",
      "     |\n",
      "     |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      "     |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      "     |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      "     |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      "     |      outcome 0 (False).\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      "     |      Actual number of iterations for all classes. If binary or multinomial,\n",
      "     |      it returns only 1 element. For liblinear solver, only the maximum\n",
      "     |      number of iteration across all classes is given.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.20\n",
      "     |\n",
      "     |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      "     |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      "     |      the parameter ``loss=\"log_loss\"``).\n",
      "     |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The underlying C implementation uses a random number generator to\n",
      "     |  select features when fitting the model. It is thus not uncommon,\n",
      "     |  to have slightly different results for the same input data. If\n",
      "     |  that happens, try with a smaller tol parameter.\n",
      "     |\n",
      "     |  Predict output may not match that of standalone liblinear in certain\n",
      "     |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      "     |  in the narrative documentation.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |\n",
      "     |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      "     |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      "     |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      "     |\n",
      "     |  LIBLINEAR -- A Library for Large Linear Classification\n",
      "     |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      "     |\n",
      "     |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      "     |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      "     |      https://hal.inria.fr/hal-00860051/document\n",
      "     |\n",
      "     |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      "     |          :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
      "     |          for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
      "     |\n",
      "     |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      "     |      methods for logistic regression and maximum entropy models.\n",
      "     |      Machine Learning 85(1-2):41-75.\n",
      "     |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_iris\n",
      "     |  >>> from sklearn.linear_model import LogisticRegression\n",
      "     |  >>> X, y = load_iris(return_X_y=True)\n",
      "     |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      "     |  >>> clf.predict(X[:2, :])\n",
      "     |  array([0, 0])\n",
      "     |  >>> clf.predict_proba(X[:2, :])\n",
      "     |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      "     |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.97...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LogisticRegression\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vector, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target vector relative to X.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,) default=None\n",
      "     |          Array of weights that are assigned to individual samples.\n",
      "     |          If not provided, then each sample is given unit weight.\n",
      "     |\n",
      "     |          .. versionadded:: 0.17\n",
      "     |             *sample_weight* support to LogisticRegression.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      "     |\n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Predict logarithm of probability estimates.\n",
      "     |\n",
      "     |      The returned estimates for all classes are ordered by the\n",
      "     |      label of classes.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Vector to be scored, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the sample for each class in the\n",
      "     |          model, where classes are ordered as they are in ``self.classes_``.\n",
      "     |\n",
      "     |  predict_proba(self, X)\n",
      "     |      Probability estimates.\n",
      "     |\n",
      "     |      The returned estimates for all classes are ordered by the\n",
      "     |      label of classes.\n",
      "     |\n",
      "     |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      "     |      the softmax function is used to find the predicted probability of\n",
      "     |      each class.\n",
      "     |      Else use a one-vs-rest approach, i.e. calculate the probability\n",
      "     |      of each class assuming it to be positive using the logistic function.\n",
      "     |      and normalize these values across all the classes.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Vector to be scored, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the sample for each class in the model,\n",
      "     |          where classes are ordered as they are in ``self.classes_``.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._logistic.LogisticRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._logistic.LogisticRegression\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._logistic.LogisticRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._logistic.LogisticRegression\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the predictions.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,)\n",
      "     |          Vector containing the class labels for each sample.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class LogisticRegressionCV(LogisticRegression, sklearn.linear_model._base.LinearClassifierMixin, sklearn.base.BaseEstimator)\n",
      "     |  LogisticRegressionCV(*, Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=100, class_weight=None, n_jobs=None, verbose=0, refit=True, intercept_scaling=1.0, multi_class='deprecated', random_state=None, l1_ratios=None)\n",
      "     |\n",
      "     |  Logistic Regression CV (aka logit, MaxEnt) classifier.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  This class implements logistic regression using liblinear, newton-cg, sag\n",
      "     |  or lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2\n",
      "     |  regularization with primal formulation. The liblinear solver supports both\n",
      "     |  L1 and L2 regularization, with a dual formulation only for the L2 penalty.\n",
      "     |  Elastic-Net penalty is only supported by the saga solver.\n",
      "     |\n",
      "     |  For the grid of `Cs` values and `l1_ratios` values, the best hyperparameter\n",
      "     |  is selected by the cross-validator\n",
      "     |  :class:`~sklearn.model_selection.StratifiedKFold`, but it can be changed\n",
      "     |  using the :term:`cv` parameter. The 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      "     |  solvers can warm-start the coefficients (see :term:`Glossary<warm_start>`).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  Cs : int or list of floats, default=10\n",
      "     |      Each of the values in Cs describes the inverse of regularization\n",
      "     |      strength. If Cs is as an int, then a grid of Cs values are chosen\n",
      "     |      in a logarithmic scale between 1e-4 and 1e4.\n",
      "     |      Like in support vector machines, smaller values specify stronger\n",
      "     |      regularization.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "     |      added to the decision function.\n",
      "     |\n",
      "     |  cv : int or cross-validation generator, default=None\n",
      "     |      The default cross-validation generator used is Stratified K-Folds.\n",
      "     |      If an integer is provided, then it is the number of folds used.\n",
      "     |      See the module :mod:`sklearn.model_selection` module for the\n",
      "     |      list of possible cross-validation objects.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  dual : bool, default=False\n",
      "     |      Dual (constrained) or primal (regularized, see also\n",
      "     |      :ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation\n",
      "     |      is only implemented for l2 penalty with liblinear solver. Prefer dual=False when\n",
      "     |      n_samples > n_features.\n",
      "     |\n",
      "     |  penalty : {'l1', 'l2', 'elasticnet'}, default='l2'\n",
      "     |      Specify the norm of the penalty:\n",
      "     |\n",
      "     |      - `'l2'`: add a L2 penalty term (used by default);\n",
      "     |      - `'l1'`: add a L1 penalty term;\n",
      "     |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      "     |\n",
      "     |      .. warning::\n",
      "     |         Some penalties may not work with some solvers. See the parameter\n",
      "     |         `solver` below, to know the compatibility between the penalty and\n",
      "     |         solver.\n",
      "     |\n",
      "     |  scoring : str or callable, default=None\n",
      "     |      A string (see model evaluation documentation) or\n",
      "     |      a scorer callable object / function with signature\n",
      "     |      ``scorer(estimator, X, y)``. For a list of scoring functions\n",
      "     |      that can be used, look at :mod:`sklearn.metrics`. The\n",
      "     |      default scoring option used is 'accuracy'.\n",
      "     |\n",
      "     |  solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'\n",
      "     |\n",
      "     |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      "     |      To choose a solver, you might want to consider the following aspects:\n",
      "     |\n",
      "     |      - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      "     |        and 'saga' are faster for large ones;\n",
      "     |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      "     |        'lbfgs' handle multinomial loss;\n",
      "     |      - 'liblinear' might be slower in :class:`LogisticRegressionCV`\n",
      "     |        because it does not handle warm-starting.\n",
      "     |      - 'liblinear' and 'newton-cholesky' can only handle binary classification\n",
      "     |        by default. To apply a one-versus-rest scheme for the multiclass setting\n",
      "     |        one can wrapt it with the `OneVsRestClassifier`.\n",
      "     |      - 'newton-cholesky' is a good choice for `n_samples` >> `n_features`,\n",
      "     |        especially with one-hot encoded categorical features with rare\n",
      "     |        categories. Be aware that the memory usage of this solver has a quadratic\n",
      "     |        dependency on `n_features` because it explicitly computes the Hessian\n",
      "     |        matrix.\n",
      "     |\n",
      "     |      .. warning::\n",
      "     |         The choice of the algorithm depends on the penalty chosen and on\n",
      "     |         (multinomial) multiclass support:\n",
      "     |\n",
      "     |         ================= ============================== ======================\n",
      "     |         solver            penalty                        multinomial multiclass\n",
      "     |         ================= ============================== ======================\n",
      "     |         'lbfgs'           'l2'                           yes\n",
      "     |         'liblinear'       'l1', 'l2'                     no\n",
      "     |         'newton-cg'       'l2'                           yes\n",
      "     |         'newton-cholesky' 'l2',                          no\n",
      "     |         'sag'             'l2',                          yes\n",
      "     |         'saga'            'elasticnet', 'l1', 'l2'       yes\n",
      "     |         ================= ============================== ======================\n",
      "     |\n",
      "     |      .. note::\n",
      "     |         'sag' and 'saga' fast convergence is only guaranteed on features\n",
      "     |         with approximately the same scale. You can preprocess the data with\n",
      "     |         a scaler from :mod:`sklearn.preprocessing`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         Stochastic Average Gradient descent solver.\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         SAGA solver.\n",
      "     |      .. versionadded:: 1.2\n",
      "     |         newton-cholesky solver.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      Tolerance for stopping criteria.\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      Maximum number of iterations of the optimization algorithm.\n",
      "     |\n",
      "     |  class_weight : dict or 'balanced', default=None\n",
      "     |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      "     |      If not given, all classes are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |      Note that these weights will be multiplied with sample_weight (passed\n",
      "     |      through the fit method) if sample_weight is specified.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         class_weight == 'balanced'\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPU cores used during the cross-validation loop.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      For the 'liblinear', 'sag' and 'lbfgs' solvers set verbose to any\n",
      "     |      positive number for verbosity.\n",
      "     |\n",
      "     |  refit : bool, default=True\n",
      "     |      If set to True, the scores are averaged across all folds, and the\n",
      "     |      coefs and the C that corresponds to the best score is taken, and a\n",
      "     |      final refit is done using these parameters.\n",
      "     |      Otherwise the coefs, intercepts and C that correspond to the\n",
      "     |      best scores across folds are averaged.\n",
      "     |\n",
      "     |  intercept_scaling : float, default=1\n",
      "     |      Useful only when the solver 'liblinear' is used\n",
      "     |      and self.fit_intercept is set to True. In this case, x becomes\n",
      "     |      [x, self.intercept_scaling],\n",
      "     |      i.e. a \"synthetic\" feature with constant value equal to\n",
      "     |      intercept_scaling is appended to the instance vector.\n",
      "     |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      "     |\n",
      "     |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "     |      as all other features.\n",
      "     |      To lessen the effect of regularization on synthetic feature weight\n",
      "     |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "     |\n",
      "     |  multi_class : {'auto, 'ovr', 'multinomial'}, default='auto'\n",
      "     |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      "     |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      "     |      across the entire probability distribution, *even when the data is\n",
      "     |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      "     |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      "     |      and otherwise selects 'multinomial'.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      "     |      .. deprecated:: 1.5\n",
      "     |         ``multi_class`` was deprecated in version 1.5 and will be removed in 1.7.\n",
      "     |         From then on, the recommended 'multinomial' will always be used for\n",
      "     |         `n_classes >= 3`.\n",
      "     |         Solvers that do not support 'multinomial' will raise an error.\n",
      "     |         Use `sklearn.multiclass.OneVsRestClassifier(LogisticRegressionCV())` if you\n",
      "     |         still want to use OvR.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used when `solver='sag'`, 'saga' or 'liblinear' to shuffle the data.\n",
      "     |      Note that this only applies to the solver and not the cross-validation\n",
      "     |      generator. See :term:`Glossary <random_state>` for details.\n",
      "     |\n",
      "     |  l1_ratios : list of float, default=None\n",
      "     |      The list of Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``.\n",
      "     |      Only used if ``penalty='elasticnet'``. A value of 0 is equivalent to\n",
      "     |      using ``penalty='l2'``, while 1 is equivalent to using\n",
      "     |      ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a combination\n",
      "     |      of L1 and L2.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  classes_ : ndarray of shape (n_classes, )\n",
      "     |      A list of class labels known to the classifier.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "     |      Coefficient of the features in the decision function.\n",
      "     |\n",
      "     |      `coef_` is of shape (1, n_features) when the given problem\n",
      "     |      is binary.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      "     |      Intercept (a.k.a. bias) added to the decision function.\n",
      "     |\n",
      "     |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      "     |      `intercept_` is of shape(1,) when the problem is binary.\n",
      "     |\n",
      "     |  Cs_ : ndarray of shape (n_cs)\n",
      "     |      Array of C i.e. inverse of regularization parameter values used\n",
      "     |      for cross-validation.\n",
      "     |\n",
      "     |  l1_ratios_ : ndarray of shape (n_l1_ratios)\n",
      "     |      Array of l1_ratios used for cross-validation. If no l1_ratio is used\n",
      "     |      (i.e. penalty is not 'elasticnet'), this is set to ``[None]``\n",
      "     |\n",
      "     |  coefs_paths_ : ndarray of shape (n_folds, n_cs, n_features) or                    (n_folds, n_cs, n_features + 1)\n",
      "     |      dict with classes as the keys, and the path of coefficients obtained\n",
      "     |      during cross-validating across each fold and then across each Cs\n",
      "     |      after doing an OvR for the corresponding class as values.\n",
      "     |      If the 'multi_class' option is set to 'multinomial', then\n",
      "     |      the coefs_paths are the coefficients corresponding to each class.\n",
      "     |      Each dict value has shape ``(n_folds, n_cs, n_features)`` or\n",
      "     |      ``(n_folds, n_cs, n_features + 1)`` depending on whether the\n",
      "     |      intercept is fit or not. If ``penalty='elasticnet'``, the shape is\n",
      "     |      ``(n_folds, n_cs, n_l1_ratios_, n_features)`` or\n",
      "     |      ``(n_folds, n_cs, n_l1_ratios_, n_features + 1)``.\n",
      "     |\n",
      "     |  scores_ : dict\n",
      "     |      dict with classes as the keys, and the values as the\n",
      "     |      grid of scores obtained during cross-validating each fold, after doing\n",
      "     |      an OvR for the corresponding class. If the 'multi_class' option\n",
      "     |      given is 'multinomial' then the same scores are repeated across\n",
      "     |      all classes, since this is the multinomial class. Each dict value\n",
      "     |      has shape ``(n_folds, n_cs)`` or ``(n_folds, n_cs, n_l1_ratios)`` if\n",
      "     |      ``penalty='elasticnet'``.\n",
      "     |\n",
      "     |  C_ : ndarray of shape (n_classes,) or (n_classes - 1,)\n",
      "     |      Array of C that maps to the best scores across every class. If refit is\n",
      "     |      set to False, then for each class, the best C is the average of the\n",
      "     |      C's that correspond to the best scores for each fold.\n",
      "     |      `C_` is of shape(n_classes,) when the problem is binary.\n",
      "     |\n",
      "     |  l1_ratio_ : ndarray of shape (n_classes,) or (n_classes - 1,)\n",
      "     |      Array of l1_ratio that maps to the best scores across every class. If\n",
      "     |      refit is set to False, then for each class, the best l1_ratio is the\n",
      "     |      average of the l1_ratio's that correspond to the best scores for each\n",
      "     |      fold.  `l1_ratio_` is of shape(n_classes,) when the problem is binary.\n",
      "     |\n",
      "     |  n_iter_ : ndarray of shape (n_classes, n_folds, n_cs) or (1, n_folds, n_cs)\n",
      "     |      Actual number of iterations for all classes, folds and Cs.\n",
      "     |      In the binary or multinomial cases, the first dimension is equal to 1.\n",
      "     |      If ``penalty='elasticnet'``, the shape is ``(n_classes, n_folds,\n",
      "     |      n_cs, n_l1_ratios)`` or ``(1, n_folds, n_cs, n_l1_ratios)``.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  LogisticRegression : Logistic regression without tuning the\n",
      "     |      hyperparameter `C`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_iris\n",
      "     |  >>> from sklearn.linear_model import LogisticRegressionCV\n",
      "     |  >>> X, y = load_iris(return_X_y=True)\n",
      "     |  >>> clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\n",
      "     |  >>> clf.predict(X[:2, :])\n",
      "     |  array([0, 0])\n",
      "     |  >>> clf.predict_proba(X[:2, :]).shape\n",
      "     |  (2, 3)\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.98...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LogisticRegressionCV\n",
      "     |      LogisticRegression\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=100, class_weight=None, n_jobs=None, verbose=0, refit=True, intercept_scaling=1.0, multi_class='deprecated', random_state=None, l1_ratios=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, **params)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vector, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target vector relative to X.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,) default=None\n",
      "     |          Array of weights that are assigned to individual samples.\n",
      "     |          If not provided, then each sample is given unit weight.\n",
      "     |\n",
      "     |      **params : dict\n",
      "     |          Parameters to pass to the underlying splitter and scorer.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted LogisticRegressionCV estimator.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None, **score_params)\n",
      "     |      Score using the `scoring` option on the given test data and labels.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          True labels for X.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      **score_params : dict\n",
      "     |          Parameters to pass to the `score` method of the underlying scorer.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Score of self.predict(X) w.r.t. y.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._logistic.LogisticRegressionCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._logistic.LogisticRegressionCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._logistic.LogisticRegressionCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._logistic.LogisticRegressionCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  param = 'l1_ratio'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LogisticRegression:\n",
      "     |\n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Predict logarithm of probability estimates.\n",
      "     |\n",
      "     |      The returned estimates for all classes are ordered by the\n",
      "     |      label of classes.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Vector to be scored, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the sample for each class in the\n",
      "     |          model, where classes are ordered as they are in ``self.classes_``.\n",
      "     |\n",
      "     |  predict_proba(self, X)\n",
      "     |      Probability estimates.\n",
      "     |\n",
      "     |      The returned estimates for all classes are ordered by the\n",
      "     |      label of classes.\n",
      "     |\n",
      "     |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      "     |      the softmax function is used to find the predicted probability of\n",
      "     |      each class.\n",
      "     |      Else use a one-vs-rest approach, i.e. calculate the probability\n",
      "     |      of each class assuming it to be positive using the logistic function.\n",
      "     |      and normalize these values across all the classes.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Vector to be scored, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the sample for each class in the model,\n",
      "     |          where classes are ordered as they are in ``self.classes_``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the predictions.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,)\n",
      "     |          Vector containing the class labels for each sample.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class ModifiedHuber(Classification)\n",
      "     |  Modified Huber loss for binary classification with y in {-1, 1}\n",
      "     |\n",
      "     |  This is equivalent to quadratically smoothed SVM with gamma = 2.\n",
      "     |\n",
      "     |  See T. Zhang 'Solving Large Scale Linear Prediction Problems Using\n",
      "     |  Stochastic Gradient Descent', ICML'04.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ModifiedHuber\n",
      "     |      Classification\n",
      "     |      LossFunction\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __reduce__(self)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Classification:\n",
      "     |\n",
      "     |  __reduce_cython__(self)\n",
      "     |\n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |\n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LossFunction:\n",
      "     |\n",
      "     |  py_dloss(self, p, y)\n",
      "     |      Python version of `dloss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The derivative of the loss function with regards to `p`.\n",
      "     |\n",
      "     |  py_loss(self, p, y)\n",
      "     |      Python version of `loss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x + intercept`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The loss evaluated at `p` and `y`.\n",
      "\n",
      "    class MultiTaskElasticNet(Lasso)\n",
      "     |  MultiTaskElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.\n",
      "     |\n",
      "     |  The optimization objective for MultiTaskElasticNet is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |      + alpha * l1_ratio * ||W||_21\n",
      "     |      + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |  Where::\n",
      "     |\n",
      "     |      ||W||_21 = sum_i sqrt(sum_j W_ij ^ 2)\n",
      "     |\n",
      "     |  i.e. the sum of norms of each row.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <multi_task_elastic_net>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Constant that multiplies the L1/L2 term. Defaults to 1.0.\n",
      "     |\n",
      "     |  l1_ratio : float, default=0.5\n",
      "     |      The ElasticNet mixing parameter, with 0 < l1_ratio <= 1.\n",
      "     |      For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it\n",
      "     |      is an L2 penalty.\n",
      "     |      For ``0 < l1_ratio < 1``, the penalty is a combination of L1/L2 and L2.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  intercept_ : ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_targets, n_features)\n",
      "     |      Parameter vector (W in the cost function formula). If a 1D y is\n",
      "     |      passed in at fit (non multi-task usage), ``coef_`` is then a 1D array.\n",
      "     |      Note that ``coef_`` stores the transpose of ``W``, ``W.T``.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance.\n",
      "     |\n",
      "     |  dual_gap_ : float\n",
      "     |      The dual gaps at the end of the optimization.\n",
      "     |\n",
      "     |  eps_ : float\n",
      "     |      The tolerance scaled scaled by the variance of the target `y`.\n",
      "     |\n",
      "     |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "     |      Sparse representation of the `coef_`.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in\n",
      "     |      cross-validation.\n",
      "     |  ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |  MultiTaskLasso : Multi-task Lasso model trained with L1/L2\n",
      "     |      mixed-norm as regularizer.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The algorithm used to fit the model is coordinate descent.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the X and y arguments of the fit\n",
      "     |  method should be directly passed as Fortran-contiguous numpy arrays.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.MultiTaskElasticNet(alpha=0.1)\n",
      "     |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [[0, 0], [1, 1], [2, 2]])\n",
      "     |  MultiTaskElasticNet(alpha=0.1)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [[0.45663524 0.45612256]\n",
      "     |   [0.45663524 0.45612256]]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  [0.0872422 0.0872422]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MultiTaskElasticNet\n",
      "     |      Lasso\n",
      "     |      ElasticNet\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit MultiTaskElasticNet model with coordinate descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Data.\n",
      "     |      y : ndarray of shape (n_samples, n_targets)\n",
      "     |          Target. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Coordinate descent is an algorithm that considers each column of\n",
      "     |      data at a time hence it will automatically convert the X input\n",
      "     |      as a Fortran-contiguous numpy array if necessary.\n",
      "     |\n",
      "     |      To avoid memory re-allocation it is advised to allocate the\n",
      "     |      initial data in memory directly using that format.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.MultiTaskElasticNet, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskElasticNet\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  param = 'positive'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lasso:\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.MultiTaskElasticNet, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskElasticNet\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from Lasso:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ElasticNet:\n",
      "     |\n",
      "     |  sparse_coef_\n",
      "     |      Sparse representation of the fitted `coef_`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class MultiTaskElasticNetCV(sklearn.base.RegressorMixin, LinearModelCV)\n",
      "     |  MultiTaskElasticNetCV(*, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  The optimization objective for MultiTaskElasticNet is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n",
      "     |      + alpha * l1_ratio * ||W||_21\n",
      "     |      + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |  Where::\n",
      "     |\n",
      "     |      ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |  i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <multi_task_elastic_net>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.15\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  l1_ratio : float or list of float, default=0.5\n",
      "     |      The ElasticNet mixing parameter, with 0 < l1_ratio <= 1.\n",
      "     |      For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it\n",
      "     |      is an L2 penalty.\n",
      "     |      For ``0 < l1_ratio < 1``, the penalty is a combination of L1/L2 and L2.\n",
      "     |      This parameter can be a list, in which case the different\n",
      "     |      values are tested by cross-validation and the one giving the best\n",
      "     |      prediction score is used. Note that a good choice of list of\n",
      "     |      values for l1_ratio is often to put more values close to 1\n",
      "     |      (i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,\n",
      "     |      .9, .95, .99, 1]``.\n",
      "     |\n",
      "     |  eps : float, default=1e-3\n",
      "     |      Length of the path. ``eps=1e-3`` means that\n",
      "     |      ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |  n_alphas : int, default=100\n",
      "     |      Number of alphas along the regularization path.\n",
      "     |\n",
      "     |  alphas : array-like, default=None\n",
      "     |      List of alphas where to compute the models.\n",
      "     |      If not provided, set automatically.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - int, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  verbose : bool or int, default=0\n",
      "     |      Amount of verbosity.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation. Note that this is\n",
      "     |      used only if multiple values for l1_ratio are given.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  intercept_ : ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_targets, n_features)\n",
      "     |      Parameter vector (W in the cost function formula).\n",
      "     |      Note that ``coef_`` stores the transpose of ``W``, ``W.T``.\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      The amount of penalization chosen by cross validation.\n",
      "     |\n",
      "     |  mse_path_ : ndarray of shape (n_alphas, n_folds) or                 (n_l1_ratio, n_alphas, n_folds)\n",
      "     |      Mean square error for the test set on each fold, varying alpha.\n",
      "     |\n",
      "     |  alphas_ : ndarray of shape (n_alphas,) or (n_l1_ratio, n_alphas)\n",
      "     |      The grid of alphas used for fitting, for each l1_ratio.\n",
      "     |\n",
      "     |  l1_ratio_ : float\n",
      "     |      Best l1_ratio obtained by cross-validation.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance for the optimal alpha.\n",
      "     |\n",
      "     |  dual_gap_ : float\n",
      "     |      The dual gap at the end of the optimization for the optimal alpha.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  MultiTaskElasticNet : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |  ElasticNetCV : Elastic net model with best model selection by\n",
      "     |      cross-validation.\n",
      "     |  MultiTaskLassoCV : Multi-task Lasso model trained with L1 norm\n",
      "     |      as regularizer and built-in cross-validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The algorithm used to fit the model is coordinate descent.\n",
      "     |\n",
      "     |  In `fit`, once the best parameters `l1_ratio` and `alpha` are found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the `X` and `y` arguments of the\n",
      "     |  `fit` method should be directly passed as Fortran-contiguous numpy arrays.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.MultiTaskElasticNetCV(cv=3)\n",
      "     |  >>> clf.fit([[0,0], [1, 1], [2, 2]],\n",
      "     |  ...         [[0, 0], [1, 1], [2, 2]])\n",
      "     |  MultiTaskElasticNetCV(cv=3)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [[0.52875032 0.46958558]\n",
      "     |   [0.52875032 0.46958558]]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  [0.00166409 0.00166409]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MultiTaskElasticNetCV\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      LinearModelCV\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, max_iter=1000, tol=0.0001, cv=None, copy_X=True, verbose=0, n_jobs=None, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, **params)\n",
      "     |      Fit MultiTaskElasticNet model with coordinate descent.\n",
      "     |\n",
      "     |      Fit is on grid of alphas and best alpha estimated by cross-validation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      y : ndarray of shape (n_samples, n_targets)\n",
      "     |          Training target variable. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns MultiTaskElasticNet instance.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LinearModelCV:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class MultiTaskLasso(MultiTaskElasticNet)\n",
      "     |  MultiTaskLasso(alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.\n",
      "     |\n",
      "     |  The optimization objective for Lasso is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21\n",
      "     |\n",
      "     |  Where::\n",
      "     |\n",
      "     |      ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |  i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <multi_task_lasso>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Constant that multiplies the L1/L2 term. Defaults to 1.0.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_targets, n_features)\n",
      "     |      Parameter vector (W in the cost function formula).\n",
      "     |      Note that ``coef_`` stores the transpose of ``W``, ``W.T``.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance.\n",
      "     |\n",
      "     |  dual_gap_ : ndarray of shape (n_alphas,)\n",
      "     |      The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |  eps_ : float\n",
      "     |      The tolerance scaled scaled by the variance of the target `y`.\n",
      "     |\n",
      "     |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      "     |      Sparse representation of the `coef_`.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Lasso: Linear Model trained with L1 prior as regularizer (aka the Lasso).\n",
      "     |  MultiTaskLassoCV: Multi-task L1 regularized linear model with built-in\n",
      "     |      cross-validation.\n",
      "     |  MultiTaskElasticNetCV: Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The algorithm used to fit the model is coordinate descent.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the X and y arguments of the fit\n",
      "     |  method should be directly passed as Fortran-contiguous numpy arrays.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.MultiTaskLasso(alpha=0.1)\n",
      "     |  >>> clf.fit([[0, 1], [1, 2], [2, 4]], [[0, 0], [1, 1], [2, 3]])\n",
      "     |  MultiTaskLasso(alpha=0.1)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [[0.         0.60809415]\n",
      "     |  [0.         0.94592424]]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  [-0.41888636 -0.87382323]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MultiTaskLasso\n",
      "     |      MultiTaskElasticNet\n",
      "     |      Lasso\n",
      "     |      ElasticNet\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.MultiTaskLasso, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskLasso\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MultiTaskElasticNet:\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit MultiTaskElasticNet model with coordinate descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Data.\n",
      "     |      y : ndarray of shape (n_samples, n_targets)\n",
      "     |          Target. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Coordinate descent is an algorithm that considers each column of\n",
      "     |      data at a time hence it will automatically convert the X input\n",
      "     |      as a Fortran-contiguous numpy array if necessary.\n",
      "     |\n",
      "     |      To avoid memory re-allocation it is advised to allocate the\n",
      "     |      initial data in memory directly using that format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MultiTaskElasticNet:\n",
      "     |\n",
      "     |  param = 'positive'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lasso:\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.MultiTaskLasso, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskLasso\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from Lasso:\n",
      "     |\n",
      "     |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "     |      Compute elastic net path with coordinate descent.\n",
      "     |\n",
      "     |      The elastic net optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "     |          + alpha * l1_ratio * ||w||_1\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "     |          + alpha * l1_ratio * ||W||_21\n",
      "     |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      l1_ratio : float, default=0.5\n",
      "     |          Number between 0 and 1 passed to elastic net (scaling between\n",
      "     |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If None alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      check_input : bool, default=True\n",
      "     |          If set to False, the input validation checks are skipped (including the\n",
      "     |          Gram matrix when provided). It is assumed that they are handled\n",
      "     |          by the caller.\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |          (Is returned when ``return_n_iter`` is set to True).\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "     |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "     |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "     |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from sklearn.linear_model import enet_path\n",
      "     |      >>> from sklearn.datasets import make_regression\n",
      "     |      >>> X, y, true_coef = make_regression(\n",
      "     |      ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "     |      ... )\n",
      "     |      >>> true_coef\n",
      "     |      array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "     |      >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "     |      >>> alphas.shape\n",
      "     |      (3,)\n",
      "     |      >>> estimated_coef\n",
      "     |       array([[ 0.        ,  0.78...,  0.56...],\n",
      "     |              [ 0.        ,  1.12...,  0.61...],\n",
      "     |              [-0.        , -2.12..., -1.12...],\n",
      "     |              [ 0.        , 23.04..., 88.93...],\n",
      "     |              [ 0.        , 10.63..., 41.56...]])\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ElasticNet:\n",
      "     |\n",
      "     |  sparse_coef_\n",
      "     |      Sparse representation of the fitted `coef_`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class MultiTaskLassoCV(sklearn.base.RegressorMixin, LinearModelCV)\n",
      "     |  MultiTaskLassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, random_state=None, selection='cyclic')\n",
      "     |\n",
      "     |  Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  The optimization objective for MultiTaskLasso is::\n",
      "     |\n",
      "     |      (1 / (2 * n_samples)) * ||Y - XW||^Fro_2 + alpha * ||W||_21\n",
      "     |\n",
      "     |  Where::\n",
      "     |\n",
      "     |      ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |  i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <multi_task_lasso>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.15\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  eps : float, default=1e-3\n",
      "     |      Length of the path. ``eps=1e-3`` means that\n",
      "     |      ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |  n_alphas : int, default=100\n",
      "     |      Number of alphas along the regularization path.\n",
      "     |\n",
      "     |  alphas : array-like, default=None\n",
      "     |      List of alphas where to compute the models.\n",
      "     |      If not provided, set automatically.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of iterations.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The tolerance for the optimization: if the updates are\n",
      "     |      smaller than ``tol``, the optimization code checks the\n",
      "     |      dual gap for optimality and continues until it is smaller\n",
      "     |      than ``tol``.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - int, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For int/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Amount of verbosity.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation. Note that this is\n",
      "     |      used only if multiple values for l1_ratio are given.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The seed of the pseudo random number generator that selects a random\n",
      "     |      feature to update. Used when ``selection`` == 'random'.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      "     |      If set to 'random', a random coefficient is updated every iteration\n",
      "     |      rather than looping over features sequentially by default. This\n",
      "     |      (setting to 'random') often leads to significantly faster convergence\n",
      "     |      especially when tol is higher than 1e-4.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  intercept_ : ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_targets, n_features)\n",
      "     |      Parameter vector (W in the cost function formula).\n",
      "     |      Note that ``coef_`` stores the transpose of ``W``, ``W.T``.\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      The amount of penalization chosen by cross validation.\n",
      "     |\n",
      "     |  mse_path_ : ndarray of shape (n_alphas, n_folds)\n",
      "     |      Mean square error for the test set on each fold, varying alpha.\n",
      "     |\n",
      "     |  alphas_ : ndarray of shape (n_alphas,)\n",
      "     |      The grid of alphas used for fitting.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations run by the coordinate descent solver to reach\n",
      "     |      the specified tolerance for the optimal alpha.\n",
      "     |\n",
      "     |  dual_gap_ : float\n",
      "     |      The dual gap at the end of the optimization for the optimal alpha.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2\n",
      "     |      mixed-norm as regularizer.\n",
      "     |  ElasticNetCV : Elastic net model with best model selection by\n",
      "     |      cross-validation.\n",
      "     |  MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in\n",
      "     |      cross-validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The algorithm used to fit the model is coordinate descent.\n",
      "     |\n",
      "     |  In `fit`, once the best parameter `alpha` is found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  To avoid unnecessary memory duplication the `X` and `y` arguments of the\n",
      "     |  `fit` method should be directly passed as Fortran-contiguous numpy arrays.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import MultiTaskLassoCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> from sklearn.metrics import r2_score\n",
      "     |  >>> X, y = make_regression(n_targets=2, noise=4, random_state=0)\n",
      "     |  >>> reg = MultiTaskLassoCV(cv=5, random_state=0).fit(X, y)\n",
      "     |  >>> r2_score(y, reg.predict(X))\n",
      "     |  0.9994...\n",
      "     |  >>> reg.alpha_\n",
      "     |  0.5713...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([[153.7971...,  94.9015...]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MultiTaskLassoCV\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      LinearModelCV\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, random_state=None, selection='cyclic')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, **params)\n",
      "     |      Fit MultiTaskLasso model with coordinate descent.\n",
      "     |\n",
      "     |      Fit is on grid of alphas and best alpha estimated by cross-validation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Data.\n",
      "     |      y : ndarray of shape (n_samples, n_targets)\n",
      "     |          Target. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the CV splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of fitted model.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._coordinate_descent.MultiTaskLassoCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskLassoCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  path = lasso_path(X, y, *, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, **params)\n",
      "     |      Compute Lasso path with coordinate descent.\n",
      "     |\n",
      "     |      The Lasso optimization function varies for mono and multi-outputs.\n",
      "     |\n",
      "     |      For mono-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "     |\n",
      "     |      For multi-output tasks it is::\n",
      "     |\n",
      "     |          (1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21\n",
      "     |\n",
      "     |      Where::\n",
      "     |\n",
      "     |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "     |\n",
      "     |      i.e. the sum of norm of each row.\n",
      "     |\n",
      "     |      Read more in the :ref:`User Guide <lasso>`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "     |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "     |          can be sparse.\n",
      "     |\n",
      "     |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      eps : float, default=1e-3\n",
      "     |          Length of the path. ``eps=1e-3`` means that\n",
      "     |          ``alpha_min / alpha_max = 1e-3``.\n",
      "     |\n",
      "     |      n_alphas : int, default=100\n",
      "     |          Number of alphas along the regularization path.\n",
      "     |\n",
      "     |      alphas : array-like, default=None\n",
      "     |          List of alphas where to compute the models.\n",
      "     |          If ``None`` alphas are set automatically.\n",
      "     |\n",
      "     |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "     |          Whether to use a precomputed Gram matrix to speed up\n",
      "     |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "     |          matrix can also be passed as argument.\n",
      "     |\n",
      "     |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "     |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "     |          only when the Gram matrix is precomputed.\n",
      "     |\n",
      "     |      copy_X : bool, default=True\n",
      "     |          If ``True``, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |      coef_init : array-like of shape (n_features, ), default=None\n",
      "     |          The initial values of the coefficients.\n",
      "     |\n",
      "     |      verbose : bool or int, default=False\n",
      "     |          Amount of verbosity.\n",
      "     |\n",
      "     |      return_n_iter : bool, default=False\n",
      "     |          Whether to return the number of iterations or not.\n",
      "     |\n",
      "     |      positive : bool, default=False\n",
      "     |          If set to True, forces coefficients to be positive.\n",
      "     |          (Only allowed when ``y.ndim == 1``).\n",
      "     |\n",
      "     |      **params : kwargs\n",
      "     |          Keyword arguments passed to the coordinate descent solver.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      alphas : ndarray of shape (n_alphas,)\n",
      "     |          The alphas along the path where models are computed.\n",
      "     |\n",
      "     |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "     |          Coefficients along the path.\n",
      "     |\n",
      "     |      dual_gaps : ndarray of shape (n_alphas,)\n",
      "     |          The dual gaps at the end of the optimization for each alpha.\n",
      "     |\n",
      "     |      n_iters : list of int\n",
      "     |          The number of iterations taken by the coordinate descent optimizer to\n",
      "     |          reach the specified tolerance for each alpha.\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      lars_path : Compute Least Angle Regression or Lasso path using LARS\n",
      "     |          algorithm.\n",
      "     |      Lasso : The Lasso is a linear model that estimates sparse coefficients.\n",
      "     |      LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |      LassoCV : Lasso linear model with iterative fitting along a regularization\n",
      "     |          path.\n",
      "     |      LassoLarsCV : Cross-validated Lasso using the LARS algorithm.\n",
      "     |      sklearn.decomposition.sparse_encode : Estimator that can be used to\n",
      "     |          transform signals into sparse linear combination of atoms from a fixed.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For an example, see\n",
      "     |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "     |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "     |\n",
      "     |      To avoid unnecessary memory duplication the X argument of the fit method\n",
      "     |      should be directly passed as a Fortran-contiguous numpy array.\n",
      "     |\n",
      "     |      Note that in certain cases, the Lars solver may be significantly\n",
      "     |      faster to implement this functionality. In particular, linear\n",
      "     |      interpolation can be used to retrieve model coefficients between the\n",
      "     |      values output by lars_path\n",
      "     |\n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |\n",
      "     |      Comparing lasso_path and lars_path with interpolation:\n",
      "     |\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from sklearn.linear_model import lasso_path\n",
      "     |      >>> X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n",
      "     |      >>> y = np.array([1, 2, 3.1])\n",
      "     |      >>> # Use lasso_path to compute a coefficient path\n",
      "     |      >>> _, coef_path, _ = lasso_path(X, y, alphas=[5., 1., .5])\n",
      "     |      >>> print(coef_path)\n",
      "     |      [[0.         0.         0.46874778]\n",
      "     |       [0.2159048  0.4425765  0.23689075]]\n",
      "     |\n",
      "     |      >>> # Now use lars_path and 1D linear interpolation to compute the\n",
      "     |      >>> # same path\n",
      "     |      >>> from sklearn.linear_model import lars_path\n",
      "     |      >>> alphas, active, coef_path_lars = lars_path(X, y, method='lasso')\n",
      "     |      >>> from scipy import interpolate\n",
      "     |      >>> coef_path_continuous = interpolate.interp1d(alphas[::-1],\n",
      "     |      ...                                             coef_path_lars[:, ::-1])\n",
      "     |      >>> print(coef_path_continuous([5., 1., .5]))\n",
      "     |      [[0.         0.         0.46915237]\n",
      "     |       [0.2159048  0.4425765  0.23668876]]\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LinearModelCV:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._coordinate_descent.MultiTaskLassoCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.MultiTaskLassoCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class OrthogonalMatchingPursuit(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  OrthogonalMatchingPursuit(*, n_nonzero_coefs=None, tol=None, fit_intercept=True, precompute='auto')\n",
      "     |\n",
      "     |  Orthogonal Matching Pursuit model (OMP).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <omp>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_nonzero_coefs : int, default=None\n",
      "     |      Desired number of non-zero entries in the solution. Ignored if `tol` is set.\n",
      "     |      When `None` and `tol` is also `None`, this value is either set to 10% of\n",
      "     |      `n_features` or 1, whichever is greater.\n",
      "     |\n",
      "     |  tol : float, default=None\n",
      "     |      Maximum squared norm of the residual. If not None, overrides n_nonzero_coefs.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  precompute : 'auto' or bool, default='auto'\n",
      "     |      Whether to use a precomputed Gram and Xy matrix to speed up\n",
      "     |      calculations. Improves performance when :term:`n_targets` or\n",
      "     |      :term:`n_samples` is very large. Note that if you already have such\n",
      "     |      matrices, you can pass them directly to the fit method.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the formula).\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  n_iter_ : int or array-like\n",
      "     |      Number of active features across every target.\n",
      "     |\n",
      "     |  n_nonzero_coefs_ : int or None\n",
      "     |      The number of non-zero coefficients in the solution or `None` when `tol` is\n",
      "     |      set. If `n_nonzero_coefs` is None and `tol` is None this value is either set\n",
      "     |      to 10% of `n_features` or 1, whichever is greater.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  orthogonal_mp : Solves n_targets Orthogonal Matching Pursuit problems.\n",
      "     |  orthogonal_mp_gram :  Solves n_targets Orthogonal Matching Pursuit\n",
      "     |      problems using only the Gram matrix X.T * X and the product X.T * y.\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso path using LARS algorithm.\n",
      "     |  Lars : Least Angle Regression model a.k.a. LAR.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  sklearn.decomposition.sparse_encode : Generic sparse coding.\n",
      "     |      Each column of the result is the solution to a Lasso problem.\n",
      "     |  OrthogonalMatchingPursuitCV : Cross-validated\n",
      "     |      Orthogonal Matching Pursuit model (OMP).\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,\n",
      "     |  Matching pursuits with time-frequency dictionaries, IEEE Transactions on\n",
      "     |  Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.\n",
      "     |  (https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf)\n",
      "     |\n",
      "     |  This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,\n",
      "     |  M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal\n",
      "     |  Matching Pursuit Technical Report - CS Technion, April 2008.\n",
      "     |  https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import OrthogonalMatchingPursuit\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(noise=4, random_state=0)\n",
      "     |  >>> reg = OrthogonalMatchingPursuit().fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9991...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-78.3854...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      OrthogonalMatchingPursuit\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, n_nonzero_coefs=None, tol=None, fit_intercept=True, precompute='auto')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._omp.OrthogonalMatchingPursuit, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._omp.OrthogonalMatchingPursuit\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class OrthogonalMatchingPursuitCV(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  OrthogonalMatchingPursuitCV(*, copy=True, fit_intercept=True, max_iter=None, cv=None, n_jobs=None, verbose=False)\n",
      "     |\n",
      "     |  Cross-validated Orthogonal Matching Pursuit model (OMP).\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <omp>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  copy : bool, default=True\n",
      "     |      Whether the design matrix X must be copied by the algorithm. A false\n",
      "     |      value is only helpful if X is already Fortran-ordered, otherwise a\n",
      "     |      copy is made anyway.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  max_iter : int, default=None\n",
      "     |      Maximum numbers of iterations to perform, therefore maximum features\n",
      "     |      to include. 10% of ``n_features`` but at least 5 if available.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the default 5-fold cross-validation,\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For integer/None inputs, :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  verbose : bool or int, default=False\n",
      "     |      Sets the verbosity amount.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Parameter vector (w in the problem formulation).\n",
      "     |\n",
      "     |  n_nonzero_coefs_ : int\n",
      "     |      Estimated number of non-zero coefficients giving the best mean squared\n",
      "     |      error over the cross-validation folds.\n",
      "     |\n",
      "     |  n_iter_ : int or array-like\n",
      "     |      Number of active features across every target for the model refit with\n",
      "     |      the best hyperparameters got by cross-validating across all folds.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  orthogonal_mp : Solves n_targets Orthogonal Matching Pursuit problems.\n",
      "     |  orthogonal_mp_gram : Solves n_targets Orthogonal Matching Pursuit\n",
      "     |      problems using only the Gram matrix X.T * X and the product X.T * y.\n",
      "     |  lars_path : Compute Least Angle Regression or Lasso path using LARS algorithm.\n",
      "     |  Lars : Least Angle Regression model a.k.a. LAR.\n",
      "     |  LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "     |  OrthogonalMatchingPursuit : Orthogonal Matching Pursuit model (OMP).\n",
      "     |  LarsCV : Cross-validated Least Angle Regression model.\n",
      "     |  LassoLarsCV : Cross-validated Lasso model fit with Least Angle Regression.\n",
      "     |  sklearn.decomposition.sparse_encode : Generic sparse coding.\n",
      "     |      Each column of the result is the solution to a Lasso problem.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  In `fit`, once the optimal number of non-zero coefficients is found through\n",
      "     |  cross-validation, the model is fit again using the entire training set.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(n_features=100, n_informative=10,\n",
      "     |  ...                        noise=4, random_state=0)\n",
      "     |  >>> reg = OrthogonalMatchingPursuitCV(cv=5).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9991...\n",
      "     |  >>> reg.n_nonzero_coefs_\n",
      "     |  10\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-78.3854...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      OrthogonalMatchingPursuitCV\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, copy=True, fit_intercept=True, max_iter=None, cv=None, n_jobs=None, verbose=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, **fit_params)\n",
      "     |      Fit the model using X, y as training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Parameters to pass to the underlying splitter.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._omp.OrthogonalMatchingPursuitCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._omp.OrthogonalMatchingPursuitCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class PassiveAggressiveClassifier(sklearn.linear_model._stochastic_gradient.BaseSGDClassifier)\n",
      "     |  PassiveAggressiveClassifier(*, C=1.0, fit_intercept=True, max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss='hinge', n_jobs=None, random_state=None, warm_start=False, class_weight=None, average=False)\n",
      "     |\n",
      "     |  Passive Aggressive Classifier.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <passive_aggressive>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  C : float, default=1.0\n",
      "     |      Maximum step size (regularization). Defaults to 1.0.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If False, the\n",
      "     |      data is assumed to be already centered.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      :meth:`~sklearn.linear_model.PassiveAggressiveClassifier.partial_fit` method.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, the iterations will stop\n",
      "     |      when (loss > previous_loss - tol).\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  early_stopping : bool, default=False\n",
      "     |      Whether to use early stopping to terminate training when validation\n",
      "     |      score is not improving. If set to True, it will automatically set aside\n",
      "     |      a stratified fraction of training data as validation and terminate\n",
      "     |      training when validation score is not improving by at least `tol` for\n",
      "     |      `n_iter_no_change` consecutive epochs.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  validation_fraction : float, default=0.1\n",
      "     |      The proportion of training data to set aside as validation set for\n",
      "     |      early stopping. Must be between 0 and 1.\n",
      "     |      Only used if early_stopping is True.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  n_iter_no_change : int, default=5\n",
      "     |      Number of iterations with no improvement to wait before early stopping.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |\n",
      "     |  loss : str, default=\"hinge\"\n",
      "     |      The loss function to be used:\n",
      "     |      hinge: equivalent to PA-I in the reference paper.\n",
      "     |      squared_hinge: equivalent to PA-II in the reference paper.\n",
      "     |\n",
      "     |  n_jobs : int or None, default=None\n",
      "     |      The number of CPUs to use to do the OVA (One Versus All, for\n",
      "     |      multi-class problems) computation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used to shuffle the training data, when ``shuffle`` is set to\n",
      "     |      ``True``. Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      Repeatedly calling fit or partial_fit when warm_start is True can\n",
      "     |      result in a different solution than when calling fit a single time\n",
      "     |      because of the way the data is shuffled.\n",
      "     |\n",
      "     |  class_weight : dict, {class_label: weight} or \"balanced\" or None,             default=None\n",
      "     |      Preset for the class_weight fit parameter.\n",
      "     |\n",
      "     |      Weights associated with classes. If not given, all classes\n",
      "     |      are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         parameter *class_weight* to automatically weight samples.\n",
      "     |\n",
      "     |  average : bool or int, default=False\n",
      "     |      When set to True, computes the averaged SGD weights and stores the\n",
      "     |      result in the ``coef_`` attribute. If set to an int greater than 1,\n",
      "     |      averaging will begin once the total number of samples seen reaches\n",
      "     |      average. So average=10 will begin averaging after seeing 10 samples.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         parameter *average* to use weights averaging in SGD.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n",
      "     |      Constants in decision function.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |      For multiclass fits, it is the maximum over every binary fit.\n",
      "     |\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      The unique classes labels.\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  loss_function_ : callable\n",
      "     |      Loss function used by the algorithm.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  SGDClassifier : Incrementally trained logistic regression.\n",
      "     |  Perceptron : Linear perceptron classifier.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Online Passive-Aggressive Algorithms\n",
      "     |  <http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf>\n",
      "     |  K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "     |  >>> from sklearn.datasets import make_classification\n",
      "     |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      "     |  >>> clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0,\n",
      "     |  ... tol=1e-3)\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  PassiveAggressiveClassifier(random_state=0)\n",
      "     |  >>> print(clf.coef_)\n",
      "     |  [[0.26642044 0.45070924 0.67251877 0.64185414]]\n",
      "     |  >>> print(clf.intercept_)\n",
      "     |  [1.84127814]\n",
      "     |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "     |  [1]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PassiveAggressiveClassifier\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGDClassifier\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, C=1.0, fit_intercept=True, max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss='hinge', n_jobs=None, random_state=None, warm_start=False, class_weight=None, average=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, coef_init=None, intercept_init=None)\n",
      "     |      Fit linear model with Passive Aggressive algorithm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      coef_init : ndarray of shape (n_classes, n_features)\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      intercept_init : ndarray of shape (n_classes,)\n",
      "     |          The initial intercept to warm-start the optimization.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  partial_fit(self, X, y, classes=None)\n",
      "     |      Fit linear model with Passive Aggressive algorithm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Subset of the training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Subset of the target values.\n",
      "     |\n",
      "     |      classes : ndarray of shape (n_classes,)\n",
      "     |          Classes across all calls to partial_fit.\n",
      "     |          Can be obtained by via `np.unique(y_all)`, where y_all is the\n",
      "     |          target vector of the entire dataset.\n",
      "     |          This argument is required for the first call to partial_fit\n",
      "     |          and can be omitted in the subsequent calls.\n",
      "     |          Note that y doesn't need to contain all labels in `classes`.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', intercept_init: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      intercept_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``intercept_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from sklearn.linear_model._stochastic_gradient.BaseSGDClassifier:\n",
      "     |\n",
      "     |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the predictions.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,)\n",
      "     |          Vector containing the class labels for each sample.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sklearn.linear_model._stochastic_gradient.BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class PassiveAggressiveRegressor(sklearn.linear_model._stochastic_gradient.BaseSGDRegressor)\n",
      "     |  PassiveAggressiveRegressor(*, C=1.0, fit_intercept=True, max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss='epsilon_insensitive', epsilon=0.1, random_state=None, warm_start=False, average=False)\n",
      "     |\n",
      "     |  Passive Aggressive Regressor.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <passive_aggressive>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |\n",
      "     |  C : float, default=1.0\n",
      "     |      Maximum step size (regularization). Defaults to 1.0.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If False, the\n",
      "     |      data is assumed to be already centered. Defaults to True.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      :meth:`~sklearn.linear_model.PassiveAggressiveRegressor.partial_fit` method.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, the iterations will stop\n",
      "     |      when (loss > previous_loss - tol).\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  early_stopping : bool, default=False\n",
      "     |      Whether to use early stopping to terminate training when validation.\n",
      "     |      score is not improving. If set to True, it will automatically set aside\n",
      "     |      a fraction of training data as validation and terminate\n",
      "     |      training when validation score is not improving by at least tol for\n",
      "     |      n_iter_no_change consecutive epochs.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  validation_fraction : float, default=0.1\n",
      "     |      The proportion of training data to set aside as validation set for\n",
      "     |      early stopping. Must be between 0 and 1.\n",
      "     |      Only used if early_stopping is True.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  n_iter_no_change : int, default=5\n",
      "     |      Number of iterations with no improvement to wait before early stopping.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |\n",
      "     |  loss : str, default=\"epsilon_insensitive\"\n",
      "     |      The loss function to be used:\n",
      "     |      epsilon_insensitive: equivalent to PA-I in the reference paper.\n",
      "     |      squared_epsilon_insensitive: equivalent to PA-II in the reference\n",
      "     |      paper.\n",
      "     |\n",
      "     |  epsilon : float, default=0.1\n",
      "     |      If the difference between the current prediction and the correct label\n",
      "     |      is below this threshold, the model is not updated.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used to shuffle the training data, when ``shuffle`` is set to\n",
      "     |      ``True``. Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      Repeatedly calling fit or partial_fit when warm_start is True can\n",
      "     |      result in a different solution than when calling fit a single time\n",
      "     |      because of the way the data is shuffled.\n",
      "     |\n",
      "     |  average : bool or int, default=False\n",
      "     |      When set to True, computes the averaged SGD weights and stores the\n",
      "     |      result in the ``coef_`` attribute. If set to an int greater than 1,\n",
      "     |      averaging will begin once the total number of samples seen reaches\n",
      "     |      average. So average=10 will begin averaging after seeing 10 samples.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         parameter *average* to use weights averaging in SGD.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array, shape = [1, n_features] if n_classes == 2 else [n_classes,            n_features]\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]\n",
      "     |      Constants in decision function.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  SGDRegressor : Linear model fitted by minimizing a regularized\n",
      "     |      empirical loss with SGD.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Online Passive-Aggressive Algorithms\n",
      "     |  <http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf>\n",
      "     |  K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006).\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import PassiveAggressiveRegressor\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |\n",
      "     |  >>> X, y = make_regression(n_features=4, random_state=0)\n",
      "     |  >>> regr = PassiveAggressiveRegressor(max_iter=100, random_state=0,\n",
      "     |  ... tol=1e-3)\n",
      "     |  >>> regr.fit(X, y)\n",
      "     |  PassiveAggressiveRegressor(max_iter=100, random_state=0)\n",
      "     |  >>> print(regr.coef_)\n",
      "     |  [20.48736655 34.18818427 67.59122734 87.94731329]\n",
      "     |  >>> print(regr.intercept_)\n",
      "     |  [-0.02306214]\n",
      "     |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      "     |  [-0.02306214]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PassiveAggressiveRegressor\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGDRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, C=1.0, fit_intercept=True, max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss='epsilon_insensitive', epsilon=0.1, random_state=None, warm_start=False, average=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, coef_init=None, intercept_init=None)\n",
      "     |      Fit linear model with Passive Aggressive algorithm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : numpy array of shape [n_samples]\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      coef_init : array, shape = [n_features]\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      intercept_init : array, shape = [1]\n",
      "     |          The initial intercept to warm-start the optimization.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  partial_fit(self, X, y)\n",
      "     |      Fit linear model with Passive Aggressive algorithm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Subset of training data.\n",
      "     |\n",
      "     |      y : numpy array of shape [n_samples]\n",
      "     |          Subset of target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', intercept_init: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      intercept_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``intercept_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._stochastic_gradient.BaseSGDRegressor:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Input data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray of shape (n_samples,)\n",
      "     |         Predicted target values per element in X.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from sklearn.linear_model._stochastic_gradient.BaseSGDRegressor:\n",
      "     |\n",
      "     |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sklearn.linear_model._stochastic_gradient.BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Perceptron(sklearn.linear_model._stochastic_gradient.BaseSGDClassifier)\n",
      "     |  Perceptron(*, penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)\n",
      "     |\n",
      "     |  Linear perceptron classifier.\n",
      "     |\n",
      "     |  The implementation is a wrapper around :class:`~sklearn.linear_model.SGDClassifier`\n",
      "     |  by fixing the `loss` and `learning_rate` parameters as::\n",
      "     |\n",
      "     |      SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\")\n",
      "     |\n",
      "     |  Other available parameters are described below and are forwarded to\n",
      "     |  :class:`~sklearn.linear_model.SGDClassifier`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <perceptron>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |\n",
      "     |  penalty : {'l2','l1','elasticnet'}, default=None\n",
      "     |      The penalty (aka regularization term) to be used.\n",
      "     |\n",
      "     |  alpha : float, default=0.0001\n",
      "     |      Constant that multiplies the regularization term if regularization is\n",
      "     |      used.\n",
      "     |\n",
      "     |  l1_ratio : float, default=0.15\n",
      "     |      The Elastic Net mixing parameter, with `0 <= l1_ratio <= 1`.\n",
      "     |      `l1_ratio=0` corresponds to L2 penalty, `l1_ratio=1` to L1.\n",
      "     |      Only used if `penalty='elasticnet'`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If False, the\n",
      "     |      data is assumed to be already centered.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      :meth:`partial_fit` method.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, the iterations will stop\n",
      "     |      when (loss > previous_loss - tol).\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |\n",
      "     |  eta0 : float, default=1\n",
      "     |      Constant by which the updates are multiplied.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      The number of CPUs to use to do the OVA (One Versus All, for\n",
      "     |      multi-class problems) computation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=0\n",
      "     |      Used to shuffle the training data, when ``shuffle`` is set to\n",
      "     |      ``True``. Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  early_stopping : bool, default=False\n",
      "     |      Whether to use early stopping to terminate training when validation\n",
      "     |      score is not improving. If set to True, it will automatically set aside\n",
      "     |      a stratified fraction of training data as validation and terminate\n",
      "     |      training when validation score is not improving by at least `tol` for\n",
      "     |      `n_iter_no_change` consecutive epochs.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  validation_fraction : float, default=0.1\n",
      "     |      The proportion of training data to set aside as validation set for\n",
      "     |      early stopping. Must be between 0 and 1.\n",
      "     |      Only used if early_stopping is True.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  n_iter_no_change : int, default=5\n",
      "     |      Number of iterations with no improvement to wait before early stopping.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  class_weight : dict, {class_label: weight} or \"balanced\", default=None\n",
      "     |      Preset for the class_weight fit parameter.\n",
      "     |\n",
      "     |      Weights associated with classes. If not given, all classes\n",
      "     |      are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution. See\n",
      "     |      :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      The unique classes labels.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n",
      "     |      Constants in decision function.\n",
      "     |\n",
      "     |  loss_function_ : concrete LossFunction\n",
      "     |      The function that determines the loss, or difference between the\n",
      "     |      output of the algorithm and the target values.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |      For multiclass fits, it is the maximum over every binary fit.\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  sklearn.linear_model.SGDClassifier : Linear classifiers\n",
      "     |      (SVM, logistic regression, etc.) with SGD training.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  ``Perceptron`` is a classification algorithm which shares the same\n",
      "     |  underlying implementation with ``SGDClassifier``. In fact,\n",
      "     |  ``Perceptron()`` is equivalent to `SGDClassifier(loss=\"perceptron\",\n",
      "     |  eta0=1, learning_rate=\"constant\", penalty=None)`.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  https://en.wikipedia.org/wiki/Perceptron and references therein.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_digits\n",
      "     |  >>> from sklearn.linear_model import Perceptron\n",
      "     |  >>> X, y = load_digits(return_X_y=True)\n",
      "     |  >>> clf = Perceptron(tol=1e-3, random_state=0)\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  Perceptron()\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.939...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Perceptron\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGDClassifier\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.linear_model._stochastic_gradient.BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._perceptron.Perceptron, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', intercept_init: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._perceptron.Perceptron\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      intercept_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``intercept_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._perceptron.Perceptron, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._perceptron.Perceptron\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._perceptron.Perceptron, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._perceptron.Perceptron\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._stochastic_gradient.BaseSGDClassifier:\n",
      "     |\n",
      "     |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None)\n",
      "     |      Fit linear model with Stochastic Gradient Descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      coef_init : ndarray of shape (n_classes, n_features), default=None\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      intercept_init : ndarray of shape (n_classes,), default=None\n",
      "     |          The initial intercept to warm-start the optimization.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed. These weights will\n",
      "     |          be multiplied with class_weight (passed through the\n",
      "     |          constructor) if class_weight is specified.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Perform one epoch of stochastic gradient descent on given samples.\n",
      "     |\n",
      "     |      Internally, this method uses ``max_iter = 1``. Therefore, it is not\n",
      "     |      guaranteed that a minimum of the cost function is reached after calling\n",
      "     |      it once. Matters such as objective convergence, early stopping, and\n",
      "     |      learning rate adjustments should be handled by the user.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Subset of the training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Subset of the target values.\n",
      "     |\n",
      "     |      classes : ndarray of shape (n_classes,), default=None\n",
      "     |          Classes across all calls to partial_fit.\n",
      "     |          Can be obtained by via `np.unique(y_all)`, where y_all is the\n",
      "     |          target vector of the entire dataset.\n",
      "     |          This argument is required for the first call to partial_fit\n",
      "     |          and can be omitted in the subsequent calls.\n",
      "     |          Note that y doesn't need to contain all labels in `classes`.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from sklearn.linear_model._stochastic_gradient.BaseSGDClassifier:\n",
      "     |\n",
      "     |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the predictions.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,)\n",
      "     |          Vector containing the class labels for each sample.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sklearn.linear_model._stochastic_gradient.BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class PoissonRegressor(_GeneralizedLinearRegressor)\n",
      "     |  PoissonRegressor(*, alpha=1.0, fit_intercept=True, solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |\n",
      "     |  Generalized Linear Model with a Poisson distribution.\n",
      "     |\n",
      "     |  This regressor uses the 'log' link function.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <Generalized_linear_models>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.23\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1\n",
      "     |      Constant that multiplies the L2 penalty term and determines the\n",
      "     |      regularization strength. ``alpha = 0`` is equivalent to unpenalized\n",
      "     |      GLMs. In this case, the design matrix `X` must have full column rank\n",
      "     |      (no collinearities).\n",
      "     |      Values of `alpha` must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "     |      added to the linear predictor (`X @ coef + intercept`).\n",
      "     |\n",
      "     |  solver : {'lbfgs', 'newton-cholesky'}, default='lbfgs'\n",
      "     |      Algorithm to use in the optimization problem:\n",
      "     |\n",
      "     |      'lbfgs'\n",
      "     |          Calls scipy's L-BFGS-B optimizer.\n",
      "     |\n",
      "     |      'newton-cholesky'\n",
      "     |          Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to\n",
      "     |          iterated reweighted least squares) with an inner Cholesky based solver.\n",
      "     |          This solver is a good choice for `n_samples` >> `n_features`, especially\n",
      "     |          with one-hot encoded categorical features with rare categories. Be aware\n",
      "     |          that the memory usage of this solver has a quadratic dependency on\n",
      "     |          `n_features` because it explicitly computes the Hessian matrix.\n",
      "     |\n",
      "     |          .. versionadded:: 1.2\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      The maximal number of iterations for the solver.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      Stopping criterion. For the lbfgs solver,\n",
      "     |      the iteration will stop when ``max{|g_j|, j = 1, ..., d} <= tol``\n",
      "     |      where ``g_j`` is the j-th component of the gradient (derivative) of\n",
      "     |      the objective function.\n",
      "     |      Values must be in the range `(0.0, inf)`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      If set to ``True``, reuse the solution of the previous call to ``fit``\n",
      "     |      as initialization for ``coef_`` and ``intercept_`` .\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      For the lbfgs solver set verbose to any positive number for verbosity.\n",
      "     |      Values must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array of shape (n_features,)\n",
      "     |      Estimated coefficients for the linear predictor (`X @ coef_ +\n",
      "     |      intercept_`) in the GLM.\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Intercept (a.k.a. bias) added to linear predictor.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Actual number of iterations used in the solver.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  TweedieRegressor : Generalized Linear Model with a Tweedie distribution.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.PoissonRegressor()\n",
      "     |  >>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]\n",
      "     |  >>> y = [12, 17, 22, 21]\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  PoissonRegressor()\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.990...\n",
      "     |  >>> clf.coef_\n",
      "     |  array([0.121..., 0.158...])\n",
      "     |  >>> clf.intercept_\n",
      "     |  2.088...\n",
      "     |  >>> clf.predict([[1, 1], [3, 4]])\n",
      "     |  array([10.676..., 21.875...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PoissonRegressor\n",
      "     |      _GeneralizedLinearRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, alpha=1.0, fit_intercept=True, solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._glm.glm.PoissonRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.PoissonRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._glm.glm.PoissonRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.PoissonRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _GeneralizedLinearRegressor:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit a Generalized Linear Model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted model.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using GLM with feature matrix X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array of shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Compute D^2, the percentage of deviance explained.\n",
      "     |\n",
      "     |      D^2 is a generalization of the coefficient of determination R^2.\n",
      "     |      R^2 uses squared error and D^2 uses the deviance of this GLM, see the\n",
      "     |      :ref:`User Guide <regression_metrics>`.\n",
      "     |\n",
      "     |      D^2 is defined as\n",
      "     |      :math:`D^2 = 1-\\frac{D(y_{true},y_{pred})}{D_{null}}`,\n",
      "     |      :math:`D_{null}` is the null deviance, i.e. the deviance of a model\n",
      "     |      with intercept alone, which corresponds to :math:`y_{pred} = \\bar{y}`.\n",
      "     |      The mean :math:`\\bar{y}` is averaged by sample_weight.\n",
      "     |      Best possible score is 1.0 and it can be negative (because the model\n",
      "     |      can be arbitrarily worse).\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          True values of target.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          D^2 of self.predict(X) w.r.t. y.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class QuantileRegressor(sklearn.linear_model._base.LinearModel, sklearn.base.RegressorMixin, sklearn.base.BaseEstimator)\n",
      "     |  QuantileRegressor(*, quantile=0.5, alpha=1.0, fit_intercept=True, solver='highs', solver_options=None)\n",
      "     |\n",
      "     |  Linear regression model that predicts conditional quantiles.\n",
      "     |\n",
      "     |  The linear :class:`QuantileRegressor` optimizes the pinball loss for a\n",
      "     |  desired `quantile` and is robust to outliers.\n",
      "     |\n",
      "     |  This model uses an L1 regularization like\n",
      "     |  :class:`~sklearn.linear_model.Lasso`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <quantile_regression>`.\n",
      "     |\n",
      "     |  .. versionadded:: 1.0\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  quantile : float, default=0.5\n",
      "     |      The quantile that the model tries to predict. It must be strictly\n",
      "     |      between 0 and 1. If 0.5 (default), the model predicts the 50%\n",
      "     |      quantile, i.e. the median.\n",
      "     |\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Regularization constant that multiplies the L1 penalty term.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether or not to fit the intercept.\n",
      "     |\n",
      "     |  solver : {'highs-ds', 'highs-ipm', 'highs', 'interior-point',             'revised simplex'}, default='highs'\n",
      "     |      Method used by :func:`scipy.optimize.linprog` to solve the linear\n",
      "     |      programming formulation.\n",
      "     |\n",
      "     |      From `scipy>=1.6.0`, it is recommended to use the highs methods because\n",
      "     |      they are the fastest ones. Solvers \"highs-ds\", \"highs-ipm\" and \"highs\"\n",
      "     |      support sparse input data and, in fact, always convert to sparse csc.\n",
      "     |\n",
      "     |      From `scipy>=1.11.0`, \"interior-point\" is not available anymore.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         The default of `solver` changed to `\"highs\"` in version 1.4.\n",
      "     |\n",
      "     |  solver_options : dict, default=None\n",
      "     |      Additional parameters passed to :func:`scipy.optimize.linprog` as\n",
      "     |      options. If `None` and if `solver='interior-point'`, then\n",
      "     |      `{\"lstsq\": True}` is passed to :func:`scipy.optimize.linprog` for the\n",
      "     |      sake of stability.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array of shape (n_features,)\n",
      "     |      Estimated coefficients for the features.\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      The intercept of the model, aka bias term.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations performed by the solver.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Lasso : The Lasso is a linear model that estimates sparse coefficients\n",
      "     |      with l1 regularization.\n",
      "     |  HuberRegressor : Linear regression model that is robust to outliers.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import QuantileRegressor\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> n_samples, n_features = 10, 2\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> y = rng.randn(n_samples)\n",
      "     |  >>> X = rng.randn(n_samples, n_features)\n",
      "     |  >>> # the two following lines are optional in practice\n",
      "     |  >>> from sklearn.utils.fixes import sp_version, parse_version\n",
      "     |  >>> solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
      "     |  >>> reg = QuantileRegressor(quantile=0.8, solver=solver).fit(X, y)\n",
      "     |  >>> np.mean(y <= reg.predict(X))\n",
      "     |  0.8\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      QuantileRegressor\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, quantile=0.5, alpha=1.0, fit_intercept=True, solver='highs', solver_options=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit the model according to the given training data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._quantile.QuantileRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._quantile.QuantileRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._quantile.QuantileRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._quantile.QuantileRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class RANSACRegressor(sklearn.base.MetaEstimatorMixin, sklearn.base.RegressorMixin, sklearn.base.MultiOutputMixin, sklearn.base.BaseEstimator)\n",
      "     |  RANSACRegressor(estimator=None, *, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss='absolute_error', random_state=None)\n",
      "     |\n",
      "     |  RANSAC (RANdom SAmple Consensus) algorithm.\n",
      "     |\n",
      "     |  RANSAC is an iterative algorithm for the robust estimation of parameters\n",
      "     |  from a subset of inliers from the complete data set.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <ransac_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : object, default=None\n",
      "     |      Base estimator object which implements the following methods:\n",
      "     |\n",
      "     |       * `fit(X, y)`: Fit model to given training data and target values.\n",
      "     |       * `score(X, y)`: Returns the mean accuracy on the given test data,\n",
      "     |         which is used for the stop criterion defined by `stop_score`.\n",
      "     |         Additionally, the score is used to decide which of two equally\n",
      "     |         large consensus sets is chosen as the better one.\n",
      "     |       * `predict(X)`: Returns predicted values using the linear model,\n",
      "     |         which is used to compute residual error using loss function.\n",
      "     |\n",
      "     |      If `estimator` is None, then\n",
      "     |      :class:`~sklearn.linear_model.LinearRegression` is used for\n",
      "     |      target values of dtype float.\n",
      "     |\n",
      "     |      Note that the current implementation only supports regression\n",
      "     |      estimators.\n",
      "     |\n",
      "     |  min_samples : int (>= 1) or float ([0, 1]), default=None\n",
      "     |      Minimum number of samples chosen randomly from original data. Treated\n",
      "     |      as an absolute number of samples for `min_samples >= 1`, treated as a\n",
      "     |      relative number `ceil(min_samples * X.shape[0])` for\n",
      "     |      `min_samples < 1`. This is typically chosen as the minimal number of\n",
      "     |      samples necessary to estimate the given `estimator`. By default a\n",
      "     |      :class:`~sklearn.linear_model.LinearRegression` estimator is assumed and\n",
      "     |      `min_samples` is chosen as ``X.shape[1] + 1``. This parameter is highly\n",
      "     |      dependent upon the model, so if a `estimator` other than\n",
      "     |      :class:`~sklearn.linear_model.LinearRegression` is used, the user must\n",
      "     |      provide a value.\n",
      "     |\n",
      "     |  residual_threshold : float, default=None\n",
      "     |      Maximum residual for a data sample to be classified as an inlier.\n",
      "     |      By default the threshold is chosen as the MAD (median absolute\n",
      "     |      deviation) of the target values `y`. Points whose residuals are\n",
      "     |      strictly equal to the threshold are considered as inliers.\n",
      "     |\n",
      "     |  is_data_valid : callable, default=None\n",
      "     |      This function is called with the randomly selected data before the\n",
      "     |      model is fitted to it: `is_data_valid(X, y)`. If its return value is\n",
      "     |      False the current randomly chosen sub-sample is skipped.\n",
      "     |\n",
      "     |  is_model_valid : callable, default=None\n",
      "     |      This function is called with the estimated model and the randomly\n",
      "     |      selected data: `is_model_valid(model, X, y)`. If its return value is\n",
      "     |      False the current randomly chosen sub-sample is skipped.\n",
      "     |      Rejecting samples with this function is computationally costlier than\n",
      "     |      with `is_data_valid`. `is_model_valid` should therefore only be used if\n",
      "     |      the estimated model is needed for making the rejection decision.\n",
      "     |\n",
      "     |  max_trials : int, default=100\n",
      "     |      Maximum number of iterations for random sample selection.\n",
      "     |\n",
      "     |  max_skips : int, default=np.inf\n",
      "     |      Maximum number of iterations that can be skipped due to finding zero\n",
      "     |      inliers or invalid data defined by ``is_data_valid`` or invalid models\n",
      "     |      defined by ``is_model_valid``.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  stop_n_inliers : int, default=np.inf\n",
      "     |      Stop iteration if at least this number of inliers are found.\n",
      "     |\n",
      "     |  stop_score : float, default=np.inf\n",
      "     |      Stop iteration if score is greater equal than this threshold.\n",
      "     |\n",
      "     |  stop_probability : float in range [0, 1], default=0.99\n",
      "     |      RANSAC iteration stops if at least one outlier-free set of the training\n",
      "     |      data is sampled in RANSAC. This requires to generate at least N\n",
      "     |      samples (iterations)::\n",
      "     |\n",
      "     |          N >= log(1 - probability) / log(1 - e**m)\n",
      "     |\n",
      "     |      where the probability (confidence) is typically set to high value such\n",
      "     |      as 0.99 (the default) and e is the current fraction of inliers w.r.t.\n",
      "     |      the total number of samples.\n",
      "     |\n",
      "     |  loss : str, callable, default='absolute_error'\n",
      "     |      String inputs, 'absolute_error' and 'squared_error' are supported which\n",
      "     |      find the absolute error and squared error per sample respectively.\n",
      "     |\n",
      "     |      If ``loss`` is a callable, then it should be a function that takes\n",
      "     |      two arrays as inputs, the true and predicted value and returns a 1-D\n",
      "     |      array with the i-th value of the array corresponding to the loss\n",
      "     |      on ``X[i]``.\n",
      "     |\n",
      "     |      If the loss on a sample is greater than the ``residual_threshold``,\n",
      "     |      then this sample is classified as an outlier.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      The generator used to initialize the centers.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  estimator_ : object\n",
      "     |      Best fitted model (copy of the `estimator` object).\n",
      "     |\n",
      "     |  n_trials_ : int\n",
      "     |      Number of random selection trials until one of the stop criteria is\n",
      "     |      met. It is always ``<= max_trials``.\n",
      "     |\n",
      "     |  inlier_mask_ : bool array of shape [n_samples]\n",
      "     |      Boolean mask of inliers classified as ``True``.\n",
      "     |\n",
      "     |  n_skips_no_inliers_ : int\n",
      "     |      Number of iterations skipped due to finding zero inliers.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  n_skips_invalid_data_ : int\n",
      "     |      Number of iterations skipped due to invalid data defined by\n",
      "     |      ``is_data_valid``.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  n_skips_invalid_model_ : int\n",
      "     |      Number of iterations skipped due to an invalid model defined by\n",
      "     |      ``is_model_valid``.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  HuberRegressor : Linear regression model that is robust to outliers.\n",
      "     |  TheilSenRegressor : Theil-Sen Estimator robust multivariate regression model.\n",
      "     |  SGDRegressor : Fitted by minimizing a regularized empirical loss with SGD.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] https://en.wikipedia.org/wiki/RANSAC\n",
      "     |  .. [2] https://www.sri.com/wp-content/uploads/2021/12/ransac-publication.pdf\n",
      "     |  .. [3] http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.pdf\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import RANSACRegressor\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(\n",
      "     |  ...     n_samples=200, n_features=2, noise=4.0, random_state=0)\n",
      "     |  >>> reg = RANSACRegressor(random_state=0).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9885...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-31.9417...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RANSACRegressor\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, estimator=None, *, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss='absolute_error', random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, *, sample_weight=None, **fit_params)\n",
      "     |      Fit estimator using RANSAC algorithm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample\n",
      "     |          raises error if sample_weight is passed and estimator\n",
      "     |          fit method does not support it.\n",
      "     |\n",
      "     |          .. versionadded:: 0.18\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Parameters routed to the `fit` method of the sub-estimator via the\n",
      "     |          metadata routing API.\n",
      "     |\n",
      "     |          .. versionadded:: 1.5\n",
      "     |\n",
      "     |              Only available if\n",
      "     |              `sklearn.set_config(enable_metadata_routing=True)` is set. See\n",
      "     |              :ref:`Metadata Routing User Guide <metadata_routing>` for more\n",
      "     |              details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted `RANSACRegressor` estimator.\n",
      "     |\n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If no valid consensus set could be found. This occurs if\n",
      "     |          `is_data_valid` and `is_model_valid` return False for all\n",
      "     |          `max_trials` randomly chosen sub-samples.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  predict(self, X, **params)\n",
      "     |      Predict using the estimated model.\n",
      "     |\n",
      "     |      This is a wrapper for `estimator_.predict(X)`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like or sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input data.\n",
      "     |\n",
      "     |      **params : dict\n",
      "     |          Parameters routed to the `predict` method of the sub-estimator via\n",
      "     |          the metadata routing API.\n",
      "     |\n",
      "     |          .. versionadded:: 1.5\n",
      "     |\n",
      "     |              Only available if\n",
      "     |              `sklearn.set_config(enable_metadata_routing=True)` is set. See\n",
      "     |              :ref:`Metadata Routing User Guide <metadata_routing>` for more\n",
      "     |              details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : array, shape = [n_samples] or [n_samples, n_targets]\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  score(self, X, y, **params)\n",
      "     |      Return the score of the prediction.\n",
      "     |\n",
      "     |      This is a wrapper for `estimator_.score(X, y)`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : (array-like or sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      **params : dict\n",
      "     |          Parameters routed to the `score` method of the sub-estimator via\n",
      "     |          the metadata routing API.\n",
      "     |\n",
      "     |          .. versionadded:: 1.5\n",
      "     |\n",
      "     |              Only available if\n",
      "     |              `sklearn.set_config(enable_metadata_routing=True)` is set. See\n",
      "     |              :ref:`Metadata Routing User Guide <metadata_routing>` for more\n",
      "     |              details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      z : float\n",
      "     |          Score of the prediction.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._ransac.RANSACRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ransac.RANSACRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class Ridge(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, _BaseRidge)\n",
      "     |  Ridge(alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, solver='auto', positive=False, random_state=None)\n",
      "     |\n",
      "     |  Linear least squares with l2 regularization.\n",
      "     |\n",
      "     |  Minimizes the objective function::\n",
      "     |\n",
      "     |  ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      "     |\n",
      "     |  This model solves a regression model where the loss function is\n",
      "     |  the linear least squares function and regularization is given by\n",
      "     |  the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      "     |  This estimator has built-in support for multi-variate regression\n",
      "     |  (i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      "     |      Constant that multiplies the L2 term, controlling regularization\n",
      "     |      strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.\n",
      "     |\n",
      "     |      When `alpha = 0`, the objective is equivalent to ordinary least\n",
      "     |      squares, solved by the :class:`LinearRegression` object. For numerical\n",
      "     |      reasons, using `alpha = 0` with the `Ridge` object is not advised.\n",
      "     |      Instead, you should use the :class:`LinearRegression` object.\n",
      "     |\n",
      "     |      If an array is passed, penalties are assumed to be specific to the\n",
      "     |      targets. Hence they must correspond in number.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to fit the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. ``X`` and ``y`` are expected to be centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_iter : int, default=None\n",
      "     |      Maximum number of iterations for conjugate gradient solver.\n",
      "     |      For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      "     |      by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      "     |      For 'lbfgs' solver, the default value is 15000.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The precision of the solution (`coef_`) is determined by `tol` which\n",
      "     |      specifies a different convergence criterion for each solver:\n",
      "     |\n",
      "     |      - 'svd': `tol` has no impact.\n",
      "     |\n",
      "     |      - 'cholesky': `tol` has no impact.\n",
      "     |\n",
      "     |      - 'sparse_cg': norm of residuals smaller than `tol`.\n",
      "     |\n",
      "     |      - 'lsqr': `tol` is set as atol and btol of scipy.sparse.linalg.lsqr,\n",
      "     |        which control the norm of the residual vector in terms of the norms of\n",
      "     |        matrix and coefficients.\n",
      "     |\n",
      "     |      - 'sag' and 'saga': relative change of coef smaller than `tol`.\n",
      "     |\n",
      "     |      - 'lbfgs': maximum of the absolute (projected) gradient=max|residuals|\n",
      "     |        smaller than `tol`.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.2\n",
      "     |         Default value changed from 1e-3 to 1e-4 for consistency with other linear\n",
      "     |         models.\n",
      "     |\n",
      "     |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      "     |      Solver to use in the computational routines:\n",
      "     |\n",
      "     |      - 'auto' chooses the solver automatically based on the type of data.\n",
      "     |\n",
      "     |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "     |        coefficients. It is the most stable solver, in particular more stable\n",
      "     |        for singular matrices than 'cholesky' at the cost of being slower.\n",
      "     |\n",
      "     |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "     |        obtain a closed-form solution.\n",
      "     |\n",
      "     |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "     |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "     |        more appropriate than 'cholesky' for large-scale data\n",
      "     |        (possibility to set `tol` and `max_iter`).\n",
      "     |\n",
      "     |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "     |        scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "     |        procedure.\n",
      "     |\n",
      "     |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "     |        its improved, unbiased version named SAGA. Both methods also use an\n",
      "     |        iterative procedure, and are often faster than other solvers when\n",
      "     |        both n_samples and n_features are large. Note that 'sag' and\n",
      "     |        'saga' fast convergence is only guaranteed on features with\n",
      "     |        approximately the same scale. You can preprocess the data with a\n",
      "     |        scaler from sklearn.preprocessing.\n",
      "     |\n",
      "     |      - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      "     |        `scipy.optimize.minimize`. It can be used only when `positive`\n",
      "     |        is True.\n",
      "     |\n",
      "     |      All solvers except 'svd' support both dense and sparse data. However, only\n",
      "     |      'lsqr', 'sag', 'sparse_cg', and 'lbfgs' support sparse input when\n",
      "     |      `fit_intercept` is True.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         Stochastic Average Gradient descent solver.\n",
      "     |      .. versionadded:: 0.19\n",
      "     |         SAGA solver.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive.\n",
      "     |      Only 'lbfgs' solver is supported in this case.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "     |      See :term:`Glossary <random_state>` for details.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         `random_state` to support Stochastic Average Gradient.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "     |      Weight vector(s).\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      ``fit_intercept = False``.\n",
      "     |\n",
      "     |  n_iter_ : None or ndarray of shape (n_targets,)\n",
      "     |      Actual number of iterations for each target. Available only for\n",
      "     |      sag and lsqr solvers. Other solvers will return None.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  solver_ : str\n",
      "     |      The solver that was used at fit time by the computational\n",
      "     |      routines.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  RidgeClassifier : Ridge classifier.\n",
      "     |  RidgeCV : Ridge regression with built-in cross validation.\n",
      "     |  :class:`~sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      "     |      combines ridge regression with the kernel trick.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Regularization improves the conditioning of the problem and\n",
      "     |  reduces the variance of the estimates. Larger values specify stronger\n",
      "     |  regularization. Alpha corresponds to ``1 / (2C)`` in other linear\n",
      "     |  models such as :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "     |  :class:`~sklearn.svm.LinearSVC`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import Ridge\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> n_samples, n_features = 10, 5\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> y = rng.randn(n_samples)\n",
      "     |  >>> X = rng.randn(n_samples, n_features)\n",
      "     |  >>> clf = Ridge(alpha=1.0)\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  Ridge()\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Ridge\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      _BaseRidge\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, solver='auto', positive=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Ridge regression model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample. If given a float, every sample\n",
      "     |          will have the same weight.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._ridge.Ridge, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.Ridge\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._ridge.Ridge, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.Ridge\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class RidgeCV(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, _BaseRidgeCV)\n",
      "     |  RidgeCV(alphas=(0.1, 1.0, 10.0), *, fit_intercept=True, scoring=None, cv=None, gcv_mode=None, store_cv_results=None, alpha_per_target=False, store_cv_values='deprecated')\n",
      "     |\n",
      "     |  Ridge regression with built-in cross-validation.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  By default, it performs efficient Leave-One-Out Cross-Validation.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n",
      "     |      Array of alpha values to try.\n",
      "     |      Regularization strength; must be a positive float. Regularization\n",
      "     |      improves the conditioning of the problem and reduces the variance of\n",
      "     |      the estimates. Larger values specify stronger regularization.\n",
      "     |      Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "     |      :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "     |      :class:`~sklearn.svm.LinearSVC`.\n",
      "     |      If using Leave-One-Out cross-validation, alphas must be strictly positive.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  scoring : str, callable, default=None\n",
      "     |      A string (see :ref:`scoring_parameter`) or a scorer callable object /\n",
      "     |      function with signature ``scorer(estimator, X, y)``. If None, the\n",
      "     |      negative mean squared error if cv is 'auto' or None (i.e. when using\n",
      "     |      leave-one-out cross-validation), and r2 score otherwise.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the efficient Leave-One-Out cross-validation\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      For integer/None inputs, if ``y`` is binary or multiclass,\n",
      "     |      :class:`~sklearn.model_selection.StratifiedKFold` is used, else,\n",
      "     |      :class:`~sklearn.model_selection.KFold` is used.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |  gcv_mode : {'auto', 'svd', 'eigen'}, default='auto'\n",
      "     |      Flag indicating which strategy to use when performing\n",
      "     |      Leave-One-Out Cross-Validation. Options are::\n",
      "     |\n",
      "     |          'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'\n",
      "     |          'svd' : force use of singular value decomposition of X when X is\n",
      "     |              dense, eigenvalue decomposition of X^T.X when X is sparse.\n",
      "     |          'eigen' : force computation via eigendecomposition of X.X^T\n",
      "     |\n",
      "     |      The 'auto' mode is the default and is intended to pick the cheaper\n",
      "     |      option of the two depending on the shape of the training data.\n",
      "     |\n",
      "     |  store_cv_results : bool, default=False\n",
      "     |      Flag indicating if the cross-validation values corresponding to\n",
      "     |      each alpha should be stored in the ``cv_values_`` attribute (see\n",
      "     |      below). This flag is only compatible with ``cv=None`` (i.e. using\n",
      "     |      Leave-One-Out Cross-Validation).\n",
      "     |\n",
      "     |      .. versionchanged:: 1.5\n",
      "     |          Parameter name changed from `store_cv_values` to `store_cv_results`.\n",
      "     |\n",
      "     |  alpha_per_target : bool, default=False\n",
      "     |      Flag indicating whether to optimize the alpha value (picked from the\n",
      "     |      `alphas` parameter list) for each target separately (for multi-output\n",
      "     |      settings: multiple prediction targets). When set to `True`, after\n",
      "     |      fitting, the `alpha_` attribute will contain a value for each target.\n",
      "     |      When set to `False`, a single alpha is used for all targets.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  store_cv_values : bool\n",
      "     |      Flag indicating if the cross-validation values corresponding to\n",
      "     |      each alpha should be stored in the ``cv_values_`` attribute (see\n",
      "     |      below). This flag is only compatible with ``cv=None`` (i.e. using\n",
      "     |      Leave-One-Out Cross-Validation).\n",
      "     |\n",
      "     |      .. deprecated:: 1.5\n",
      "     |          `store_cv_values` is deprecated in version 1.5 in favor of\n",
      "     |          `store_cv_results` and will be removed in version 1.7.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : ndarray of shape (n_samples, n_alphas) or             shape (n_samples, n_targets, n_alphas), optional\n",
      "     |      Cross-validation values for each alpha (only available if\n",
      "     |      ``store_cv_results=True`` and ``cv=None``). After ``fit()`` has been\n",
      "     |      called, this attribute will contain the mean squared errors if\n",
      "     |      `scoring is None` otherwise it will contain standardized per point\n",
      "     |      prediction values.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.5\n",
      "     |          `cv_values_` changed to `cv_results_`.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (n_features) or (n_targets, n_features)\n",
      "     |      Weight vector(s).\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      ``fit_intercept = False``.\n",
      "     |\n",
      "     |  alpha_ : float or ndarray of shape (n_targets,)\n",
      "     |      Estimated regularization parameter, or, if ``alpha_per_target=True``,\n",
      "     |      the estimated regularization parameter for each target.\n",
      "     |\n",
      "     |  best_score_ : float or ndarray of shape (n_targets,)\n",
      "     |      Score of base estimator with best alpha, or, if\n",
      "     |      ``alpha_per_target=True``, a score for each target.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Ridge : Ridge regression.\n",
      "     |  RidgeClassifier : Classifier based on ridge regression on {-1, 1} labels.\n",
      "     |  RidgeClassifierCV : Ridge classifier with built-in cross validation.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_diabetes\n",
      "     |  >>> from sklearn.linear_model import RidgeCV\n",
      "     |  >>> X, y = load_diabetes(return_X_y=True)\n",
      "     |  >>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.5166...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RidgeCV\n",
      "     |      sklearn.base.MultiOutputMixin\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      _BaseRidgeCV\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, **params)\n",
      "     |      Fit Ridge regression model with cv.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Training data. If using GCV, will be cast to float64\n",
      "     |          if necessary.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample. If given a float, every sample\n",
      "     |          will have the same weight.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the underlying scorer.\n",
      "     |\n",
      "     |          .. versionadded:: 1.5\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When sample_weight is provided, the selected hyperparameter may depend\n",
      "     |      on whether we use leave-one-out cross-validation (cv=None or cv='auto')\n",
      "     |      or another form of cross-validation, because only leave-one-out\n",
      "     |      cross-validation takes the sample weights into account when computing\n",
      "     |      the validation score.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._ridge.RidgeCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._ridge.RidgeCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseRidgeCV:\n",
      "     |\n",
      "     |  __init__(self, alphas=(0.1, 1.0, 10.0), *, fit_intercept=True, scoring=None, cv=None, gcv_mode=None, store_cv_results=None, alpha_per_target=False, store_cv_values='deprecated')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _BaseRidgeCV:\n",
      "     |\n",
      "     |  cv_values_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class RidgeClassifier(_RidgeClassifierMixin, _BaseRidge)\n",
      "     |  RidgeClassifier(alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, class_weight=None, solver='auto', positive=False, random_state=None)\n",
      "     |\n",
      "     |  Classifier using Ridge regression.\n",
      "     |\n",
      "     |  This classifier first converts the target values into ``{-1, 1}`` and\n",
      "     |  then treats the problem as a regression task (multi-output regression in\n",
      "     |  the multiclass case).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Regularization strength; must be a positive float. Regularization\n",
      "     |      improves the conditioning of the problem and reduces the variance of\n",
      "     |      the estimates. Larger values specify stronger regularization.\n",
      "     |      Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "     |      :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "     |      :class:`~sklearn.svm.LinearSVC`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set to false, no\n",
      "     |      intercept will be used in calculations (e.g. data is expected to be\n",
      "     |      already centered).\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_iter : int, default=None\n",
      "     |      Maximum number of iterations for conjugate gradient solver.\n",
      "     |      The default value is determined by scipy.sparse.linalg.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      The precision of the solution (`coef_`) is determined by `tol` which\n",
      "     |      specifies a different convergence criterion for each solver:\n",
      "     |\n",
      "     |      - 'svd': `tol` has no impact.\n",
      "     |\n",
      "     |      - 'cholesky': `tol` has no impact.\n",
      "     |\n",
      "     |      - 'sparse_cg': norm of residuals smaller than `tol`.\n",
      "     |\n",
      "     |      - 'lsqr': `tol` is set as atol and btol of scipy.sparse.linalg.lsqr,\n",
      "     |        which control the norm of the residual vector in terms of the norms of\n",
      "     |        matrix and coefficients.\n",
      "     |\n",
      "     |      - 'sag' and 'saga': relative change of coef smaller than `tol`.\n",
      "     |\n",
      "     |      - 'lbfgs': maximum of the absolute (projected) gradient=max|residuals|\n",
      "     |        smaller than `tol`.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.2\n",
      "     |         Default value changed from 1e-3 to 1e-4 for consistency with other linear\n",
      "     |         models.\n",
      "     |\n",
      "     |  class_weight : dict or 'balanced', default=None\n",
      "     |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      "     |      If not given, all classes are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |  solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      "     |      Solver to use in the computational routines:\n",
      "     |\n",
      "     |      - 'auto' chooses the solver automatically based on the type of data.\n",
      "     |\n",
      "     |      - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "     |        coefficients. It is the most stable solver, in particular more stable\n",
      "     |        for singular matrices than 'cholesky' at the cost of being slower.\n",
      "     |\n",
      "     |      - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "     |        obtain a closed-form solution.\n",
      "     |\n",
      "     |      - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "     |        scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "     |        more appropriate than 'cholesky' for large-scale data\n",
      "     |        (possibility to set `tol` and `max_iter`).\n",
      "     |\n",
      "     |      - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "     |        scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "     |        procedure.\n",
      "     |\n",
      "     |      - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "     |        its unbiased and more flexible version named SAGA. Both methods\n",
      "     |        use an iterative procedure, and are often faster than other solvers\n",
      "     |        when both n_samples and n_features are large. Note that 'sag' and\n",
      "     |        'saga' fast convergence is only guaranteed on features with\n",
      "     |        approximately the same scale. You can preprocess the data with a\n",
      "     |        scaler from sklearn.preprocessing.\n",
      "     |\n",
      "     |        .. versionadded:: 0.17\n",
      "     |           Stochastic Average Gradient descent solver.\n",
      "     |        .. versionadded:: 0.19\n",
      "     |           SAGA solver.\n",
      "     |\n",
      "     |      - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      "     |        `scipy.optimize.minimize`. It can be used only when `positive`\n",
      "     |        is True.\n",
      "     |\n",
      "     |  positive : bool, default=False\n",
      "     |      When set to ``True``, forces the coefficients to be positive.\n",
      "     |      Only 'lbfgs' solver is supported in this case.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "     |      See :term:`Glossary <random_state>` for details.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "     |      Coefficient of the features in the decision function.\n",
      "     |\n",
      "     |      ``coef_`` is of shape (1, n_features) when the given problem is binary.\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      ``fit_intercept = False``.\n",
      "     |\n",
      "     |  n_iter_ : None or ndarray of shape (n_targets,)\n",
      "     |      Actual number of iterations for each target. Available only for\n",
      "     |      sag and lsqr solvers. Other solvers will return None.\n",
      "     |\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      The classes labels.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  solver_ : str\n",
      "     |      The solver that was used at fit time by the computational\n",
      "     |      routines.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Ridge : Ridge regression.\n",
      "     |  RidgeClassifierCV :  Ridge classifier with built-in cross validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  For multi-class classification, n_class classifiers are trained in\n",
      "     |  a one-versus-all approach. Concretely, this is implemented by taking\n",
      "     |  advantage of the multi-variate response support in Ridge.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_breast_cancer\n",
      "     |  >>> from sklearn.linear_model import RidgeClassifier\n",
      "     |  >>> X, y = load_breast_cancer(return_X_y=True)\n",
      "     |  >>> clf = RidgeClassifier().fit(X, y)\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.9595...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RidgeClassifier\n",
      "     |      _RidgeClassifierMixin\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      _BaseRidge\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, class_weight=None, solver='auto', positive=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Ridge classifier model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample. If given a float, every sample\n",
      "     |          will have the same weight.\n",
      "     |\n",
      "     |          .. versionadded:: 0.17\n",
      "     |             *sample_weight* support to RidgeClassifier.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Instance of the estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._ridge.RidgeClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeClassifier\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._ridge.RidgeClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeClassifier\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RidgeClassifierMixin:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, spare matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to predict the targets.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          Vector or matrix containing the predictions. In binary and\n",
      "     |          multiclass problems, this is a vector containing `n_samples`. In\n",
      "     |          a multilabel problem, it returns a matrix of shape\n",
      "     |          `(n_samples, n_outputs)`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _RidgeClassifierMixin:\n",
      "     |\n",
      "     |  classes_\n",
      "     |      Classes labels.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class RidgeClassifierCV(_RidgeClassifierMixin, _BaseRidgeCV)\n",
      "     |  RidgeClassifierCV(alphas=(0.1, 1.0, 10.0), *, fit_intercept=True, scoring=None, cv=None, class_weight=None, store_cv_results=None, store_cv_values='deprecated')\n",
      "     |\n",
      "     |  Ridge classifier with built-in cross-validation.\n",
      "     |\n",
      "     |  See glossary entry for :term:`cross-validation estimator`.\n",
      "     |\n",
      "     |  By default, it performs Leave-One-Out Cross-Validation. Currently,\n",
      "     |  only the n_features > n_samples case is handled efficiently.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alphas : array-like of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n",
      "     |      Array of alpha values to try.\n",
      "     |      Regularization strength; must be a positive float. Regularization\n",
      "     |      improves the conditioning of the problem and reduces the variance of\n",
      "     |      the estimates. Larger values specify stronger regularization.\n",
      "     |      Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "     |      :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "     |      :class:`~sklearn.svm.LinearSVC`.\n",
      "     |      If using Leave-One-Out cross-validation, alphas must be strictly positive.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations\n",
      "     |      (i.e. data is expected to be centered).\n",
      "     |\n",
      "     |  scoring : str, callable, default=None\n",
      "     |      A string (see :ref:`scoring_parameter`) or a scorer callable object /\n",
      "     |      function with signature ``scorer(estimator, X, y)``.\n",
      "     |\n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |\n",
      "     |      - None, to use the efficient Leave-One-Out cross-validation\n",
      "     |      - integer, to specify the number of folds.\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |\n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |\n",
      "     |  class_weight : dict or 'balanced', default=None\n",
      "     |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      "     |      If not given, all classes are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |  store_cv_results : bool, default=False\n",
      "     |      Flag indicating if the cross-validation results corresponding to\n",
      "     |      each alpha should be stored in the ``cv_results_`` attribute (see\n",
      "     |      below). This flag is only compatible with ``cv=None`` (i.e. using\n",
      "     |      Leave-One-Out Cross-Validation).\n",
      "     |\n",
      "     |      .. versionchanged:: 1.5\n",
      "     |          Parameter name changed from `store_cv_values` to `store_cv_results`.\n",
      "     |\n",
      "     |  store_cv_values : bool\n",
      "     |      Flag indicating if the cross-validation values corresponding to\n",
      "     |      each alpha should be stored in the ``cv_values_`` attribute (see\n",
      "     |      below). This flag is only compatible with ``cv=None`` (i.e. using\n",
      "     |      Leave-One-Out Cross-Validation).\n",
      "     |\n",
      "     |      .. deprecated:: 1.5\n",
      "     |          `store_cv_values` is deprecated in version 1.5 in favor of\n",
      "     |          `store_cv_results` and will be removed in version 1.7.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : ndarray of shape (n_samples, n_targets, n_alphas), optional\n",
      "     |      Cross-validation results for each alpha (only if ``store_cv_results=True`` and\n",
      "     |      ``cv=None``). After ``fit()`` has been called, this attribute will\n",
      "     |      contain the mean squared errors if `scoring is None` otherwise it\n",
      "     |      will contain standardized per point prediction values.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.5\n",
      "     |          `cv_values_` changed to `cv_results_`.\n",
      "     |\n",
      "     |  coef_ : ndarray of shape (1, n_features) or (n_targets, n_features)\n",
      "     |      Coefficient of the features in the decision function.\n",
      "     |\n",
      "     |      ``coef_`` is of shape (1, n_features) when the given problem is binary.\n",
      "     |\n",
      "     |  intercept_ : float or ndarray of shape (n_targets,)\n",
      "     |      Independent term in decision function. Set to 0.0 if\n",
      "     |      ``fit_intercept = False``.\n",
      "     |\n",
      "     |  alpha_ : float\n",
      "     |      Estimated regularization parameter.\n",
      "     |\n",
      "     |  best_score_ : float\n",
      "     |      Score of base estimator with best alpha.\n",
      "     |\n",
      "     |      .. versionadded:: 0.23\n",
      "     |\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      The classes labels.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Ridge : Ridge regression.\n",
      "     |  RidgeClassifier : Ridge classifier.\n",
      "     |  RidgeCV : Ridge regression with built-in cross validation.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  For multi-class classification, n_class classifiers are trained in\n",
      "     |  a one-versus-all approach. Concretely, this is implemented by taking\n",
      "     |  advantage of the multi-variate response support in Ridge.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_breast_cancer\n",
      "     |  >>> from sklearn.linear_model import RidgeClassifierCV\n",
      "     |  >>> X, y = load_breast_cancer(return_X_y=True)\n",
      "     |  >>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.9630...\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RidgeClassifierCV\n",
      "     |      _RidgeClassifierMixin\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      _BaseRidgeCV\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, alphas=(0.1, 1.0, 10.0), *, fit_intercept=True, scoring=None, cv=None, class_weight=None, store_cv_results=None, store_cv_values='deprecated')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None, **params)\n",
      "     |      Fit Ridge classifier with cv.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples\n",
      "     |          and `n_features` is the number of features. When using GCV,\n",
      "     |          will be cast to float64 if necessary.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values. Will be cast to X's dtype if necessary.\n",
      "     |\n",
      "     |      sample_weight : float or ndarray of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample. If given a float, every sample\n",
      "     |          will have the same weight.\n",
      "     |\n",
      "     |      **params : dict, default=None\n",
      "     |          Parameters to be passed to the underlying scorer.\n",
      "     |\n",
      "     |          .. versionadded:: 1.5\n",
      "     |              Only available if `enable_metadata_routing=True`,\n",
      "     |              which can be set by using\n",
      "     |              ``sklearn.set_config(enable_metadata_routing=True)``.\n",
      "     |              See :ref:`Metadata Routing User Guide <metadata_routing>` for\n",
      "     |              more details.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._ridge.RidgeClassifierCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeClassifierCV\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._ridge.RidgeClassifierCV, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._ridge.RidgeClassifierCV\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  param = 'alpha_per_target'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RidgeClassifierMixin:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, spare matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to predict the targets.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          Vector or matrix containing the predictions. In binary and\n",
      "     |          multiclass problems, this is a vector containing `n_samples`. In\n",
      "     |          a multilabel problem, it returns a matrix of shape\n",
      "     |          `(n_samples, n_outputs)`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _RidgeClassifierMixin:\n",
      "     |\n",
      "     |  classes_\n",
      "     |      Classes labels.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseRidgeCV:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRouter\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _BaseRidgeCV:\n",
      "     |\n",
      "     |  cv_values_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class SGDClassifier(BaseSGDClassifier)\n",
      "     |  SGDClassifier(loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
      "     |\n",
      "     |  Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n",
      "     |\n",
      "     |  This estimator implements regularized linear models with stochastic\n",
      "     |  gradient descent (SGD) learning: the gradient of the loss is estimated\n",
      "     |  each sample at a time and the model is updated along the way with a\n",
      "     |  decreasing strength schedule (aka learning rate). SGD allows minibatch\n",
      "     |  (online/out-of-core) learning via the `partial_fit` method.\n",
      "     |  For best results using the default learning rate schedule, the data should\n",
      "     |  have zero mean and unit variance.\n",
      "     |\n",
      "     |  This implementation works with data represented as dense or sparse arrays\n",
      "     |  of floating point values for the features. The model it fits can be\n",
      "     |  controlled with the loss parameter; by default, it fits a linear support\n",
      "     |  vector machine (SVM).\n",
      "     |\n",
      "     |  The regularizer is a penalty added to the loss function that shrinks model\n",
      "     |  parameters towards the zero vector using either the squared euclidean norm\n",
      "     |  L2 or the absolute norm L1 or a combination of both (Elastic Net). If the\n",
      "     |  parameter update crosses the 0.0 value because of the regularizer, the\n",
      "     |  update is truncated to 0.0 to allow for learning sparse models and achieve\n",
      "     |  online feature selection.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <sgd>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  loss : {'hinge', 'log_loss', 'modified_huber', 'squared_hinge',        'perceptron', 'squared_error', 'huber', 'epsilon_insensitive',        'squared_epsilon_insensitive'}, default='hinge'\n",
      "     |      The loss function to be used.\n",
      "     |\n",
      "     |      - 'hinge' gives a linear SVM.\n",
      "     |      - 'log_loss' gives logistic regression, a probabilistic classifier.\n",
      "     |      - 'modified_huber' is another smooth loss that brings tolerance to\n",
      "     |        outliers as well as probability estimates.\n",
      "     |      - 'squared_hinge' is like hinge but is quadratically penalized.\n",
      "     |      - 'perceptron' is the linear loss used by the perceptron algorithm.\n",
      "     |      - The other losses, 'squared_error', 'huber', 'epsilon_insensitive' and\n",
      "     |        'squared_epsilon_insensitive' are designed for regression but can be useful\n",
      "     |        in classification as well; see\n",
      "     |        :class:`~sklearn.linear_model.SGDRegressor` for a description.\n",
      "     |\n",
      "     |      More details about the losses formulas can be found in the\n",
      "     |      :ref:`User Guide <sgd_mathematical_formulation>`.\n",
      "     |\n",
      "     |  penalty : {'l2', 'l1', 'elasticnet', None}, default='l2'\n",
      "     |      The penalty (aka regularization term) to be used. Defaults to 'l2'\n",
      "     |      which is the standard regularizer for linear SVM models. 'l1' and\n",
      "     |      'elasticnet' might bring sparsity to the model (feature selection)\n",
      "     |      not achievable with 'l2'. No penalty is added when set to `None`.\n",
      "     |\n",
      "     |  alpha : float, default=0.0001\n",
      "     |      Constant that multiplies the regularization term. The higher the\n",
      "     |      value, the stronger the regularization. Also used to compute the\n",
      "     |      learning rate when `learning_rate` is set to 'optimal'.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  l1_ratio : float, default=0.15\n",
      "     |      The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\n",
      "     |      l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.\n",
      "     |      Only used if `penalty` is 'elasticnet'.\n",
      "     |      Values must be in the range `[0.0, 1.0]`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If False, the\n",
      "     |      data is assumed to be already centered.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      :meth:`partial_fit` method.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, training will stop\n",
      "     |      when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive\n",
      "     |      epochs.\n",
      "     |      Convergence is checked against the training loss or the\n",
      "     |      validation loss depending on the `early_stopping` parameter.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |      Values must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  epsilon : float, default=0.1\n",
      "     |      Epsilon in the epsilon-insensitive loss functions; only if `loss` is\n",
      "     |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\n",
      "     |      For 'huber', determines the threshold at which it becomes less\n",
      "     |      important to get the prediction exactly right.\n",
      "     |      For epsilon-insensitive, any differences between the current prediction\n",
      "     |      and the correct label are ignored if they are less than this threshold.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      The number of CPUs to use to do the OVA (One Versus All, for\n",
      "     |      multi-class problems) computation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used for shuffling the data, when ``shuffle`` is set to ``True``.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |      Integer values must be in the range `[0, 2**32 - 1]`.\n",
      "     |\n",
      "     |  learning_rate : str, default='optimal'\n",
      "     |      The learning rate schedule:\n",
      "     |\n",
      "     |      - 'constant': `eta = eta0`\n",
      "     |      - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\n",
      "     |        where `t0` is chosen by a heuristic proposed by Leon Bottou.\n",
      "     |      - 'invscaling': `eta = eta0 / pow(t, power_t)`\n",
      "     |      - 'adaptive': `eta = eta0`, as long as the training keeps decreasing.\n",
      "     |        Each time n_iter_no_change consecutive epochs fail to decrease the\n",
      "     |        training loss by tol or fail to increase validation score by tol if\n",
      "     |        `early_stopping` is `True`, the current learning rate is divided by 5.\n",
      "     |\n",
      "     |          .. versionadded:: 0.20\n",
      "     |              Added 'adaptive' option\n",
      "     |\n",
      "     |  eta0 : float, default=0.0\n",
      "     |      The initial learning rate for the 'constant', 'invscaling' or\n",
      "     |      'adaptive' schedules. The default value is 0.0 as eta0 is not used by\n",
      "     |      the default schedule 'optimal'.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  power_t : float, default=0.5\n",
      "     |      The exponent for inverse scaling learning rate.\n",
      "     |      Values must be in the range `(-inf, inf)`.\n",
      "     |\n",
      "     |  early_stopping : bool, default=False\n",
      "     |      Whether to use early stopping to terminate training when validation\n",
      "     |      score is not improving. If set to `True`, it will automatically set aside\n",
      "     |      a stratified fraction of training data as validation and terminate\n",
      "     |      training when validation score returned by the `score` method is not\n",
      "     |      improving by at least tol for n_iter_no_change consecutive epochs.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'early_stopping' option\n",
      "     |\n",
      "     |  validation_fraction : float, default=0.1\n",
      "     |      The proportion of training data to set aside as validation set for\n",
      "     |      early stopping. Must be between 0 and 1.\n",
      "     |      Only used if `early_stopping` is True.\n",
      "     |      Values must be in the range `(0.0, 1.0)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'validation_fraction' option\n",
      "     |\n",
      "     |  n_iter_no_change : int, default=5\n",
      "     |      Number of iterations with no improvement to wait before stopping\n",
      "     |      fitting.\n",
      "     |      Convergence is checked against the training loss or the\n",
      "     |      validation loss depending on the `early_stopping` parameter.\n",
      "     |      Integer values must be in the range `[1, max_iter)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'n_iter_no_change' option\n",
      "     |\n",
      "     |  class_weight : dict, {class_label: weight} or \"balanced\", default=None\n",
      "     |      Preset for the class_weight fit parameter.\n",
      "     |\n",
      "     |      Weights associated with classes. If not given, all classes\n",
      "     |      are supposed to have weight one.\n",
      "     |\n",
      "     |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      "     |      weights inversely proportional to class frequencies in the input data\n",
      "     |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      Repeatedly calling fit or partial_fit when warm_start is True can\n",
      "     |      result in a different solution than when calling fit a single time\n",
      "     |      because of the way the data is shuffled.\n",
      "     |      If a dynamic learning rate is used, the learning rate is adapted\n",
      "     |      depending on the number of samples already seen. Calling ``fit`` resets\n",
      "     |      this counter, while ``partial_fit`` will result in increasing the\n",
      "     |      existing counter.\n",
      "     |\n",
      "     |  average : bool or int, default=False\n",
      "     |      When set to `True`, computes the averaged SGD weights across all\n",
      "     |      updates and stores the result in the ``coef_`` attribute. If set to\n",
      "     |      an int greater than 1, averaging will begin once the total number of\n",
      "     |      samples seen reaches `average`. So ``average=10`` will begin\n",
      "     |      averaging after seeing 10 samples.\n",
      "     |      Integer values must be in the range `[1, n_samples]`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n",
      "     |      Constants in decision function.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations before reaching the stopping criterion.\n",
      "     |      For multiclass fits, it is the maximum over every binary fit.\n",
      "     |\n",
      "     |  loss_function_ : concrete ``LossFunction``\n",
      "     |\n",
      "     |      .. deprecated:: 1.4\n",
      "     |          Attribute `loss_function_` was deprecated in version 1.4 and will be\n",
      "     |          removed in 1.6.\n",
      "     |\n",
      "     |  classes_ : array of shape (n_classes,)\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  sklearn.svm.LinearSVC : Linear support vector classification.\n",
      "     |  LogisticRegression : Logistic regression.\n",
      "     |  Perceptron : Inherits from SGDClassifier. ``Perceptron()`` is equivalent to\n",
      "     |      ``SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\",\n",
      "     |      penalty=None)``.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.linear_model import SGDClassifier\n",
      "     |  >>> from sklearn.preprocessing import StandardScaler\n",
      "     |  >>> from sklearn.pipeline import make_pipeline\n",
      "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "     |  >>> Y = np.array([1, 1, 2, 2])\n",
      "     |  >>> # Always scale the input. The most convenient way is to use a pipeline.\n",
      "     |  >>> clf = make_pipeline(StandardScaler(),\n",
      "     |  ...                     SGDClassifier(max_iter=1000, tol=1e-3))\n",
      "     |  >>> clf.fit(X, Y)\n",
      "     |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "     |                  ('sgdclassifier', SGDClassifier())])\n",
      "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
      "     |  [1]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SGDClassifier\n",
      "     |      BaseSGDClassifier\n",
      "     |      sklearn.linear_model._base.LinearClassifierMixin\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Log of probability estimates.\n",
      "     |\n",
      "     |      This method is only available for log loss and modified Huber loss.\n",
      "     |\n",
      "     |      When loss=\"modified_huber\", probability estimates may be hard zeros\n",
      "     |      and ones, so taking the logarithm is not possible.\n",
      "     |\n",
      "     |      See ``predict_proba`` for details.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input data for prediction.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      T : array-like, shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the sample for each class in the\n",
      "     |          model, where classes are ordered as they are in\n",
      "     |          `self.classes_`.\n",
      "     |\n",
      "     |  predict_proba(self, X)\n",
      "     |      Probability estimates.\n",
      "     |\n",
      "     |      This method is only available for log loss and modified Huber loss.\n",
      "     |\n",
      "     |      Multiclass probability estimates are derived from binary (one-vs.-rest)\n",
      "     |      estimates by simple normalization, as recommended by Zadrozny and\n",
      "     |      Elkan.\n",
      "     |\n",
      "     |      Binary probability estimates for loss=\"modified_huber\" are given by\n",
      "     |      (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions\n",
      "     |      it is necessary to perform proper probability calibration by wrapping\n",
      "     |      the classifier with\n",
      "     |      :class:`~sklearn.calibration.CalibratedClassifierCV` instead.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Input data for prediction.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the sample for each class in the model,\n",
      "     |          where classes are ordered as they are in `self.classes_`.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Zadrozny and Elkan, \"Transforming classifier scores into multiclass\n",
      "     |      probability estimates\", SIGKDD'02,\n",
      "     |      https://dl.acm.org/doi/pdf/10.1145/775047.775151\n",
      "     |\n",
      "     |      The justification for the formula in the loss=\"modified_huber\"\n",
      "     |      case is in the appendix B in:\n",
      "     |      http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDClassifier, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', intercept_init: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDClassifier\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      intercept_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``intercept_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDClassifier, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDClassifier\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._stochastic_gradient.SGDClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDClassifier\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSGDClassifier:\n",
      "     |\n",
      "     |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None)\n",
      "     |      Fit linear model with Stochastic Gradient Descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      coef_init : ndarray of shape (n_classes, n_features), default=None\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      intercept_init : ndarray of shape (n_classes,), default=None\n",
      "     |          The initial intercept to warm-start the optimization.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed. These weights will\n",
      "     |          be multiplied with class_weight (passed through the\n",
      "     |          constructor) if class_weight is specified.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Perform one epoch of stochastic gradient descent on given samples.\n",
      "     |\n",
      "     |      Internally, this method uses ``max_iter = 1``. Therefore, it is not\n",
      "     |      guaranteed that a minimum of the cost function is reached after calling\n",
      "     |      it once. Matters such as objective convergence, early stopping, and\n",
      "     |      learning rate adjustments should be handled by the user.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Subset of the training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Subset of the target values.\n",
      "     |\n",
      "     |      classes : ndarray of shape (n_classes,), default=None\n",
      "     |          Classes across all calls to partial_fit.\n",
      "     |          Can be obtained by via `np.unique(y_all)`, where y_all is the\n",
      "     |          target vector of the entire dataset.\n",
      "     |          This argument is required for the first call to partial_fit\n",
      "     |          and can be omitted in the subsequent calls.\n",
      "     |          Note that y doesn't need to contain all labels in `classes`.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSGDClassifier:\n",
      "     |\n",
      "     |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Predict confidence scores for samples.\n",
      "     |\n",
      "     |      The confidence score for a sample is proportional to the signed\n",
      "     |      distance of that sample to the hyperplane.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the confidence scores.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      "     |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      "     |          this class would be predicted.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict class labels for samples in X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data matrix for which we want to get the predictions.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : ndarray of shape (n_samples,)\n",
      "     |          Vector containing the class labels for each sample.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |\n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class SGDOneClassSVM(BaseSGD, sklearn.base.OutlierMixin)\n",
      "     |  SGDOneClassSVM(nu=0.5, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, warm_start=False, average=False)\n",
      "     |\n",
      "     |  Solves linear One-Class SVM using Stochastic Gradient Descent.\n",
      "     |\n",
      "     |  This implementation is meant to be used with a kernel approximation\n",
      "     |  technique (e.g. `sklearn.kernel_approximation.Nystroem`) to obtain results\n",
      "     |  similar to `sklearn.svm.OneClassSVM` which uses a Gaussian kernel by\n",
      "     |  default.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <sgd_online_one_class_svm>`.\n",
      "     |\n",
      "     |  .. versionadded:: 1.0\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  nu : float, default=0.5\n",
      "     |      The nu parameter of the One Class SVM: an upper bound on the\n",
      "     |      fraction of training errors and a lower bound of the fraction of\n",
      "     |      support vectors. Should be in the interval (0, 1]. By default 0.5\n",
      "     |      will be taken.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. Defaults to True.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      `partial_fit`. Defaults to 1000.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, the iterations will stop\n",
      "     |      when (loss > previous_loss - tol). Defaults to 1e-3.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |      Defaults to True.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      The seed of the pseudo random number generator to use when shuffling\n",
      "     |      the data.  If int, random_state is the seed used by the random number\n",
      "     |      generator; If RandomState instance, random_state is the random number\n",
      "     |      generator; If None, the random number generator is the RandomState\n",
      "     |      instance used by `np.random`.\n",
      "     |\n",
      "     |  learning_rate : {'constant', 'optimal', 'invscaling', 'adaptive'}, default='optimal'\n",
      "     |      The learning rate schedule to use with `fit`. (If using `partial_fit`,\n",
      "     |      learning rate must be controlled directly).\n",
      "     |\n",
      "     |      - 'constant': `eta = eta0`\n",
      "     |      - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\n",
      "     |        where t0 is chosen by a heuristic proposed by Leon Bottou.\n",
      "     |      - 'invscaling': `eta = eta0 / pow(t, power_t)`\n",
      "     |      - 'adaptive': eta = eta0, as long as the training keeps decreasing.\n",
      "     |        Each time n_iter_no_change consecutive epochs fail to decrease the\n",
      "     |        training loss by tol or fail to increase validation score by tol if\n",
      "     |        early_stopping is True, the current learning rate is divided by 5.\n",
      "     |\n",
      "     |  eta0 : float, default=0.0\n",
      "     |      The initial learning rate for the 'constant', 'invscaling' or\n",
      "     |      'adaptive' schedules. The default value is 0.0 as eta0 is not used by\n",
      "     |      the default schedule 'optimal'.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  power_t : float, default=0.5\n",
      "     |      The exponent for inverse scaling learning rate.\n",
      "     |      Values must be in the range `(-inf, inf)`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      Repeatedly calling fit or partial_fit when warm_start is True can\n",
      "     |      result in a different solution than when calling fit a single time\n",
      "     |      because of the way the data is shuffled.\n",
      "     |      If a dynamic learning rate is used, the learning rate is adapted\n",
      "     |      depending on the number of samples already seen. Calling ``fit`` resets\n",
      "     |      this counter, while ``partial_fit``  will result in increasing the\n",
      "     |      existing counter.\n",
      "     |\n",
      "     |  average : bool or int, default=False\n",
      "     |      When set to True, computes the averaged SGD weights and stores the\n",
      "     |      result in the ``coef_`` attribute. If set to an int greater than 1,\n",
      "     |      averaging will begin once the total number of samples seen reaches\n",
      "     |      average. So ``average=10`` will begin averaging after seeing 10\n",
      "     |      samples.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (1, n_features)\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  offset_ : ndarray of shape (1,)\n",
      "     |      Offset used to define the decision function from the raw scores.\n",
      "     |      We have the relation: decision_function = score_samples - offset.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations to reach the stopping criterion.\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  loss_function_ : concrete ``LossFunction``\n",
      "     |\n",
      "     |      .. deprecated:: 1.4\n",
      "     |          ``loss_function_`` was deprecated in version 1.4 and will be removed in\n",
      "     |          1.6.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  sklearn.svm.OneClassSVM : Unsupervised Outlier Detection.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This estimator has a linear complexity in the number of training samples\n",
      "     |  and is thus better suited than the `sklearn.svm.OneClassSVM`\n",
      "     |  implementation for datasets with a large number of training samples (say\n",
      "     |  > 10,000).\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      "     |  >>> clf = linear_model.SGDOneClassSVM(random_state=42)\n",
      "     |  >>> clf.fit(X)\n",
      "     |  SGDOneClassSVM(random_state=42)\n",
      "     |\n",
      "     |  >>> print(clf.predict([[4, 4]]))\n",
      "     |  [1]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SGDOneClassSVM\n",
      "     |      BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      sklearn.base.OutlierMixin\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, nu=0.5, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, warm_start=False, average=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  decision_function(self, X)\n",
      "     |      Signed distance to the separating hyperplane.\n",
      "     |\n",
      "     |      Signed distance is positive for an inlier and negative for an\n",
      "     |      outlier.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Testing data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dec : array-like, shape (n_samples,)\n",
      "     |          Decision function values of the samples.\n",
      "     |\n",
      "     |  fit(self, X, y=None, coef_init=None, offset_init=None, sample_weight=None)\n",
      "     |      Fit linear One-Class SVM with Stochastic Gradient Descent.\n",
      "     |\n",
      "     |      This solves an equivalent optimization problem of the\n",
      "     |      One-Class SVM primal optimization problem and returns a weight vector\n",
      "     |      w and an offset rho such that the decision function is given by\n",
      "     |      <w, x> - rho.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |\n",
      "     |      coef_init : array, shape (n_classes, n_features)\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      offset_init : array, shape (n_classes,)\n",
      "     |          The initial offset to warm-start the optimization.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), optional\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed. These weights will\n",
      "     |          be multiplied with class_weight (passed through the\n",
      "     |          constructor) if class_weight is specified.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns a fitted instance of self.\n",
      "     |\n",
      "     |  partial_fit(self, X, y=None, sample_weight=None)\n",
      "     |      Fit linear One-Class SVM with Stochastic Gradient Descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Subset of the training data.\n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), optional\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns a fitted instance of self.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Return labels (1 inlier, -1 outlier) of the samples.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Testing data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : array, shape (n_samples,)\n",
      "     |          Labels of the samples.\n",
      "     |\n",
      "     |  score_samples(self, X)\n",
      "     |      Raw scoring function of the samples.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Testing data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score_samples : array-like, shape (n_samples,)\n",
      "     |          Unshiffted scoring function values of the samples.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDOneClassSVM, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', offset_init: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDOneClassSVM\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      offset_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``offset_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDOneClassSVM, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDOneClassSVM\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  loss_functions = {'hinge': (<class 'sklearn.linear_model._sgd_fast.Hin...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OutlierMixin:\n",
      "     |\n",
      "     |  fit_predict(self, X, y=None, **kwargs)\n",
      "     |      Perform fit on X and returns labels for X.\n",
      "     |\n",
      "     |      Returns -1 for outliers and 1 for inliers.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |\n",
      "     |      **kwargs : dict\n",
      "     |          Arguments to be passed to ``fit``.\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          1 for inliers, -1 for outliers.\n",
      "\n",
      "    class SGDRegressor(BaseSGDRegressor)\n",
      "     |  SGDRegressor(loss='squared_error', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)\n",
      "     |\n",
      "     |  Linear model fitted by minimizing a regularized empirical loss with SGD.\n",
      "     |\n",
      "     |  SGD stands for Stochastic Gradient Descent: the gradient of the loss is\n",
      "     |  estimated each sample at a time and the model is updated along the way with\n",
      "     |  a decreasing strength schedule (aka learning rate).\n",
      "     |\n",
      "     |  The regularizer is a penalty added to the loss function that shrinks model\n",
      "     |  parameters towards the zero vector using either the squared euclidean norm\n",
      "     |  L2 or the absolute norm L1 or a combination of both (Elastic Net). If the\n",
      "     |  parameter update crosses the 0.0 value because of the regularizer, the\n",
      "     |  update is truncated to 0.0 to allow for learning sparse models and achieve\n",
      "     |  online feature selection.\n",
      "     |\n",
      "     |  This implementation works with data represented as dense numpy arrays of\n",
      "     |  floating point values for the features.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <sgd>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  loss : str, default='squared_error'\n",
      "     |      The loss function to be used. The possible values are 'squared_error',\n",
      "     |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'\n",
      "     |\n",
      "     |      The 'squared_error' refers to the ordinary least squares fit.\n",
      "     |      'huber' modifies 'squared_error' to focus less on getting outliers\n",
      "     |      correct by switching from squared to linear loss past a distance of\n",
      "     |      epsilon. 'epsilon_insensitive' ignores errors less than epsilon and is\n",
      "     |      linear past that; this is the loss function used in SVR.\n",
      "     |      'squared_epsilon_insensitive' is the same but becomes squared loss past\n",
      "     |      a tolerance of epsilon.\n",
      "     |\n",
      "     |      More details about the losses formulas can be found in the\n",
      "     |      :ref:`User Guide <sgd_mathematical_formulation>`.\n",
      "     |\n",
      "     |  penalty : {'l2', 'l1', 'elasticnet', None}, default='l2'\n",
      "     |      The penalty (aka regularization term) to be used. Defaults to 'l2'\n",
      "     |      which is the standard regularizer for linear SVM models. 'l1' and\n",
      "     |      'elasticnet' might bring sparsity to the model (feature selection)\n",
      "     |      not achievable with 'l2'. No penalty is added when set to `None`.\n",
      "     |\n",
      "     |  alpha : float, default=0.0001\n",
      "     |      Constant that multiplies the regularization term. The higher the\n",
      "     |      value, the stronger the regularization. Also used to compute the\n",
      "     |      learning rate when `learning_rate` is set to 'optimal'.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  l1_ratio : float, default=0.15\n",
      "     |      The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\n",
      "     |      l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.\n",
      "     |      Only used if `penalty` is 'elasticnet'.\n",
      "     |      Values must be in the range `[0.0, 1.0]`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether the intercept should be estimated or not. If False, the\n",
      "     |      data is assumed to be already centered.\n",
      "     |\n",
      "     |  max_iter : int, default=1000\n",
      "     |      The maximum number of passes over the training data (aka epochs).\n",
      "     |      It only impacts the behavior in the ``fit`` method, and not the\n",
      "     |      :meth:`partial_fit` method.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  tol : float or None, default=1e-3\n",
      "     |      The stopping criterion. If it is not None, training will stop\n",
      "     |      when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive\n",
      "     |      epochs.\n",
      "     |      Convergence is checked against the training loss or the\n",
      "     |      validation loss depending on the `early_stopping` parameter.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.19\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether or not the training data should be shuffled after each epoch.\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      The verbosity level.\n",
      "     |      Values must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  epsilon : float, default=0.1\n",
      "     |      Epsilon in the epsilon-insensitive loss functions; only if `loss` is\n",
      "     |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\n",
      "     |      For 'huber', determines the threshold at which it becomes less\n",
      "     |      important to get the prediction exactly right.\n",
      "     |      For epsilon-insensitive, any differences between the current prediction\n",
      "     |      and the correct label are ignored if they are less than this threshold.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance, default=None\n",
      "     |      Used for shuffling the data, when ``shuffle`` is set to ``True``.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  learning_rate : str, default='invscaling'\n",
      "     |      The learning rate schedule:\n",
      "     |\n",
      "     |      - 'constant': `eta = eta0`\n",
      "     |      - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\n",
      "     |        where t0 is chosen by a heuristic proposed by Leon Bottou.\n",
      "     |      - 'invscaling': `eta = eta0 / pow(t, power_t)`\n",
      "     |      - 'adaptive': eta = eta0, as long as the training keeps decreasing.\n",
      "     |        Each time n_iter_no_change consecutive epochs fail to decrease the\n",
      "     |        training loss by tol or fail to increase validation score by tol if\n",
      "     |        early_stopping is True, the current learning rate is divided by 5.\n",
      "     |\n",
      "     |          .. versionadded:: 0.20\n",
      "     |              Added 'adaptive' option\n",
      "     |\n",
      "     |  eta0 : float, default=0.01\n",
      "     |      The initial learning rate for the 'constant', 'invscaling' or\n",
      "     |      'adaptive' schedules. The default value is 0.01.\n",
      "     |      Values must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  power_t : float, default=0.25\n",
      "     |      The exponent for inverse scaling learning rate.\n",
      "     |      Values must be in the range `(-inf, inf)`.\n",
      "     |\n",
      "     |  early_stopping : bool, default=False\n",
      "     |      Whether to use early stopping to terminate training when validation\n",
      "     |      score is not improving. If set to True, it will automatically set aside\n",
      "     |      a fraction of training data as validation and terminate\n",
      "     |      training when validation score returned by the `score` method is not\n",
      "     |      improving by at least `tol` for `n_iter_no_change` consecutive\n",
      "     |      epochs.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'early_stopping' option\n",
      "     |\n",
      "     |  validation_fraction : float, default=0.1\n",
      "     |      The proportion of training data to set aside as validation set for\n",
      "     |      early stopping. Must be between 0 and 1.\n",
      "     |      Only used if `early_stopping` is True.\n",
      "     |      Values must be in the range `(0.0, 1.0)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'validation_fraction' option\n",
      "     |\n",
      "     |  n_iter_no_change : int, default=5\n",
      "     |      Number of iterations with no improvement to wait before stopping\n",
      "     |      fitting.\n",
      "     |      Convergence is checked against the training loss or the\n",
      "     |      validation loss depending on the `early_stopping` parameter.\n",
      "     |      Integer values must be in the range `[1, max_iter)`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |          Added 'n_iter_no_change' option\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      When set to True, reuse the solution of the previous call to fit as\n",
      "     |      initialization, otherwise, just erase the previous solution.\n",
      "     |      See :term:`the Glossary <warm_start>`.\n",
      "     |\n",
      "     |      Repeatedly calling fit or partial_fit when warm_start is True can\n",
      "     |      result in a different solution than when calling fit a single time\n",
      "     |      because of the way the data is shuffled.\n",
      "     |      If a dynamic learning rate is used, the learning rate is adapted\n",
      "     |      depending on the number of samples already seen. Calling ``fit`` resets\n",
      "     |      this counter, while ``partial_fit``  will result in increasing the\n",
      "     |      existing counter.\n",
      "     |\n",
      "     |  average : bool or int, default=False\n",
      "     |      When set to True, computes the averaged SGD weights across all\n",
      "     |      updates and stores the result in the ``coef_`` attribute. If set to\n",
      "     |      an int greater than 1, averaging will begin once the total number of\n",
      "     |      samples seen reaches `average`. So ``average=10`` will begin\n",
      "     |      averaging after seeing 10 samples.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,)\n",
      "     |      Weights assigned to the features.\n",
      "     |\n",
      "     |  intercept_ : ndarray of shape (1,)\n",
      "     |      The intercept term.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      The actual number of iterations before reaching the stopping criterion.\n",
      "     |\n",
      "     |  t_ : int\n",
      "     |      Number of weight updates performed during training.\n",
      "     |      Same as ``(n_iter_ * n_samples + 1)``.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  HuberRegressor : Linear regression model that is robust to outliers.\n",
      "     |  Lars : Least Angle Regression model.\n",
      "     |  Lasso : Linear Model trained with L1 prior as regularizer.\n",
      "     |  RANSACRegressor : RANSAC (RANdom SAmple Consensus) algorithm.\n",
      "     |  Ridge : Linear least squares with l2 regularization.\n",
      "     |  sklearn.svm.SVR : Epsilon-Support Vector Regression.\n",
      "     |  TheilSenRegressor : Theil-Sen Estimator robust multivariate regression model.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.linear_model import SGDRegressor\n",
      "     |  >>> from sklearn.pipeline import make_pipeline\n",
      "     |  >>> from sklearn.preprocessing import StandardScaler\n",
      "     |  >>> n_samples, n_features = 10, 5\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> y = rng.randn(n_samples)\n",
      "     |  >>> X = rng.randn(n_samples, n_features)\n",
      "     |  >>> # Always scale the input. The most convenient way is to use a pipeline.\n",
      "     |  >>> reg = make_pipeline(StandardScaler(),\n",
      "     |  ...                     SGDRegressor(max_iter=1000, tol=1e-3))\n",
      "     |  >>> reg.fit(X, y)\n",
      "     |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "     |                  ('sgdregressor', SGDRegressor())])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SGDRegressor\n",
      "     |      BaseSGDRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      BaseSGD\n",
      "     |      sklearn.linear_model._base.SparseCoefMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, loss='squared_error', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDRegressor, *, coef_init: Union[bool, NoneType, str] = '$UNCHANGED$', intercept_init: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      coef_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``coef_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      intercept_init : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``intercept_init`` parameter in ``fit``.\n",
      "     |\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.linear_model._stochastic_gradient.SGDRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDRegressor\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._stochastic_gradient.SGDRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._stochastic_gradient.SGDRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSGDRegressor:\n",
      "     |\n",
      "     |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None)\n",
      "     |      Fit linear model with Stochastic Gradient Descent.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      coef_init : ndarray of shape (n_features,), default=None\n",
      "     |          The initial coefficients to warm-start the optimization.\n",
      "     |\n",
      "     |      intercept_init : ndarray of shape (1,), default=None\n",
      "     |          The initial intercept to warm-start the optimization.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted `SGDRegressor` estimator.\n",
      "     |\n",
      "     |  partial_fit(self, X, y, sample_weight=None)\n",
      "     |      Perform one epoch of stochastic gradient descent on given samples.\n",
      "     |\n",
      "     |      Internally, this method uses ``max_iter = 1``. Therefore, it is not\n",
      "     |      guaranteed that a minimum of the cost function is reached after calling\n",
      "     |      it once. Matters such as objective convergence and early stopping\n",
      "     |      should be handled by the user.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Subset of training data.\n",
      "     |\n",
      "     |      y : numpy array of shape (n_samples,)\n",
      "     |          Subset of target values.\n",
      "     |\n",
      "     |      sample_weight : array-like, shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples.\n",
      "     |          If not provided, uniform weights are assumed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns an instance of self.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "     |          Input data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray of shape (n_samples,)\n",
      "     |         Predicted target values per element in X.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSGDRegressor:\n",
      "     |\n",
      "     |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSGD:\n",
      "     |\n",
      "     |  loss_function_\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      "     |\n",
      "     |  densify(self)\n",
      "     |      Convert coefficient matrix to dense array format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      "     |      default format of ``coef_`` and is required for fitting, so calling\n",
      "     |      this method is only required on models that have previously been\n",
      "     |      sparsified; otherwise, it is a no-op.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  sparsify(self)\n",
      "     |      Convert coefficient matrix to sparse format.\n",
      "     |\n",
      "     |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      "     |      L1-regularized models can be much more memory- and storage-efficient\n",
      "     |      than the usual numpy.ndarray representation.\n",
      "     |\n",
      "     |      The ``intercept_`` member is not converted.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      "     |      this may actually *increase* memory usage, so use this method with\n",
      "     |      care. A rule of thumb is that the number of zero elements, which can\n",
      "     |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      "     |      to provide significant benefits.\n",
      "     |\n",
      "     |      After calling this method, further fitting with the partial_fit\n",
      "     |      method (if any) will not work until you call densify.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class SquaredLoss(Regression)\n",
      "     |  Squared loss traditional used in linear regression.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SquaredLoss\n",
      "     |      Regression\n",
      "     |      LossFunction\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __reduce__(self)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Regression:\n",
      "     |\n",
      "     |  __reduce_cython__(self)\n",
      "     |\n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |\n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LossFunction:\n",
      "     |\n",
      "     |  py_dloss(self, p, y)\n",
      "     |      Python version of `dloss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The derivative of the loss function with regards to `p`.\n",
      "     |\n",
      "     |  py_loss(self, p, y)\n",
      "     |      Python version of `loss` for testing.\n",
      "     |\n",
      "     |      Pytest needs a python function and can't use cdef functions.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : double\n",
      "     |          The prediction, `p = w^T x + intercept`.\n",
      "     |      y : double\n",
      "     |          The true value (aka target).\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      double\n",
      "     |          The loss evaluated at `p` and `y`.\n",
      "\n",
      "    class TheilSenRegressor(sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      "     |  TheilSenRegressor(*, fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False)\n",
      "     |\n",
      "     |  Theil-Sen Estimator: robust multivariate regression model.\n",
      "     |\n",
      "     |  The algorithm calculates least square solutions on subsets with size\n",
      "     |  n_subsamples of the samples in X. Any value of n_subsamples between the\n",
      "     |  number of features and samples leads to an estimator with a compromise\n",
      "     |  between robustness and efficiency. Since the number of least square\n",
      "     |  solutions is \"n_samples choose n_subsamples\", it can be extremely large\n",
      "     |  and can therefore be limited with max_subpopulation. If this limit is\n",
      "     |  reached, the subsets are chosen randomly. In a final step, the spatial\n",
      "     |  median (or L1 median) is calculated of all least square solutions.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <theil_sen_regression>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Whether to calculate the intercept for this model. If set\n",
      "     |      to false, no intercept will be used in calculations.\n",
      "     |\n",
      "     |  copy_X : bool, default=True\n",
      "     |      If True, X will be copied; else, it may be overwritten.\n",
      "     |\n",
      "     |  max_subpopulation : int, default=1e4\n",
      "     |      Instead of computing with a set of cardinality 'n choose k', where n is\n",
      "     |      the number of samples and k is the number of subsamples (at least\n",
      "     |      number of features), consider only a stochastic subpopulation of a\n",
      "     |      given maximal size if 'n choose k' is larger than max_subpopulation.\n",
      "     |      For other than small problem sizes this parameter will determine\n",
      "     |      memory usage and runtime if n_subsamples is not changed. Note that the\n",
      "     |      data type should be int but floats such as 1e4 can be accepted too.\n",
      "     |\n",
      "     |  n_subsamples : int, default=None\n",
      "     |      Number of samples to calculate the parameters. This is at least the\n",
      "     |      number of features (plus 1 if fit_intercept=True) and the number of\n",
      "     |      samples as a maximum. A lower number leads to a higher breakdown\n",
      "     |      point and a low efficiency while a high number leads to a low\n",
      "     |      breakdown point and a high efficiency. If None, take the\n",
      "     |      minimum number of subsamples leading to maximal robustness.\n",
      "     |      If n_subsamples is set to n_samples, Theil-Sen is identical to least\n",
      "     |      squares.\n",
      "     |\n",
      "     |  max_iter : int, default=300\n",
      "     |      Maximum number of iterations for the calculation of spatial median.\n",
      "     |\n",
      "     |  tol : float, default=1e-3\n",
      "     |      Tolerance when calculating spatial median.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      A random number generator instance to define the state of the random\n",
      "     |      permutations generator. Pass an int for reproducible output across\n",
      "     |      multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of CPUs to use during the cross validation.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |\n",
      "     |  verbose : bool, default=False\n",
      "     |      Verbose mode when fitting the model.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : ndarray of shape (n_features,)\n",
      "     |      Coefficients of the regression model (median of distribution).\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Estimated intercept of regression model.\n",
      "     |\n",
      "     |  breakdown_ : float\n",
      "     |      Approximated breakdown point.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Number of iterations needed for the spatial median.\n",
      "     |\n",
      "     |  n_subpopulation_ : int\n",
      "     |      Number of combinations taken into account from 'n choose k', where n is\n",
      "     |      the number of samples and k is the number of subsamples.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  HuberRegressor : Linear regression model that is robust to outliers.\n",
      "     |  RANSACRegressor : RANSAC (RANdom SAmple Consensus) algorithm.\n",
      "     |  SGDRegressor : Fitted by minimizing a regularized empirical loss with SGD.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  - Theil-Sen Estimators in a Multiple Linear Regression Model, 2009\n",
      "     |    Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang\n",
      "     |    http://home.olemiss.edu/~xdang/papers/MTSE.pdf\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.linear_model import TheilSenRegressor\n",
      "     |  >>> from sklearn.datasets import make_regression\n",
      "     |  >>> X, y = make_regression(\n",
      "     |  ...     n_samples=200, n_features=2, noise=4.0, random_state=0)\n",
      "     |  >>> reg = TheilSenRegressor(random_state=0).fit(X, y)\n",
      "     |  >>> reg.score(X, y)\n",
      "     |  0.9884...\n",
      "     |  >>> reg.predict(X[:1,])\n",
      "     |  array([-31.5871...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      TheilSenRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.linear_model._base.LinearModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : returns an instance of self.\n",
      "     |          Fitted `TheilSenRegressor` estimator.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._theil_sen.TheilSenRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._theil_sen.TheilSenRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |\n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using the linear model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array, shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "    class TweedieRegressor(_GeneralizedLinearRegressor)\n",
      "     |  TweedieRegressor(*, power=0.0, alpha=1.0, fit_intercept=True, link='auto', solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |\n",
      "     |  Generalized Linear Model with a Tweedie distribution.\n",
      "     |\n",
      "     |  This estimator can be used to model different GLMs depending on the\n",
      "     |  ``power`` parameter, which determines the underlying distribution.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <Generalized_linear_models>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.23\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  power : float, default=0\n",
      "     |          The power determines the underlying target distribution according\n",
      "     |          to the following table:\n",
      "     |\n",
      "     |          +-------+------------------------+\n",
      "     |          | Power | Distribution           |\n",
      "     |          +=======+========================+\n",
      "     |          | 0     | Normal                 |\n",
      "     |          +-------+------------------------+\n",
      "     |          | 1     | Poisson                |\n",
      "     |          +-------+------------------------+\n",
      "     |          | (1,2) | Compound Poisson Gamma |\n",
      "     |          +-------+------------------------+\n",
      "     |          | 2     | Gamma                  |\n",
      "     |          +-------+------------------------+\n",
      "     |          | 3     | Inverse Gaussian       |\n",
      "     |          +-------+------------------------+\n",
      "     |\n",
      "     |          For ``0 < power < 1``, no distribution exists.\n",
      "     |\n",
      "     |  alpha : float, default=1\n",
      "     |      Constant that multiplies the L2 penalty term and determines the\n",
      "     |      regularization strength. ``alpha = 0`` is equivalent to unpenalized\n",
      "     |      GLMs. In this case, the design matrix `X` must have full column rank\n",
      "     |      (no collinearities).\n",
      "     |      Values of `alpha` must be in the range `[0.0, inf)`.\n",
      "     |\n",
      "     |  fit_intercept : bool, default=True\n",
      "     |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "     |      added to the linear predictor (`X @ coef + intercept`).\n",
      "     |\n",
      "     |  link : {'auto', 'identity', 'log'}, default='auto'\n",
      "     |      The link function of the GLM, i.e. mapping from linear predictor\n",
      "     |      `X @ coeff + intercept` to prediction `y_pred`. Option 'auto' sets\n",
      "     |      the link depending on the chosen `power` parameter as follows:\n",
      "     |\n",
      "     |      - 'identity' for ``power <= 0``, e.g. for the Normal distribution\n",
      "     |      - 'log' for ``power > 0``, e.g. for Poisson, Gamma and Inverse Gaussian\n",
      "     |        distributions\n",
      "     |\n",
      "     |  solver : {'lbfgs', 'newton-cholesky'}, default='lbfgs'\n",
      "     |      Algorithm to use in the optimization problem:\n",
      "     |\n",
      "     |      'lbfgs'\n",
      "     |          Calls scipy's L-BFGS-B optimizer.\n",
      "     |\n",
      "     |      'newton-cholesky'\n",
      "     |          Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to\n",
      "     |          iterated reweighted least squares) with an inner Cholesky based solver.\n",
      "     |          This solver is a good choice for `n_samples` >> `n_features`, especially\n",
      "     |          with one-hot encoded categorical features with rare categories. Be aware\n",
      "     |          that the memory usage of this solver has a quadratic dependency on\n",
      "     |          `n_features` because it explicitly computes the Hessian matrix.\n",
      "     |\n",
      "     |          .. versionadded:: 1.2\n",
      "     |\n",
      "     |  max_iter : int, default=100\n",
      "     |      The maximal number of iterations for the solver.\n",
      "     |      Values must be in the range `[1, inf)`.\n",
      "     |\n",
      "     |  tol : float, default=1e-4\n",
      "     |      Stopping criterion. For the lbfgs solver,\n",
      "     |      the iteration will stop when ``max{|g_j|, j = 1, ..., d} <= tol``\n",
      "     |      where ``g_j`` is the j-th component of the gradient (derivative) of\n",
      "     |      the objective function.\n",
      "     |      Values must be in the range `(0.0, inf)`.\n",
      "     |\n",
      "     |  warm_start : bool, default=False\n",
      "     |      If set to ``True``, reuse the solution of the previous call to ``fit``\n",
      "     |      as initialization for ``coef_`` and ``intercept_`` .\n",
      "     |\n",
      "     |  verbose : int, default=0\n",
      "     |      For the lbfgs solver set verbose to any positive number for verbosity.\n",
      "     |      Values must be in the range `[0, inf)`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  coef_ : array of shape (n_features,)\n",
      "     |      Estimated coefficients for the linear predictor (`X @ coef_ +\n",
      "     |      intercept_`) in the GLM.\n",
      "     |\n",
      "     |  intercept_ : float\n",
      "     |      Intercept (a.k.a. bias) added to linear predictor.\n",
      "     |\n",
      "     |  n_iter_ : int\n",
      "     |      Actual number of iterations used in the solver.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  PoissonRegressor : Generalized Linear Model with a Poisson distribution.\n",
      "     |  GammaRegressor : Generalized Linear Model with a Gamma distribution.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import linear_model\n",
      "     |  >>> clf = linear_model.TweedieRegressor()\n",
      "     |  >>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]\n",
      "     |  >>> y = [2, 3.5, 5, 5.5]\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  TweedieRegressor()\n",
      "     |  >>> clf.score(X, y)\n",
      "     |  0.839...\n",
      "     |  >>> clf.coef_\n",
      "     |  array([0.599..., 0.299...])\n",
      "     |  >>> clf.intercept_\n",
      "     |  1.600...\n",
      "     |  >>> clf.predict([[1, 1], [3, 4]])\n",
      "     |  array([2.500..., 4.599...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      TweedieRegressor\n",
      "     |      _GeneralizedLinearRegressor\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, power=0.0, alpha=1.0, fit_intercept=True, link='auto', solver='lbfgs', max_iter=100, tol=0.0001, warm_start=False, verbose=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.linear_model._glm.glm.TweedieRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.TweedieRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_score_request(self: sklearn.linear_model._glm.glm.TweedieRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._glm.glm.TweedieRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _GeneralizedLinearRegressor:\n",
      "     |\n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit a Generalized Linear Model.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training data.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted model.\n",
      "     |\n",
      "     |  predict(self, X)\n",
      "     |      Predict using GLM with feature matrix X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_pred : array of shape (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |\n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Compute D^2, the percentage of deviance explained.\n",
      "     |\n",
      "     |      D^2 is a generalization of the coefficient of determination R^2.\n",
      "     |      R^2 uses squared error and D^2 uses the deviance of this GLM, see the\n",
      "     |      :ref:`User Guide <regression_metrics>`.\n",
      "     |\n",
      "     |      D^2 is defined as\n",
      "     |      :math:`D^2 = 1-\\frac{D(y_{true},y_{pred})}{D_{null}}`,\n",
      "     |      :math:`D_{null}` is the null deviance, i.e. the deviance of a model\n",
      "     |      with intercept alone, which corresponds to :math:`y_{pred} = \\bar{y}`.\n",
      "     |      The mean :math:`\\bar{y}` is averaged by sample_weight.\n",
      "     |      Best possible score is 1.0 and it can be negative (because the model\n",
      "     |      can be arbitrarily worse).\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          True values of target.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          D^2 of self.predict(X) w.r.t. y.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "FUNCTIONS\n",
      "    enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      "        Compute elastic net path with coordinate descent.\n",
      "\n",
      "        The elastic net optimization function varies for mono and multi-outputs.\n",
      "\n",
      "        For mono-output tasks it is::\n",
      "\n",
      "            1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "            + alpha * l1_ratio * ||w||_1\n",
      "            + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "\n",
      "        For multi-output tasks it is::\n",
      "\n",
      "            (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      "            + alpha * l1_ratio * ||W||_21\n",
      "            + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      "\n",
      "        Where::\n",
      "\n",
      "            ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "\n",
      "        i.e. the sum of norm of each row.\n",
      "\n",
      "        Read more in the :ref:`User Guide <elastic_net>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "            unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "            can be sparse.\n",
      "\n",
      "        y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "            Target values.\n",
      "\n",
      "        l1_ratio : float, default=0.5\n",
      "            Number between 0 and 1 passed to elastic net (scaling between\n",
      "            l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      "\n",
      "        eps : float, default=1e-3\n",
      "            Length of the path. ``eps=1e-3`` means that\n",
      "            ``alpha_min / alpha_max = 1e-3``.\n",
      "\n",
      "        n_alphas : int, default=100\n",
      "            Number of alphas along the regularization path.\n",
      "\n",
      "        alphas : array-like, default=None\n",
      "            List of alphas where to compute the models.\n",
      "            If None alphas are set automatically.\n",
      "\n",
      "        precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "            Whether to use a precomputed Gram matrix to speed up\n",
      "            calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "            matrix can also be passed as argument.\n",
      "\n",
      "        Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "            Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "            only when the Gram matrix is precomputed.\n",
      "\n",
      "        copy_X : bool, default=True\n",
      "            If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "        coef_init : array-like of shape (n_features, ), default=None\n",
      "            The initial values of the coefficients.\n",
      "\n",
      "        verbose : bool or int, default=False\n",
      "            Amount of verbosity.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether to return the number of iterations or not.\n",
      "\n",
      "        positive : bool, default=False\n",
      "            If set to True, forces coefficients to be positive.\n",
      "            (Only allowed when ``y.ndim == 1``).\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            If set to False, the input validation checks are skipped (including the\n",
      "            Gram matrix when provided). It is assumed that they are handled\n",
      "            by the caller.\n",
      "\n",
      "        **params : kwargs\n",
      "            Keyword arguments passed to the coordinate descent solver.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        alphas : ndarray of shape (n_alphas,)\n",
      "            The alphas along the path where models are computed.\n",
      "\n",
      "        coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "            Coefficients along the path.\n",
      "\n",
      "        dual_gaps : ndarray of shape (n_alphas,)\n",
      "            The dual gaps at the end of the optimization for each alpha.\n",
      "\n",
      "        n_iters : list of int\n",
      "            The number of iterations taken by the coordinate descent optimizer to\n",
      "            reach the specified tolerance for each alpha.\n",
      "            (Is returned when ``return_n_iter`` is set to True).\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      "        MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      "        ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      "        ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        For an example, see\n",
      "        :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "        <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.linear_model import enet_path\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> X, y, true_coef = make_regression(\n",
      "        ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "        ... )\n",
      "        >>> true_coef\n",
      "        array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "        >>> alphas, estimated_coef, _ = enet_path(X, y, n_alphas=3)\n",
      "        >>> alphas.shape\n",
      "        (3,)\n",
      "        >>> estimated_coef\n",
      "         array([[ 0.        ,  0.78...,  0.56...],\n",
      "                [ 0.        ,  1.12...,  0.61...],\n",
      "                [-0.        , -2.12..., -1.12...],\n",
      "                [ 0.        , 23.04..., 88.93...],\n",
      "                [ 0.        , 10.63..., 41.56...]])\n",
      "\n",
      "    lars_path(X, y, Xy=None, *, Gram=None, max_iter=500, alpha_min=0, method='lar', copy_X=True, eps=2.220446049250313e-16, copy_Gram=True, verbose=0, return_path=True, return_n_iter=False, positive=False)\n",
      "        Compute Least Angle Regression or Lasso path using the LARS algorithm [1].\n",
      "\n",
      "        The optimization objective for the case method='lasso' is::\n",
      "\n",
      "        (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "\n",
      "        in the case of method='lar', the objective function is only known in\n",
      "        the form of an implicit equation (see discussion in [1]).\n",
      "\n",
      "        Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : None or ndarray of shape (n_samples, n_features)\n",
      "            Input data. Note that if X is `None` then the Gram matrix must be\n",
      "            specified, i.e., cannot be `None` or `False`.\n",
      "\n",
      "        y : None or ndarray of shape (n_samples,)\n",
      "            Input targets.\n",
      "\n",
      "        Xy : array-like of shape (n_features,), default=None\n",
      "            `Xy = X.T @ y` that can be precomputed. It is useful\n",
      "            only when the Gram matrix is precomputed.\n",
      "\n",
      "        Gram : None, 'auto', bool, ndarray of shape (n_features, n_features),             default=None\n",
      "            Precomputed Gram matrix `X.T @ X`, if `'auto'`, the Gram\n",
      "            matrix is precomputed from the given X, if there are more samples\n",
      "            than features.\n",
      "\n",
      "        max_iter : int, default=500\n",
      "            Maximum number of iterations to perform, set to infinity for no limit.\n",
      "\n",
      "        alpha_min : float, default=0\n",
      "            Minimum correlation along the path. It corresponds to the\n",
      "            regularization parameter `alpha` in the Lasso.\n",
      "\n",
      "        method : {'lar', 'lasso'}, default='lar'\n",
      "            Specifies the returned model. Select `'lar'` for Least Angle\n",
      "            Regression, `'lasso'` for the Lasso.\n",
      "\n",
      "        copy_X : bool, default=True\n",
      "            If `False`, `X` is overwritten.\n",
      "\n",
      "        eps : float, default=np.finfo(float).eps\n",
      "            The machine-precision regularization in the computation of the\n",
      "            Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "            systems. Unlike the `tol` parameter in some iterative\n",
      "            optimization-based algorithms, this parameter does not control\n",
      "            the tolerance of the optimization.\n",
      "\n",
      "        copy_Gram : bool, default=True\n",
      "            If `False`, `Gram` is overwritten.\n",
      "\n",
      "        verbose : int, default=0\n",
      "            Controls output verbosity.\n",
      "\n",
      "        return_path : bool, default=True\n",
      "            If `True`, returns the entire path, else returns only the\n",
      "            last point of the path.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether to return the number of iterations.\n",
      "\n",
      "        positive : bool, default=False\n",
      "            Restrict coefficients to be >= 0.\n",
      "            This option is only allowed with method 'lasso'. Note that the model\n",
      "            coefficients will not converge to the ordinary-least-squares solution\n",
      "            for small values of alpha. Only coefficients up to the smallest alpha\n",
      "            value (`alphas_[alphas_ > 0.].min()` when fit_path=True) reached by\n",
      "            the stepwise Lars-Lasso algorithm are typically in congruence with the\n",
      "            solution of the coordinate descent `lasso_path` function.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        alphas : ndarray of shape (n_alphas + 1,)\n",
      "            Maximum of covariances (in absolute value) at each iteration.\n",
      "            `n_alphas` is either `max_iter`, `n_features`, or the\n",
      "            number of nodes in the path with `alpha >= alpha_min`, whichever\n",
      "            is smaller.\n",
      "\n",
      "        active : ndarray of shape (n_alphas,)\n",
      "            Indices of active variables at the end of the path.\n",
      "\n",
      "        coefs : ndarray of shape (n_features, n_alphas + 1)\n",
      "            Coefficients along the path.\n",
      "\n",
      "        n_iter : int\n",
      "            Number of iterations run. Returned only if `return_n_iter` is set\n",
      "            to True.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        lars_path_gram : Compute LARS path in the sufficient stats mode.\n",
      "        lasso_path : Compute Lasso path with coordinate descent.\n",
      "        LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "        Lars : Least Angle Regression model a.k.a. LAR.\n",
      "        LassoLarsCV : Cross-validated Lasso, using the LARS algorithm.\n",
      "        LarsCV : Cross-validated Least Angle Regression model.\n",
      "        sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Least Angle Regression\", Efron et al.\n",
      "               http://statweb.stanford.edu/~tibs/ftp/lars.pdf\n",
      "\n",
      "        .. [2] `Wikipedia entry on the Least-angle regression\n",
      "               <https://en.wikipedia.org/wiki/Least-angle_regression>`_\n",
      "\n",
      "        .. [3] `Wikipedia entry on the Lasso\n",
      "               <https://en.wikipedia.org/wiki/Lasso_(statistics)>`_\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.linear_model import lars_path\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> X, y, true_coef = make_regression(\n",
      "        ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "        ... )\n",
      "        >>> true_coef\n",
      "        array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "        >>> alphas, _, estimated_coef = lars_path(X, y)\n",
      "        >>> alphas.shape\n",
      "        (3,)\n",
      "        >>> estimated_coef\n",
      "        array([[ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     , 46.96..., 97.99...],\n",
      "               [ 0.     ,  0.     , 45.70...]])\n",
      "\n",
      "    lars_path_gram(Xy, Gram, *, n_samples, max_iter=500, alpha_min=0, method='lar', copy_X=True, eps=2.220446049250313e-16, copy_Gram=True, verbose=0, return_path=True, return_n_iter=False, positive=False)\n",
      "        The lars_path in the sufficient stats mode [1].\n",
      "\n",
      "        The optimization objective for the case method='lasso' is::\n",
      "\n",
      "        (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "\n",
      "        in the case of method='lar', the objective function is only known in\n",
      "        the form of an implicit equation (see discussion in [1])\n",
      "\n",
      "        Read more in the :ref:`User Guide <least_angle_regression>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        Xy : ndarray of shape (n_features,)\n",
      "            `Xy = X.T @ y`.\n",
      "\n",
      "        Gram : ndarray of shape (n_features, n_features)\n",
      "            `Gram = X.T @ X`.\n",
      "\n",
      "        n_samples : int\n",
      "            Equivalent size of sample.\n",
      "\n",
      "        max_iter : int, default=500\n",
      "            Maximum number of iterations to perform, set to infinity for no limit.\n",
      "\n",
      "        alpha_min : float, default=0\n",
      "            Minimum correlation along the path. It corresponds to the\n",
      "            regularization parameter alpha parameter in the Lasso.\n",
      "\n",
      "        method : {'lar', 'lasso'}, default='lar'\n",
      "            Specifies the returned model. Select `'lar'` for Least Angle\n",
      "            Regression, ``'lasso'`` for the Lasso.\n",
      "\n",
      "        copy_X : bool, default=True\n",
      "            If `False`, `X` is overwritten.\n",
      "\n",
      "        eps : float, default=np.finfo(float).eps\n",
      "            The machine-precision regularization in the computation of the\n",
      "            Cholesky diagonal factors. Increase this for very ill-conditioned\n",
      "            systems. Unlike the `tol` parameter in some iterative\n",
      "            optimization-based algorithms, this parameter does not control\n",
      "            the tolerance of the optimization.\n",
      "\n",
      "        copy_Gram : bool, default=True\n",
      "            If `False`, `Gram` is overwritten.\n",
      "\n",
      "        verbose : int, default=0\n",
      "            Controls output verbosity.\n",
      "\n",
      "        return_path : bool, default=True\n",
      "            If `return_path==True` returns the entire path, else returns only the\n",
      "            last point of the path.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether to return the number of iterations.\n",
      "\n",
      "        positive : bool, default=False\n",
      "            Restrict coefficients to be >= 0.\n",
      "            This option is only allowed with method 'lasso'. Note that the model\n",
      "            coefficients will not converge to the ordinary-least-squares solution\n",
      "            for small values of alpha. Only coefficients up to the smallest alpha\n",
      "            value (`alphas_[alphas_ > 0.].min()` when `fit_path=True`) reached by\n",
      "            the stepwise Lars-Lasso algorithm are typically in congruence with the\n",
      "            solution of the coordinate descent lasso_path function.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        alphas : ndarray of shape (n_alphas + 1,)\n",
      "            Maximum of covariances (in absolute value) at each iteration.\n",
      "            `n_alphas` is either `max_iter`, `n_features` or the\n",
      "            number of nodes in the path with `alpha >= alpha_min`, whichever\n",
      "            is smaller.\n",
      "\n",
      "        active : ndarray of shape (n_alphas,)\n",
      "            Indices of active variables at the end of the path.\n",
      "\n",
      "        coefs : ndarray of shape (n_features, n_alphas + 1)\n",
      "            Coefficients along the path.\n",
      "\n",
      "        n_iter : int\n",
      "            Number of iterations run. Returned only if `return_n_iter` is set\n",
      "            to True.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        lars_path_gram : Compute LARS path.\n",
      "        lasso_path : Compute Lasso path with coordinate descent.\n",
      "        LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "        Lars : Least Angle Regression model a.k.a. LAR.\n",
      "        LassoLarsCV : Cross-validated Lasso, using the LARS algorithm.\n",
      "        LarsCV : Cross-validated Least Angle Regression model.\n",
      "        sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Least Angle Regression\", Efron et al.\n",
      "               http://statweb.stanford.edu/~tibs/ftp/lars.pdf\n",
      "\n",
      "        .. [2] `Wikipedia entry on the Least-angle regression\n",
      "               <https://en.wikipedia.org/wiki/Least-angle_regression>`_\n",
      "\n",
      "        .. [3] `Wikipedia entry on the Lasso\n",
      "               <https://en.wikipedia.org/wiki/Lasso_(statistics)>`_\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.linear_model import lars_path_gram\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> X, y, true_coef = make_regression(\n",
      "        ...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0\n",
      "        ... )\n",
      "        >>> true_coef\n",
      "        array([ 0.        ,  0.        ,  0.        , 97.9..., 45.7...])\n",
      "        >>> alphas, _, estimated_coef = lars_path_gram(X.T @ y, X.T @ X, n_samples=100)\n",
      "        >>> alphas.shape\n",
      "        (3,)\n",
      "        >>> estimated_coef\n",
      "        array([[ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     ,  0.     ,  0.     ],\n",
      "               [ 0.     , 46.96..., 97.99...],\n",
      "               [ 0.     ,  0.     , 45.70...]])\n",
      "\n",
      "    lasso_path(X, y, *, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, **params)\n",
      "        Compute Lasso path with coordinate descent.\n",
      "\n",
      "        The Lasso optimization function varies for mono and multi-outputs.\n",
      "\n",
      "        For mono-output tasks it is::\n",
      "\n",
      "            (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      "\n",
      "        For multi-output tasks it is::\n",
      "\n",
      "            (1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21\n",
      "\n",
      "        Where::\n",
      "\n",
      "            ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      "\n",
      "        i.e. the sum of norm of each row.\n",
      "\n",
      "        Read more in the :ref:`User Guide <lasso>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training data. Pass directly as Fortran-contiguous data to avoid\n",
      "            unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      "            can be sparse.\n",
      "\n",
      "        y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      "            Target values.\n",
      "\n",
      "        eps : float, default=1e-3\n",
      "            Length of the path. ``eps=1e-3`` means that\n",
      "            ``alpha_min / alpha_max = 1e-3``.\n",
      "\n",
      "        n_alphas : int, default=100\n",
      "            Number of alphas along the regularization path.\n",
      "\n",
      "        alphas : array-like, default=None\n",
      "            List of alphas where to compute the models.\n",
      "            If ``None`` alphas are set automatically.\n",
      "\n",
      "        precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      "            Whether to use a precomputed Gram matrix to speed up\n",
      "            calculations. If set to ``'auto'`` let us decide. The Gram\n",
      "            matrix can also be passed as argument.\n",
      "\n",
      "        Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      "            Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      "            only when the Gram matrix is precomputed.\n",
      "\n",
      "        copy_X : bool, default=True\n",
      "            If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "        coef_init : array-like of shape (n_features, ), default=None\n",
      "            The initial values of the coefficients.\n",
      "\n",
      "        verbose : bool or int, default=False\n",
      "            Amount of verbosity.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether to return the number of iterations or not.\n",
      "\n",
      "        positive : bool, default=False\n",
      "            If set to True, forces coefficients to be positive.\n",
      "            (Only allowed when ``y.ndim == 1``).\n",
      "\n",
      "        **params : kwargs\n",
      "            Keyword arguments passed to the coordinate descent solver.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        alphas : ndarray of shape (n_alphas,)\n",
      "            The alphas along the path where models are computed.\n",
      "\n",
      "        coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      "            Coefficients along the path.\n",
      "\n",
      "        dual_gaps : ndarray of shape (n_alphas,)\n",
      "            The dual gaps at the end of the optimization for each alpha.\n",
      "\n",
      "        n_iters : list of int\n",
      "            The number of iterations taken by the coordinate descent optimizer to\n",
      "            reach the specified tolerance for each alpha.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        lars_path : Compute Least Angle Regression or Lasso path using LARS\n",
      "            algorithm.\n",
      "        Lasso : The Lasso is a linear model that estimates sparse coefficients.\n",
      "        LassoLars : Lasso model fit with Least Angle Regression a.k.a. Lars.\n",
      "        LassoCV : Lasso linear model with iterative fitting along a regularization\n",
      "            path.\n",
      "        LassoLarsCV : Cross-validated Lasso using the LARS algorithm.\n",
      "        sklearn.decomposition.sparse_encode : Estimator that can be used to\n",
      "            transform signals into sparse linear combination of atoms from a fixed.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        For an example, see\n",
      "        :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      "        <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      "\n",
      "        To avoid unnecessary memory duplication the X argument of the fit method\n",
      "        should be directly passed as a Fortran-contiguous numpy array.\n",
      "\n",
      "        Note that in certain cases, the Lars solver may be significantly\n",
      "        faster to implement this functionality. In particular, linear\n",
      "        interpolation can be used to retrieve model coefficients between the\n",
      "        values output by lars_path\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "\n",
      "        Comparing lasso_path and lars_path with interpolation:\n",
      "\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.linear_model import lasso_path\n",
      "        >>> X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n",
      "        >>> y = np.array([1, 2, 3.1])\n",
      "        >>> # Use lasso_path to compute a coefficient path\n",
      "        >>> _, coef_path, _ = lasso_path(X, y, alphas=[5., 1., .5])\n",
      "        >>> print(coef_path)\n",
      "        [[0.         0.         0.46874778]\n",
      "         [0.2159048  0.4425765  0.23689075]]\n",
      "\n",
      "        >>> # Now use lars_path and 1D linear interpolation to compute the\n",
      "        >>> # same path\n",
      "        >>> from sklearn.linear_model import lars_path\n",
      "        >>> alphas, active, coef_path_lars = lars_path(X, y, method='lasso')\n",
      "        >>> from scipy import interpolate\n",
      "        >>> coef_path_continuous = interpolate.interp1d(alphas[::-1],\n",
      "        ...                                             coef_path_lars[:, ::-1])\n",
      "        >>> print(coef_path_continuous([5., 1., .5]))\n",
      "        [[0.         0.         0.46915237]\n",
      "         [0.2159048  0.4425765  0.23668876]]\n",
      "\n",
      "    orthogonal_mp(X, y, *, n_nonzero_coefs=None, tol=None, precompute=False, copy_X=True, return_path=False, return_n_iter=False)\n",
      "        Orthogonal Matching Pursuit (OMP).\n",
      "\n",
      "        Solves n_targets Orthogonal Matching Pursuit problems.\n",
      "        An instance of the problem has the form:\n",
      "\n",
      "        When parametrized by the number of non-zero coefficients using\n",
      "        `n_nonzero_coefs`:\n",
      "        argmin ||y - X\\gamma||^2 subject to ||\\gamma||_0 <= n_{nonzero coefs}\n",
      "\n",
      "        When parametrized by error using the parameter `tol`:\n",
      "        argmin ||\\gamma||_0 subject to ||y - X\\gamma||^2 <= tol\n",
      "\n",
      "        Read more in the :ref:`User Guide <omp>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Input data. Columns are assumed to have unit norm.\n",
      "\n",
      "        y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "            Input targets.\n",
      "\n",
      "        n_nonzero_coefs : int, default=None\n",
      "            Desired number of non-zero entries in the solution. If None (by\n",
      "            default) this value is set to 10% of n_features.\n",
      "\n",
      "        tol : float, default=None\n",
      "            Maximum squared norm of the residual. If not None, overrides n_nonzero_coefs.\n",
      "\n",
      "        precompute : 'auto' or bool, default=False\n",
      "            Whether to perform precomputations. Improves performance when n_targets\n",
      "            or n_samples is very large.\n",
      "\n",
      "        copy_X : bool, default=True\n",
      "            Whether the design matrix X must be copied by the algorithm. A false\n",
      "            value is only helpful if X is already Fortran-ordered, otherwise a\n",
      "            copy is made anyway.\n",
      "\n",
      "        return_path : bool, default=False\n",
      "            Whether to return every value of the nonzero coefficients along the\n",
      "            forward path. Useful for cross-validation.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether or not to return the number of iterations.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "            Coefficients of the OMP solution. If `return_path=True`, this contains\n",
      "            the whole coefficient path. In this case its shape is\n",
      "            (n_features, n_features) or (n_features, n_targets, n_features) and\n",
      "            iterating over the last axis generates coefficients in increasing order\n",
      "            of active features.\n",
      "\n",
      "        n_iters : array-like or int\n",
      "            Number of active features across every target. Returned only if\n",
      "            `return_n_iter` is set to True.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        OrthogonalMatchingPursuit : Orthogonal Matching Pursuit model.\n",
      "        orthogonal_mp_gram : Solve OMP problems using Gram matrix and the product X.T * y.\n",
      "        lars_path : Compute Least Angle Regression or Lasso path using LARS algorithm.\n",
      "        sklearn.decomposition.sparse_encode : Sparse coding.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang,\n",
      "        Matching pursuits with time-frequency dictionaries, IEEE Transactions on\n",
      "        Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.\n",
      "        (https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf)\n",
      "\n",
      "        This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,\n",
      "        M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal\n",
      "        Matching Pursuit Technical Report - CS Technion, April 2008.\n",
      "        https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> from sklearn.linear_model import orthogonal_mp\n",
      "        >>> X, y = make_regression(noise=4, random_state=0)\n",
      "        >>> coef = orthogonal_mp(X, y)\n",
      "        >>> coef.shape\n",
      "        (100,)\n",
      "        >>> X[:1,] @ coef\n",
      "        array([-78.68...])\n",
      "\n",
      "    orthogonal_mp_gram(Gram, Xy, *, n_nonzero_coefs=None, tol=None, norms_squared=None, copy_Gram=True, copy_Xy=True, return_path=False, return_n_iter=False)\n",
      "        Gram Orthogonal Matching Pursuit (OMP).\n",
      "\n",
      "        Solves n_targets Orthogonal Matching Pursuit problems using only\n",
      "        the Gram matrix X.T * X and the product X.T * y.\n",
      "\n",
      "        Read more in the :ref:`User Guide <omp>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        Gram : array-like of shape (n_features, n_features)\n",
      "            Gram matrix of the input data: `X.T * X`.\n",
      "\n",
      "        Xy : array-like of shape (n_features,) or (n_features, n_targets)\n",
      "            Input targets multiplied by `X`: `X.T * y`.\n",
      "\n",
      "        n_nonzero_coefs : int, default=None\n",
      "            Desired number of non-zero entries in the solution. If `None` (by\n",
      "            default) this value is set to 10% of n_features.\n",
      "\n",
      "        tol : float, default=None\n",
      "            Maximum squared norm of the residual. If not `None`,\n",
      "            overrides `n_nonzero_coefs`.\n",
      "\n",
      "        norms_squared : array-like of shape (n_targets,), default=None\n",
      "            Squared L2 norms of the lines of `y`. Required if `tol` is not None.\n",
      "\n",
      "        copy_Gram : bool, default=True\n",
      "            Whether the gram matrix must be copied by the algorithm. A `False`\n",
      "            value is only helpful if it is already Fortran-ordered, otherwise a\n",
      "            copy is made anyway.\n",
      "\n",
      "        copy_Xy : bool, default=True\n",
      "            Whether the covariance vector `Xy` must be copied by the algorithm.\n",
      "            If `False`, it may be overwritten.\n",
      "\n",
      "        return_path : bool, default=False\n",
      "            Whether to return every value of the nonzero coefficients along the\n",
      "            forward path. Useful for cross-validation.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            Whether or not to return the number of iterations.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "            Coefficients of the OMP solution. If `return_path=True`, this contains\n",
      "            the whole coefficient path. In this case its shape is\n",
      "            `(n_features, n_features)` or `(n_features, n_targets, n_features)` and\n",
      "            iterating over the last axis yields coefficients in increasing order\n",
      "            of active features.\n",
      "\n",
      "        n_iters : list or int\n",
      "            Number of active features across every target. Returned only if\n",
      "            `return_n_iter` is set to True.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        OrthogonalMatchingPursuit : Orthogonal Matching Pursuit model (OMP).\n",
      "        orthogonal_mp : Solves n_targets Orthogonal Matching Pursuit problems.\n",
      "        lars_path : Compute Least Angle Regression or Lasso path using\n",
      "            LARS algorithm.\n",
      "        sklearn.decomposition.sparse_encode : Generic sparse coding.\n",
      "            Each column of the result is the solution to a Lasso problem.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang,\n",
      "        Matching pursuits with time-frequency dictionaries, IEEE Transactions on\n",
      "        Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415.\n",
      "        (https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf)\n",
      "\n",
      "        This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad,\n",
      "        M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal\n",
      "        Matching Pursuit Technical Report - CS Technion, April 2008.\n",
      "        https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> from sklearn.linear_model import orthogonal_mp_gram\n",
      "        >>> X, y = make_regression(noise=4, random_state=0)\n",
      "        >>> coef = orthogonal_mp_gram(X.T @ X, X.T @ y)\n",
      "        >>> coef.shape\n",
      "        (100,)\n",
      "        >>> X[:1,] @ coef\n",
      "        array([-78.68...])\n",
      "\n",
      "    ridge_regression(X, y, alpha, *, sample_weight=None, solver='auto', max_iter=None, tol=0.0001, verbose=0, positive=False, random_state=None, return_n_iter=False, return_intercept=False, check_input=True)\n",
      "        Solve the ridge equation by the method of normal equations.\n",
      "\n",
      "        Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix, LinearOperator} of shape         (n_samples, n_features)\n",
      "            Training data.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      "            Target values.\n",
      "\n",
      "        alpha : float or array-like of shape (n_targets,)\n",
      "            Constant that multiplies the L2 term, controlling regularization\n",
      "            strength. `alpha` must be a non-negative float i.e. in `[0, inf)`.\n",
      "\n",
      "            When `alpha = 0`, the objective is equivalent to ordinary least\n",
      "            squares, solved by the :class:`LinearRegression` object. For numerical\n",
      "            reasons, using `alpha = 0` with the `Ridge` object is not advised.\n",
      "            Instead, you should use the :class:`LinearRegression` object.\n",
      "\n",
      "            If an array is passed, penalties are assumed to be specific to the\n",
      "            targets. Hence they must correspond in number.\n",
      "\n",
      "        sample_weight : float or array-like of shape (n_samples,), default=None\n",
      "            Individual weights for each sample. If given a float, every sample\n",
      "            will have the same weight. If sample_weight is not None and\n",
      "            solver='auto', the solver will be set to 'cholesky'.\n",
      "\n",
      "            .. versionadded:: 0.17\n",
      "\n",
      "        solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',             'sag', 'saga', 'lbfgs'}, default='auto'\n",
      "            Solver to use in the computational routines:\n",
      "\n",
      "            - 'auto' chooses the solver automatically based on the type of data.\n",
      "\n",
      "            - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "              coefficients. It is the most stable solver, in particular more stable\n",
      "              for singular matrices than 'cholesky' at the cost of being slower.\n",
      "\n",
      "            - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "              obtain a closed-form solution via a Cholesky decomposition of\n",
      "              dot(X.T, X)\n",
      "\n",
      "            - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "              scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "              more appropriate than 'cholesky' for large-scale data\n",
      "              (possibility to set `tol` and `max_iter`).\n",
      "\n",
      "            - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "              scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "              procedure.\n",
      "\n",
      "            - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "              its improved, unbiased version named SAGA. Both methods also use an\n",
      "              iterative procedure, and are often faster than other solvers when\n",
      "              both n_samples and n_features are large. Note that 'sag' and\n",
      "              'saga' fast convergence is only guaranteed on features with\n",
      "              approximately the same scale. You can preprocess the data with a\n",
      "              scaler from sklearn.preprocessing.\n",
      "\n",
      "            - 'lbfgs' uses L-BFGS-B algorithm implemented in\n",
      "              `scipy.optimize.minimize`. It can be used only when `positive`\n",
      "              is True.\n",
      "\n",
      "            All solvers except 'svd' support both dense and sparse data. However, only\n",
      "            'lsqr', 'sag', 'sparse_cg', and 'lbfgs' support sparse input when\n",
      "            `fit_intercept` is True.\n",
      "\n",
      "            .. versionadded:: 0.17\n",
      "               Stochastic Average Gradient descent solver.\n",
      "            .. versionadded:: 0.19\n",
      "               SAGA solver.\n",
      "\n",
      "        max_iter : int, default=None\n",
      "            Maximum number of iterations for conjugate gradient solver.\n",
      "            For the 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      "            by scipy.sparse.linalg. For 'sag' and saga solver, the default value is\n",
      "            1000. For 'lbfgs' solver, the default value is 15000.\n",
      "\n",
      "        tol : float, default=1e-4\n",
      "            Precision of the solution. Note that `tol` has no effect for solvers 'svd' and\n",
      "            'cholesky'.\n",
      "\n",
      "            .. versionchanged:: 1.2\n",
      "               Default value changed from 1e-3 to 1e-4 for consistency with other linear\n",
      "               models.\n",
      "\n",
      "        verbose : int, default=0\n",
      "            Verbosity level. Setting verbose > 0 will display additional\n",
      "            information depending on the solver used.\n",
      "\n",
      "        positive : bool, default=False\n",
      "            When set to ``True``, forces the coefficients to be positive.\n",
      "            Only 'lbfgs' solver is supported in this case.\n",
      "\n",
      "        random_state : int, RandomState instance, default=None\n",
      "            Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "            See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "        return_n_iter : bool, default=False\n",
      "            If True, the method also returns `n_iter`, the actual number of\n",
      "            iteration performed by the solver.\n",
      "\n",
      "            .. versionadded:: 0.17\n",
      "\n",
      "        return_intercept : bool, default=False\n",
      "            If True and if X is sparse, the method also returns the intercept,\n",
      "            and the solver is automatically changed to 'sag'. This is only a\n",
      "            temporary fix for fitting the intercept with sparse data. For dense\n",
      "            data, use sklearn.linear_model._preprocess_data before your regression.\n",
      "\n",
      "            .. versionadded:: 0.17\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            If False, the input arrays X and y will not be checked.\n",
      "\n",
      "            .. versionadded:: 0.21\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        coef : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "            Weight vector(s).\n",
      "\n",
      "        n_iter : int, optional\n",
      "            The actual number of iteration performed by the solver.\n",
      "            Only returned if `return_n_iter` is True.\n",
      "\n",
      "        intercept : float or ndarray of shape (n_targets,)\n",
      "            The intercept of the model. Only returned if `return_intercept`\n",
      "            is True and if X is a scipy sparse array.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This function won't compute the intercept.\n",
      "\n",
      "        Regularization improves the conditioning of the problem and\n",
      "        reduces the variance of the estimates. Larger values specify stronger\n",
      "        regularization. Alpha corresponds to ``1 / (2C)`` in other linear\n",
      "        models such as :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "        :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      "        assumed to be specific to the targets. Hence they must correspond in\n",
      "        number.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.datasets import make_regression\n",
      "        >>> from sklearn.linear_model import ridge_regression\n",
      "        >>> rng = np.random.RandomState(0)\n",
      "        >>> X = rng.randn(100, 4)\n",
      "        >>> y = 2.0 * X[:, 0] - 1.0 * X[:, 1] + 0.1 * rng.standard_normal(100)\n",
      "        >>> coef, intercept = ridge_regression(X, y, alpha=1.0, return_intercept=True)\n",
      "        >>> list(coef)\n",
      "        [1.9..., -1.0..., -0.0..., -0.0...]\n",
      "        >>> intercept\n",
      "        -0.0...\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ARDRegression', 'BayesianRidge', 'ElasticNet', 'ElasticNet...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\taek5\\desktop\\bigdataanalysis\\venv\\lib\\site-packages\\sklearn\\linear_model\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "help(sklearn.linear_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
